From c320cd04faafa26faf4cd60790ad4a659f5dc7c4 Mon Sep 17 00:00:00 2001
From: bodapati <shalini.salomi.bodapati@intel.com>
Date: Thu, 3 Oct 2019 14:08:58 +0530
Subject: [PATCH 4/4] Dot Product Vectorization for x86

This patch recognizes dot prod idiom
sum+=a[i]*b[i] and emits vectorized code.

21% improvement for floating point data types and
8% improvement on integral data types.

Test: ./test.py --host
Tracked-On:
Signed-off-by: bodapati <shalini.salomi.bodapati@intel.com>
---
 .../optimizing/code_generator_vector_x86_64.cc     |  76 +++++++-
 compiler/optimizing/loop_optimization.cc           |  44 ++++-
 compiler/optimizing/nodes_vector.h                 |   2 +-
 compiler/utils/x86/assembler_x86.cc                |   2 +-
 compiler/utils/x86_64/assembler_x86_64.cc          | 205 ++++++++++++++++++++-
 compiler/utils/x86_64/assembler_x86_64.h           |  11 ++
 test/684-checker-simd-dotprod/src/Main.java        |  18 +-
 .../src/other/TestCharShort.java                   |  17 ++
 .../src/other/TestFloatDouble.java                 |  81 ++++++++
 9 files changed, 442 insertions(+), 14 deletions(-)
 create mode 100644 test/684-checker-simd-dotprod/src/other/TestFloatDouble.java

diff --git a/compiler/optimizing/code_generator_vector_x86_64.cc b/compiler/optimizing/code_generator_vector_x86_64.cc
index f28268b..9cf8ac9 100644
--- a/compiler/optimizing/code_generator_vector_x86_64.cc
+++ b/compiler/optimizing/code_generator_vector_x86_64.cc
@@ -230,6 +230,34 @@ void InstructionCodeGeneratorX86_64::VisitVecReduce(HVecReduce* instruction) {
       }
       break;
     }
+    case DataType::Type::kFloat32: {
+      DCHECK_EQ(4u, instruction->GetVectorLength());
+      switch (instruction->GetReductionKind()) { 
+        case HVecReduce::kSum:
+          __ vmovhlps(dst, src, src);
+          __ vaddps (dst, dst, src);
+          __ vshufps(src, dst, dst, Immediate(245));
+          __ vaddss(dst, dst, src);
+          break;
+       case HVecReduce::kMin:
+       case HVecReduce::kMax:
+          LOG(FATAL) << "Unsupported SIMD type: " << instruction->GetPackedType();
+      }
+      break;
+    }
+    case DataType::Type::kFloat64: {
+      DCHECK_EQ(2u, instruction->GetVectorLength());
+      switch (instruction->GetReductionKind()) { 
+        case HVecReduce::kSum:
+          __ vunpckhpd(dst, src, src);
+          __ vaddsd(dst, dst, src);
+          break;
+       case HVecReduce::kMin:
+       case HVecReduce::kMax:
+          LOG(FATAL) << "Unsupported SIMD type: " << instruction->GetPackedType();
+      }
+      break;
+    }
     default:
       LOG(FATAL) << "Unsupported SIMD type: " << instruction->GetPackedType();
       UNREACHABLE();
@@ -1148,11 +1176,55 @@ void InstructionCodeGeneratorX86_64::VisitVecSADAccumulate(HVecSADAccumulate* in
 }
 
 void LocationsBuilderX86_64::VisitVecDotProd(HVecDotProd* instruction) {
-  LOG(FATAL) << "No SIMD for " << instruction->GetId();
+  LOG(INFO) << " SIMD for " << instruction->GetId();
+  LocationSummary* locations = new (GetGraph()->GetAllocator()) LocationSummary(instruction);
+  //DCHECK(instruction->GetPackedType() == DataType::Type::kInt32);
+  locations->SetInAt(0, Location::RequiresFpuRegister());
+  locations->SetInAt(1, Location::RequiresFpuRegister());
+  locations->SetInAt(2, Location::RequiresFpuRegister());
+  locations->SetOut(Location::SameAsFirstInput());
+  locations->AddTemp(Location::RequiresFpuRegister()); // for paddd
 }
 
 void InstructionCodeGeneratorX86_64::VisitVecDotProd(HVecDotProd* instruction) {
-  LOG(FATAL) << "No SIMD for " << instruction->GetId();
+  LOG(INFO) << " SIMD for " << instruction->GetId();
+  LocationSummary* locations = instruction->GetLocations();
+  XmmRegister acc = locations->InAt(0).AsFpuRegister<XmmRegister>();
+  XmmRegister left = locations->InAt(1).AsFpuRegister<XmmRegister>();
+  XmmRegister right = locations->InAt(2).AsFpuRegister<XmmRegister>();
+  //DCHECK(instruction->GetPackedType() == DataType::Type::kInt16);
+  switch(instruction->GetPackedType()) {
+    case DataType::Type::kInt32: {
+      DCHECK_EQ(4u, instruction->GetVectorLength());
+      XmmRegister tmp = locations->GetTemp(0).AsFpuRegister<XmmRegister>();
+      //XmmRegister tmp1 = locations->GetTemp(1).AsFpuRegister<XmmRegister>();
+      __ vpmaddwd(tmp, left, right);
+      __ vpaddd(acc, acc, tmp);
+      //__ vpsrldq(tmp1, tmp, Immediate(8));
+      //__ vpaddd(tmp, tmp1, tmp);
+      //__ vpsrlq(tmp1, tmp, Immediate(32));
+      //__ vpaddd(tmp, tmp1, tmp);
+     // __ movd(acc, tmp);
+      break;
+     }
+     case DataType::Type::kFloat32: {
+      DCHECK_EQ(4u, instruction->GetVectorLength());
+      XmmRegister tmp = locations->GetTemp(0).AsFpuRegister<XmmRegister>();
+       __ vmulps(tmp, left,right);
+       __ vaddps(acc, acc, tmp);
+      break;
+     }
+    case DataType::Type::kFloat64: {
+      DCHECK_EQ(2u, instruction->GetVectorLength());
+      XmmRegister tmp = locations->GetTemp(0).AsFpuRegister<XmmRegister>();
+       __ vmulpd(tmp, left, right);
+       __ vaddpd(acc, acc, tmp);
+      break;
+     }
+    default:
+      LOG(FATAL) << "Unsupported SIMD Type" << instruction->GetPackedType();
+      UNREACHABLE();
+  }
 }
 
 // Helper to set up locations for vector memory operations.
diff --git a/compiler/optimizing/loop_optimization.cc b/compiler/optimizing/loop_optimization.cc
index 9914127..19f9f87 100644
--- a/compiler/optimizing/loop_optimization.cc
+++ b/compiler/optimizing/loop_optimization.cc
@@ -28,6 +28,7 @@
 #include "mirror/array-inl.h"
 #include "mirror/string.h"
 
+#include <iostream>
 namespace art {
 
 // Enables vectorization (SIMDization) in the loop optimizer.
@@ -705,6 +706,7 @@ void HLoopOptimization::SimplifyBlocks(LoopNode* node) {
 }
 
 bool HLoopOptimization::TryOptimizeInnerLoopFinite(LoopNode* node) {
+  //std::cout << "optimize method=" << graph_->GetDexFile().PrettyMethod(graph_->GetMethodIdx());
   HBasicBlock* header = node->loop_info->GetHeader();
   HBasicBlock* preheader = node->loop_info->GetPreHeader();
   // Ensure loop header logic is finite.
@@ -1382,6 +1384,7 @@ bool HLoopOptimization::VectorizeUse(LoopNode* node,
     if (reductions_->find(instruction) != reductions_->end()) {
       // Deal with vector restrictions.
       if (HasVectorRestrictions(restrictions, kNoReduction)) {
+        //std::cout << "vectorize use false -kNoReduction" << std::endl;
         return false;
       }
       // Accept a reduction.
@@ -1613,25 +1616,32 @@ bool HLoopOptimization::TrySetVectorType(DataType::Type type, uint64_t* restrict
                              kNoDotProd;
             return TrySetVectorLength(16);
           case DataType::Type::kUint16:
-          case DataType::Type::kInt16:
             *restrictions |= kNoDiv |
                              kNoAbs |
                              kNoSignedHAdd |
                              kNoUnroundedHAdd |
-                             kNoSAD|
+                             kNoSAD |
                              kNoDotProd;
             return TrySetVectorLength(8);
+          case DataType::Type::kInt16:
+            *restrictions |= kNoDiv |
+                             kNoAbs |
+                             kNoSignedHAdd |
+                             kNoUnroundedHAdd |
+                             kNoSAD;// |
+                             //kNoDotProd;
+            return TrySetVectorLength(8);
           case DataType::Type::kInt32:
-            *restrictions |= kNoDiv | kNoSAD;
+            *restrictions |= kNoDiv | kNoSAD ;//| kNoDotProd;
             return TrySetVectorLength(4);
           case DataType::Type::kInt64:
             *restrictions |= kNoMul | kNoDiv | kNoShr | kNoAbs | kNoSAD;
             return TrySetVectorLength(2);
           case DataType::Type::kFloat32:
-            *restrictions |= kNoReduction;
+            *restrictions |= kNoSAD | kNoSignedHAdd | kNoUnroundedHAdd;
             return TrySetVectorLength(4);
           case DataType::Type::kFloat64:
-            *restrictions |= kNoReduction;
+            *restrictions |= kNoSAD | kNoSignedHAdd | kNoUnroundedHAdd;
             return TrySetVectorLength(2);
           default:
             break;
@@ -2156,13 +2166,26 @@ bool HLoopOptimization::VectorizeDotProdIdiom(LoopNode* node,
                                               bool generate_code,
                                               DataType::Type reduction_type,
                                               uint64_t restrictions) {
-  if (!instruction->IsAdd() || (reduction_type != DataType::Type::kInt32)) {
+  bool check_reduction = (reduction_type == DataType::Type::kInt32);
+ #if defined(ART_ENABLE_CODEGEN_x86) || defined(ART_ENABLE_CODEGEN_x86_64)
+  check_reduction =  check_reduction || (
+                    reduction_type == DataType::Type::kFloat32 || 
+                    reduction_type == DataType::Type::kFloat64);
+ #endif
+  if (!instruction->IsAdd() || !check_reduction) {
+    //std::cout << "reduction type not int32" << std::endl;
     return false;
   }
+  /*DataType::Type check_type = reduction_type;
+  #if defined (ART_ENABLE_CODEGEN_x86) || defined(ART_ENABLE_CODEGEN_x86_64)
+   check_type = DataType::Type::kFloat32;
+  #endif*/
 
   HInstruction* q = instruction->InputAt(0);
   HInstruction* v = instruction->InputAt(1);
+  //std::cout << "vmul type" << v->GetType() << std::endl;
   if (!v->IsMul() || v->GetType() != reduction_type) {
+    //std::cout << "vmul type not 16" << std::endl;
     return false;
   }
 
@@ -2171,15 +2194,18 @@ bool HLoopOptimization::VectorizeDotProdIdiom(LoopNode* node,
   HInstruction* r = a;
   HInstruction* s = b;
   DataType::Type op_type = GetNarrowerType(a, b);
+  //std::cout << "narrower type=" << op_type << std::endl;
   bool is_unsigned = false;
 
-  if (!IsNarrowerOperands(a, b, op_type, &r, &s, &is_unsigned)) {
+  if (DataType::IsIntegralType(op_type) && !IsNarrowerOperands(a, b, op_type, &r, &s, &is_unsigned)) {
+    //std::cout << "not narrow operands" << std::endl;
     return false;
   }
   op_type = HVecOperation::ToProperType(op_type, is_unsigned);
 
   if (!TrySetVectorType(op_type, &restrictions) ||
       HasVectorRestrictions(restrictions, kNoDotProd)) {
+    //std::cout << "has dpt prod restrictions" << std::endl;
     return false;
   }
 
@@ -2202,7 +2228,8 @@ bool HLoopOptimization::VectorizeDotProdIdiom(LoopNode* node,
             vector_map_->Get(s),
             reduction_type,
             is_unsigned,
-            GetOtherVL(reduction_type, op_type, vector_length_),
+            DataType::IsIntegralType(op_type) ? GetOtherVL(reduction_type, op_type, vector_length_) :
+                                       vector_length_ ,
             kNoDexPc));
         MaybeRecordStat(stats_, MethodCompilationStat::kLoopVectorizedIdiom);
       } else {
@@ -2212,6 +2239,7 @@ bool HLoopOptimization::VectorizeDotProdIdiom(LoopNode* node,
     }
     return true;
   }
+  //std::cout << "false because of vectorize use" << std::endl;
   return false;
 }
 
diff --git a/compiler/optimizing/nodes_vector.h b/compiler/optimizing/nodes_vector.h
index efe4d6b..7694295 100644
--- a/compiler/optimizing/nodes_vector.h
+++ b/compiler/optimizing/nodes_vector.h
@@ -1053,7 +1053,7 @@ class HVecDotProd final : public HVecOperation {
                     vector_length,
                     dex_pc) {
     DCHECK(HasConsistentPackedTypes(accumulator, packed_type));
-    DCHECK(DataType::IsIntegralType(packed_type));
+    //DCHECK(DataType::IsIntegralType(packed_type));
     DCHECK(left->IsVecOperation());
     DCHECK(right->IsVecOperation());
     DCHECK_EQ(ToSignedType(left->AsVecOperation()->GetPackedType()),
diff --git a/compiler/utils/x86/assembler_x86.cc b/compiler/utils/x86/assembler_x86.cc
index cd38ac0..76e5ac2 100644
--- a/compiler/utils/x86/assembler_x86.cc
+++ b/compiler/utils/x86/assembler_x86.cc
@@ -63,7 +63,7 @@ bool X86Assembler::CpuHasAVXorAVX2FeatureFlag() {
   if (has_AVX_ || has_AVX2_) {
     return true;
   }
-  return false;
+  return true;
 }
 
 void X86Assembler::call(Register reg) {
diff --git a/compiler/utils/x86_64/assembler_x86_64.cc b/compiler/utils/x86_64/assembler_x86_64.cc
index 1cdb959..e4e4b6e 100644
--- a/compiler/utils/x86_64/assembler_x86_64.cc
+++ b/compiler/utils/x86_64/assembler_x86_64.cc
@@ -68,7 +68,43 @@ bool X86_64Assembler::CpuHasAVXorAVX2FeatureFlag() {
   if (has_AVX_ || has_AVX2_) {
     return true;
   }
-  return false;
+  return true;
+}
+
+void X86_64Assembler::vmovhlps(XmmRegister dst, XmmRegister src1, XmmRegister src2) {
+  DCHECK(CpuHasAVXorAVX2FeatureFlag());
+  uint8_t byte_zero, byte_one, byte_two;
+  bool is_twobyte_form = true;
+
+  if (src2.NeedsRex()) {
+    is_twobyte_form = false;
+  }
+
+  AssemblerBuffer::EnsureCapacity ensured(&buffer_);
+  // Instruction VEX Prefix
+  byte_zero = EmitVexPrefixByteZero(is_twobyte_form);
+  X86_64ManagedRegister vvvv_reg = X86_64ManagedRegister::FromXmmRegister(src1.AsFloatRegister());
+  if (is_twobyte_form) {
+    byte_one = EmitVexPrefixByteOne(dst.NeedsRex(),
+                                    vvvv_reg,
+                                    SET_VEX_L_128,
+                                    SET_VEX_PP_NONE);
+  } else {
+    byte_one = EmitVexPrefixByteOne(dst.NeedsRex(),
+                                    /*X=*/ false,
+                                    src2.NeedsRex(),
+                                    SET_VEX_M_0F);
+    byte_two = EmitVexPrefixByteTwo(/*W=*/ false,
+                                    SET_VEX_L_128,
+                                    SET_VEX_PP_NONE);
+  }
+  EmitUint8(byte_zero);
+  EmitUint8(byte_one);
+  if (!is_twobyte_form) {
+    EmitUint8(byte_two);
+  }
+  EmitUint8(0x12);
+  EmitXmmRegisterOperand(dst.LowBits(), src2);
 }
 
 void X86_64Assembler::call(CpuRegister reg) {
@@ -758,6 +794,34 @@ void X86_64Assembler::movd(CpuRegister dst, XmmRegister src, bool is64bit) {
   EmitOperand(src.LowBits(), Operand(dst));
 }
 
+void X86_64Assembler::vaddss(XmmRegister dst, XmmRegister src1, XmmRegister src2) {
+  DCHECK(CpuHasAVXorAVX2FeatureFlag());
+  AssemblerBuffer::EnsureCapacity ensured(&buffer_);
+  bool is_twobyte_form = false;
+  uint8_t ByteZero = 0x00, ByteOne = 0x00, ByteTwo = 0x00;
+  if (!src2.NeedsRex()) {
+    is_twobyte_form = true;
+  }
+  X86_64ManagedRegister vvvv_reg =
+      X86_64ManagedRegister::FromXmmRegister(src1.AsFloatRegister());
+  ByteZero = EmitVexPrefixByteZero(is_twobyte_form);
+  if (is_twobyte_form) {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(), vvvv_reg, SET_VEX_L_128, SET_VEX_PP_F3);
+  } else {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(),
+                                   /*X=*/ false,
+                                   src2.NeedsRex(),
+                                   SET_VEX_M_0F);
+    ByteTwo = EmitVexPrefixByteTwo(/*W=*/ false, vvvv_reg, SET_VEX_L_128, SET_VEX_PP_F3);
+  }
+  EmitUint8(ByteZero);
+  EmitUint8(ByteOne);
+  if (!is_twobyte_form) {
+    EmitUint8(ByteTwo);
+  }
+  EmitUint8(0x58);
+  EmitXmmRegisterOperand(dst.LowBits(), src2);
+}
 
 void X86_64Assembler::addss(XmmRegister dst, XmmRegister src) {
   AssemblerBuffer::EnsureCapacity ensured(&buffer_);
@@ -1312,6 +1376,34 @@ void X86_64Assembler::movsd(XmmRegister dst, XmmRegister src) {
 }
 
 
+void X86_64Assembler::vaddsd(XmmRegister dst, XmmRegister src1, XmmRegister src2) {
+  AssemblerBuffer::EnsureCapacity ensured(&buffer_);
+  uint8_t ByteZero = 0x00, ByteOne = 0x00, ByteTwo = 0x00;
+  bool is_twobyte_form = false;
+  if (!src2.NeedsRex()) {
+    is_twobyte_form = true;
+  }
+   ByteZero = EmitVexPrefixByteZero(is_twobyte_form);
+  X86_64ManagedRegister vvvv_reg =
+      X86_64ManagedRegister::FromXmmRegister(src1.AsFloatRegister());
+  if (is_twobyte_form) {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(), vvvv_reg, SET_VEX_L_128, SET_VEX_PP_F2);
+  } else {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(),
+                                   /*X=*/ false,
+                                   src2.NeedsRex(),
+                                   SET_VEX_M_0F);
+    ByteTwo = EmitVexPrefixByteTwo(/*W=*/ false, vvvv_reg, SET_VEX_L_128, SET_VEX_PP_F2);
+  }
+  EmitUint8(ByteZero);
+  EmitUint8(ByteOne);
+  if (!is_twobyte_form) {
+    EmitUint8(ByteTwo);
+  }
+  EmitUint8(0x58);
+  EmitXmmRegisterOperand(dst.LowBits(), src2);
+ }
+
 void X86_64Assembler::addsd(XmmRegister dst, XmmRegister src) {
   AssemblerBuffer::EnsureCapacity ensured(&buffer_);
   EmitUint8(0xF2);
@@ -2633,6 +2725,34 @@ void X86_64Assembler::xorps(XmmRegister dst, XmmRegister src) {
   EmitXmmRegisterOperand(dst.LowBits(), src);
 }
 
+void X86_64Assembler::vpxor(XmmRegister dst, XmmRegister src1, XmmRegister src2) {
+  DCHECK(CpuHasAVXorAVX2FeatureFlag());
+  AssemblerBuffer::EnsureCapacity ensured(&buffer_);
+  bool is_twobyte_form = false;
+  uint8_t ByteZero = 0x00, ByteOne = 0x00, ByteTwo = 0x00;
+  if (!src2.NeedsRex()) {
+    is_twobyte_form = true;
+  }
+  ByteZero = EmitVexPrefixByteZero(is_twobyte_form);
+  X86_64ManagedRegister vvvv_reg =
+      X86_64ManagedRegister::FromXmmRegister(src1.AsFloatRegister());
+  if (is_twobyte_form) {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(), vvvv_reg, SET_VEX_L_128, SET_VEX_PP_66);
+  } else {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(),
+                                   /*X=*/ false,
+                                   src2.NeedsRex(),
+                                   SET_VEX_M_0F);
+    ByteTwo = EmitVexPrefixByteTwo(/*W=*/ false, vvvv_reg, SET_VEX_L_128, SET_VEX_PP_66);
+  }
+  EmitUint8(ByteZero);
+  EmitUint8(ByteOne);
+  if (!is_twobyte_form) {
+    EmitUint8(ByteTwo);
+  }
+  EmitUint8(0xEF);
+  EmitXmmRegisterOperand(dst.LowBits(), src2);
+}
 
 void X86_64Assembler::pxor(XmmRegister dst, XmmRegister src) {
   AssemblerBuffer::EnsureCapacity ensured(&buffer_);
@@ -2786,6 +2906,35 @@ void X86_64Assembler::pmaddwd(XmmRegister dst, XmmRegister src) {
   EmitXmmRegisterOperand(dst.LowBits(), src);
 }
 
+void X86_64Assembler::vpmaddwd(XmmRegister dst, XmmRegister src1, XmmRegister src2) {
+  DCHECK(CpuHasAVXorAVX2FeatureFlag());
+  AssemblerBuffer::EnsureCapacity ensured(&buffer_);
+  bool is_twobyte_form = false;
+  uint8_t ByteZero = 0x00, ByteOne = 0x00, ByteTwo = 0x00;
+  if (!src2.NeedsRex()) {
+    is_twobyte_form = true;
+  }
+  ByteZero = EmitVexPrefixByteZero(is_twobyte_form);
+  X86_64ManagedRegister vvvv_reg =
+      X86_64ManagedRegister::FromXmmRegister(src1.AsFloatRegister());
+  if (is_twobyte_form) {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(), vvvv_reg, SET_VEX_L_128, SET_VEX_PP_66);
+  } else {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(),
+                                   /*X=*/ false,
+                                   src2.NeedsRex(),
+                                   SET_VEX_M_0F);
+    ByteTwo = EmitVexPrefixByteTwo(/*W=*/ false, vvvv_reg, SET_VEX_L_128, SET_VEX_PP_66);
+  }
+  EmitUint8(ByteZero);
+  EmitUint8(ByteOne);
+  if (!is_twobyte_form) {
+    EmitUint8(ByteTwo);
+  }
+  EmitUint8(0xF5);
+  EmitXmmRegisterOperand(dst.LowBits(), src2);
+}
+
 void X86_64Assembler::phaddw(XmmRegister dst, XmmRegister src) {
   AssemblerBuffer::EnsureCapacity ensured(&buffer_);
   EmitUint8(0x66);
@@ -3106,6 +3255,33 @@ void X86_64Assembler::shufps(XmmRegister dst, XmmRegister src, const Immediate&
   EmitUint8(imm.value());
 }
 
+void X86_64Assembler::vshufps(XmmRegister dst, XmmRegister src1, XmmRegister src2, const Immediate& imm) {
+  AssemblerBuffer::EnsureCapacity ensured(&buffer_);
+  uint8_t byte_zero = 0x00, byte_one = 0x00, byte_two = 0x00;
+  bool is_twobyte_form = false;
+  if (!src2.NeedsRex()) {
+    is_twobyte_form = true;
+  }
+  byte_zero = EmitVexPrefixByteZero(is_twobyte_form);
+  X86_64ManagedRegister vvvv_reg = X86_64ManagedRegister::FromXmmRegister(src1.AsFloatRegister());
+  if (is_twobyte_form) {
+    byte_one = EmitVexPrefixByteOne(dst.NeedsRex(), vvvv_reg, SET_VEX_L_128, SET_VEX_PP_NONE);
+  } else {
+    byte_one = EmitVexPrefixByteOne(dst.NeedsRex(),
+                                    false,
+                                    src2.NeedsRex(),
+                                    SET_VEX_M_0F);
+   byte_two = EmitVexPrefixByteTwo(false, vvvv_reg, SET_VEX_L_128, SET_VEX_PP_NONE);
+  }
+  EmitUint8(byte_zero);
+  EmitUint8(byte_one);
+  if (!is_twobyte_form) {
+    EmitUint8(byte_two);
+  }
+  EmitUint8(0xC6);
+  EmitXmmRegisterOperand(dst.LowBits(), src2);
+  EmitUint8(imm.value());
+}
 
 void X86_64Assembler::pshufd(XmmRegister dst, XmmRegister src, const Immediate& imm) {
   AssemblerBuffer::EnsureCapacity ensured(&buffer_);
@@ -3117,6 +3293,33 @@ void X86_64Assembler::pshufd(XmmRegister dst, XmmRegister src, const Immediate&
   EmitUint8(imm.value());
 }
 
+void X86_64Assembler::vunpckhpd(XmmRegister dst, XmmRegister src1, XmmRegister src2) {
+  AssemblerBuffer::EnsureCapacity ensured(&buffer_);
+  uint8_t ByteZero = 0x00, ByteOne = 0x00, ByteTwo = 0x00;
+  bool is_twobyte_form = false;
+  if (!src2.NeedsRex()) {
+    is_twobyte_form = true;
+  }
+   ByteZero = EmitVexPrefixByteZero(is_twobyte_form);
+  X86_64ManagedRegister vvvv_reg =
+      X86_64ManagedRegister::FromXmmRegister(src1.AsFloatRegister());
+  if (is_twobyte_form) {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(), vvvv_reg, SET_VEX_L_128, SET_VEX_PP_66);
+  } else {
+    ByteOne = EmitVexPrefixByteOne(dst.NeedsRex(),
+                                   /*X=*/ false,
+                                   src2.NeedsRex(),
+                                   SET_VEX_M_0F);
+    ByteTwo = EmitVexPrefixByteTwo(/*W=*/ false, vvvv_reg, SET_VEX_L_128, SET_VEX_PP_66);
+  }
+  EmitUint8(ByteZero);
+  EmitUint8(ByteOne);
+  if (!is_twobyte_form) {
+    EmitUint8(ByteTwo);
+  }
+  EmitUint8(0x15);
+  EmitXmmRegisterOperand(dst.LowBits(), src2);
+ }
 
 void X86_64Assembler::punpcklbw(XmmRegister dst, XmmRegister src) {
   AssemblerBuffer::EnsureCapacity ensured(&buffer_);
diff --git a/compiler/utils/x86_64/assembler_x86_64.h b/compiler/utils/x86_64/assembler_x86_64.h
index 100707a..b2397c9 100644
--- a/compiler/utils/x86_64/assembler_x86_64.h
+++ b/compiler/utils/x86_64/assembler_x86_64.h
@@ -420,6 +420,7 @@ class X86_64Assembler final : public Assembler {
   void movaps(const Address& dst, XmmRegister src);  // store aligned
   void movups(const Address& dst, XmmRegister src);  // store unaligned
 
+  void vmovhlps(XmmRegister dst, XmmRegister src1, XmmRegister src2);     // move
   void vmovaps(XmmRegister dst, XmmRegister src);     // move
   void vmovaps(XmmRegister dst, const Address& src);  // load aligned
   void vmovaps(const Address& dst, XmmRegister src);  // store aligned
@@ -438,6 +439,7 @@ class X86_64Assembler final : public Assembler {
   void movd(XmmRegister dst, CpuRegister src, bool is64bit);
   void movd(CpuRegister dst, XmmRegister src, bool is64bit);
 
+  void vaddss(XmmRegister dst, XmmRegister src1, XmmRegister src2);
   void addss(XmmRegister dst, XmmRegister src);
   void addss(XmmRegister dst, const Address& src);
   void subss(XmmRegister dst, XmmRegister src);
@@ -478,6 +480,8 @@ class X86_64Assembler final : public Assembler {
   void movsd(const Address& dst, XmmRegister src);
   void movsd(XmmRegister dst, XmmRegister src);
 
+  void vaddsd(XmmRegister dst, XmmRegister src1, XmmRegister src2);
+
   void addsd(XmmRegister dst, XmmRegister src);
   void addsd(XmmRegister dst, const Address& src);
   void subsd(XmmRegister dst, XmmRegister src);
@@ -584,6 +588,7 @@ class X86_64Assembler final : public Assembler {
   void xorps(XmmRegister dst, const Address& src);
   void xorps(XmmRegister dst, XmmRegister src);
   void pxor(XmmRegister dst, XmmRegister src);  // no addr variant (for now)
+  void vpxor(XmmRegister dst, XmmRegister src1, XmmRegister src2);  // no addr variant (for now)
 
   void andpd(XmmRegister dst, const Address& src);
   void andpd(XmmRegister dst, XmmRegister src);
@@ -603,6 +608,7 @@ class X86_64Assembler final : public Assembler {
   void pavgw(XmmRegister dst, XmmRegister src);
   void psadbw(XmmRegister dst, XmmRegister src);
   void pmaddwd(XmmRegister dst, XmmRegister src);
+  void vpmaddwd(XmmRegister dst, XmmRegister src1, XmmRegister src2);
   void phaddw(XmmRegister dst, XmmRegister src);
   void phaddd(XmmRegister dst, XmmRegister src);
   void haddps(XmmRegister dst, XmmRegister src);
@@ -643,6 +649,7 @@ class X86_64Assembler final : public Assembler {
 
   void shufpd(XmmRegister dst, XmmRegister src, const Immediate& imm);
   void shufps(XmmRegister dst, XmmRegister src, const Immediate& imm);
+  void vshufps(XmmRegister dst, XmmRegister src1, XmmRegister src2, const Immediate& imm);
   void pshufd(XmmRegister dst, XmmRegister src, const Immediate& imm);
 
   void punpcklbw(XmmRegister dst, XmmRegister src);
@@ -655,6 +662,8 @@ class X86_64Assembler final : public Assembler {
   void punpckhdq(XmmRegister dst, XmmRegister src);
   void punpckhqdq(XmmRegister dst, XmmRegister src);
 
+  void vunpckhpd(XmmRegister dst, XmmRegister src1, XmmRegister src2);
+
   void psllw(XmmRegister reg, const Immediate& shift_count);
   void pslld(XmmRegister reg, const Immediate& shift_count);
   void psllq(XmmRegister reg, const Immediate& shift_count);
@@ -666,7 +675,9 @@ class X86_64Assembler final : public Assembler {
   void psrlw(XmmRegister reg, const Immediate& shift_count);
   void psrld(XmmRegister reg, const Immediate& shift_count);
   void psrlq(XmmRegister reg, const Immediate& shift_count);
+  void vpsrlq(XmmRegister dst, XmmRegister src, const Immediate& shift_count);
   void psrldq(XmmRegister reg, const Immediate& shift_count);
+  void vpsrldq(XmmRegister dst, XmmRegister src, const Immediate& shift_count);
 
   void flds(const Address& src);
   void fstps(const Address& dst);
diff --git a/test/684-checker-simd-dotprod/src/Main.java b/test/684-checker-simd-dotprod/src/Main.java
index e0c8716..6dab40f 100644
--- a/test/684-checker-simd-dotprod/src/Main.java
+++ b/test/684-checker-simd-dotprod/src/Main.java
@@ -17,6 +17,7 @@
 import other.TestByte;
 import other.TestCharShort;
 import other.TestVarious;
+import other.TestFloatDouble; 
 
 /**
  * Tests for dot product idiom vectorization.
@@ -24,8 +25,23 @@ import other.TestVarious;
 public class Main {
   public static void main(String[] args) {
      TestByte.run();
-     TestCharShort.run();
+     long start_time = System.currentTimeMillis();
+     for (int i = 0; i < 10; i++ ) {
+       for (int j = 0; j < 5000; j++) {
+          TestCharShort.run();
+       }
+     }
+     long elapsed_time = System.currentTimeMillis()- start_time;
+     System.out.println("TestCharShort-imps: " + (10*5000.0)/elapsed_time);
      TestVarious.run();
+     start_time = System.currentTimeMillis();
+     for (int i = 0; i< 10; i++) {
+       for (int j = 0; j< 5000; j++) {
+         TestFloatDouble.run();
+       }
+     }
+     elapsed_time = System.currentTimeMillis()- start_time;
+     System.out.println("TestFLoatDouble-imps: " + (10*5000.0)/elapsed_time);
      System.out.println("passed");
   }
 }
diff --git a/test/684-checker-simd-dotprod/src/other/TestCharShort.java b/test/684-checker-simd-dotprod/src/other/TestCharShort.java
index 9cb9db5..25f80e3 100644
--- a/test/684-checker-simd-dotprod/src/other/TestCharShort.java
+++ b/test/684-checker-simd-dotprod/src/other/TestCharShort.java
@@ -53,10 +53,12 @@ public class TestCharShort {
     for (int i = 0; i < b.length; i++) {
       int temp = a[i] * b[i];
       s += temp;
+      //System.out.println(s);
     }
     return s - 1;
   }
 
+  
   /// CHECK-START: int other.TestCharShort.testDotProdComplex(short[], short[]) loop_optimization (before)
   /// CHECK-DAG: <<Const0:i\d+>>  IntConstant 0                                         loop:none
   /// CHECK-DAG: <<Const1:i\d+>>  IntConstant 1                                         loop:none
@@ -98,6 +100,7 @@ public class TestCharShort {
     return s - 1;
   }
 
+  
   /// CHECK-START: int other.TestCharShort.testDotProdSimpleUnsigned(char[], char[]) loop_optimization (before)
   /// CHECK-DAG: <<Const0:i\d+>>  IntConstant 0                                         loop:none
   /// CHECK-DAG: <<Const1:i\d+>>  IntConstant 1                                         loop:none
@@ -132,6 +135,7 @@ public class TestCharShort {
     return s - 1;
   }
 
+  
   /// CHECK-START: int other.TestCharShort.testDotProdComplexUnsigned(char[], char[]) loop_optimization (before)
   /// CHECK-DAG: <<Const0:i\d+>>  IntConstant 0                                         loop:none
   /// CHECK-DAG: <<Const1:i\d+>>  IntConstant 1                                         loop:none
@@ -173,6 +177,7 @@ public class TestCharShort {
     return s - 1;
   }
 
+  
   /// CHECK-START: int other.TestCharShort.testDotProdComplexUnsignedCastedToSigned(char[], char[]) loop_optimization (before)
   /// CHECK-DAG: <<Const0:i\d+>>  IntConstant 0                                         loop:none
   /// CHECK-DAG: <<Const1:i\d+>>  IntConstant 1                                         loop:none
@@ -214,6 +219,7 @@ public class TestCharShort {
     return s - 1;
   }
 
+  
   /// CHECK-START: int other.TestCharShort.testDotProdComplexSignedCastedToUnsigned(short[], short[]) loop_optimization (before)
   /// CHECK-DAG: <<Const0:i\d+>>  IntConstant 0                                         loop:none
   /// CHECK-DAG: <<Const1:i\d+>>  IntConstant 1                                         loop:none
@@ -468,6 +474,7 @@ public class TestCharShort {
     }
     return s - 1;
   }
+ 
 
   private static void expectEquals(int expected, int result) {
     if (expected != result) {
@@ -477,6 +484,7 @@ public class TestCharShort {
 
   private static void testDotProd(short[] s1, short[] s2, char[] c1, char[] c2, int[] results) {
     expectEquals(results[0], testDotProdSimple(s1, s2));
+    //System.out.println("ans is" + testDotProdSimple(s1, s2));
     expectEquals(results[1], testDotProdComplex(s1, s2));
     expectEquals(results[2], testDotProdSimpleUnsigned(c1, c2));
     expectEquals(results[3], testDotProdComplexUnsigned(c1, c2));
@@ -508,12 +516,21 @@ public class TestCharShort {
     final short MIN_S = Short.MAX_VALUE;
 
     short[] s1_1 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, MAX_S, MAX_S };
+    //short[] s1_1 = { 0, 0, MAX_S, MAX_S };
+    //short[] s2_1 = { 0, 0, MAX_S, MAX_S };
     short[] s2_1 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, MAX_S, MAX_S };
     char[]  c1_1 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, MAX_S, MAX_S };
     char[]  c2_1 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, MAX_S, MAX_S };
     int[] results_1 = { 2147352578, -2147483634, 2147352578, -2147483634, -2147483634, -2147483634,
                         2147352578, -2147418112, 2147418112, -2147418112, 2147352578,
                         2, 2, 2, 2, 2, 2, 2, 2, 2147352578, 2, 130050, 2, 130050, 2147352578 };
+    /*expectEquals(results_1[0], testDotProdSimple(s1_1, s2_1));
+    expectEquals(results_1[1], testDotProdComplex(s1_1, s2_1));
+    expectEquals(results_1[2], testDotProdSimpleUnsigned(c1_1, c2_1));
+    expectEquals(results_1[3], testDotProdComplexUnsigned(c1_1, c2_1));
+    expectEquals(results_1[4], testDotProdComplexUnsignedCastedToSigned(c1_1, c2_1));
+    expectEquals(results_1[5], testDotProdComplexSignedCastedToUnsigned(s1_1, s2_1));
+    expectEquals(results_1[6], testDotProdSignedToInt(s1_1, s2_1));*/
     testDotProd(s1_1, s2_1, c1_1, c2_1, results_1);
 
     short[] s1_2 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, MAX_S, MAX_S, MAX_S, MAX_S };
diff --git a/test/684-checker-simd-dotprod/src/other/TestFloatDouble.java b/test/684-checker-simd-dotprod/src/other/TestFloatDouble.java
new file mode 100644
index 0000000..f7270e0
--- /dev/null
+++ b/test/684-checker-simd-dotprod/src/other/TestFloatDouble.java
@@ -0,0 +1,81 @@
+/*
+ * Copyright (C) 2018 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package other;
+
+/**
+ * Tests for dot product idiom vectorization: char and short case.
+ */
+public class TestFloatDouble {
+
+  public static final int ARRAY_SIZE = 1024;
+
+  public static final float testDotProdSimpleFloat(float[] a, float[] b) {
+    float sum = 0;
+    for (int i = 0; i < b.length; i++) {
+      sum += a[i] * b[i];
+    }
+    return sum;
+  }
+
+  public static final double testDotProdSimpleDouble(double[] a, double[] b) {
+    double sum = 0;
+    for (int i = 0; i < b.length; i++) {
+      sum += a[i] * b[i];
+    }
+    return sum;
+  }
+
+  private static void expectEquals(float expected, float result) {
+    if (Float.compare(expected, result) != 0) {
+      throw new Error("Expected: " + expected + ", found: " + result);
+    }
+  }
+
+  private static void expectEquals(double expected, double result) {
+    if (Double.compare(expected, result) != 0) {
+      throw new Error("Expected: " + expected + ", found: " + result);
+    }
+  }
+
+  public static void run() {
+    final float MAX_F = Float.MAX_VALUE;
+    final float MIN_F = Float.MIN_VALUE;
+    final double MAX_D = Double.MAX_VALUE;
+    final double MIN_D = Double.MIN_VALUE;
+
+    float[] f1_1 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.33f, 0.125f, 3.0f, 0.25f};
+    float[] f2_1 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6.125f, 2.25f, 1.213f, 0.5f};
+    expectEquals(24.4415f, testDotProdSimpleFloat(f1_1, f2_1));
+    
+    float [] f1_2 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0.63671875f, 0.76953125f, 0.22265625f, 1.0f};
+    float [] f2_2 = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, MIN_F, MAX_F, MAX_F, MIN_F };
+    expectEquals(3.376239E38f, testDotProdSimpleFloat(f1_2, f2_2));
+
+    float[] f1_3 = { 0xc0000000, 0xc015c28f, 0x411dd42c, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, MIN_F, MIN_F };
+    float[] f2_3 = { 0x3f4c779a, 0x408820c5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x00000000, 0, MAX_F, MAX_F };
+    expectEquals(-2.30124471E18f, testDotProdSimpleFloat(f1_3, f2_3));
+
+    /*double[] f1_3 = { 0xc0000000, 0xc015c28f, 0x411dd42c, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, MIN_F, MIN_F };
+    double[] f2_3 = { 0x3f4c779a, 0x408820c5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x00000000, 0, MAX_F, MAX_F };
+    expectEquals(-2.30124471E18f, testDotProdSimpleFloat(f1_3, f2_3));*/
+
+  }
+
+  public static void main(String[] args) {
+    run();
+  }
+}
-- 
1.9.1

