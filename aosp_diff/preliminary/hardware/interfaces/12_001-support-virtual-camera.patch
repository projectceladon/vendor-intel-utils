From 9aa2b67e570c99f93f5dd718bac7b68a3a087b08 Mon Sep 17 00:00:00 2001
From: shivasku82 <shiva.kumara.rudrappa@intel.com>
Date: Wed, 23 Aug 2023 18:50:36 +0530
Subject: [PATCH] support virtual camera device

Signed-off-by: shivasku82 <shiva.kumara.rudrappa@intel.com>
---
 camera/device/3.4/default/Android.bp          |  113 +
 .../3.4/default/ExternalCameraDevice.cpp      |    8 +-
 .../3.4/default/UnitTest/NetlinkCmdTest.cpp   |   61 +
 .../device/3.4/default/UnitTest/Unitest.cpp   |   38 +
 camera/device/3.4/default/UnitTest/Unitest.h  |   25 +
 .../device/3.4/default/UnitTest/V4L2Test.cpp  |   84 +
 .../default/UnitTest/VirtualCameraTest.cpp    |   74 +
 .../3.4/default/Virtual/CaptureManager.cpp    |  344 +++
 .../3.4/default/Virtual/IVICameraUtils.cpp    |  871 ++++++
 .../3.4/default/Virtual/LoopbackListener.cpp  |  398 +++
 .../3.4/default/Virtual/MediaControl.cpp      |  799 ++++++
 .../3.4/default/Virtual/NetlinkUtil.cpp       |  176 ++
 .../device/3.4/default/Virtual/NodeInfo.cpp   |   57 +
 camera/device/3.4/default/Virtual/SysCall.cpp |  171 ++
 .../3.4/default/Virtual/V4L2CameraDevice.cpp  |  440 +++
 .../default/Virtual/VirtualCameraDevice.cpp   | 1024 +++++++
 .../Virtual/VirtualCameraDeviceSession.cpp    | 2465 +++++++++++++++++
 .../default/Virtual/VirtualCameraManager.cpp  |  128 +
 .../ExternalCameraUtils.h                     |    3 +-
 .../ivi_device_v3_4_impl/CaptureManager.h     |  123 +
 .../ivi_device_v3_4_impl/IVICameraUtils.h     |   21 +
 .../ivi_device_v3_4_impl/LoopbackListener.h   |  181 ++
 .../ivi_device_v3_4_impl/MediaControl.h       |  249 ++
 .../ivi_device_v3_4_impl/NetlinkUtil.h        |   56 +
 .../include/ivi_device_v3_4_impl/NodeInfo.h   |   51 +
 .../include/ivi_device_v3_4_impl/SysCall.h    |   81 +
 .../ivi_device_v3_4_impl/V4L2CameraDevice.h   |  164 ++
 .../VirtualCameraDevice.h                     |  291 ++
 .../VirtualCameraDeviceSession.h              |  441 +++
 .../VirtualCameraManager.h                    |   93 +
 .../ivi_device_v3_4_impl/v4l2-subdev.h        |  171 ++
 camera/provider/2.4/default/Android.bp        |   88 +
 .../2.4/default/CameraProvider_2_4.cpp        |    5 +
 .../2.4/default/IVICameraProviderImpl_2_4.cpp |  378 +++
 .../2.4/default/IVICameraProviderImpl_2_4.h   |  122 +
 ...ardware.camera.provider@2.4-ivi-service.rc |    8 +
 camera/provider/2.4/default/ivi-service.cpp   |   34 +
 37 files changed, 9830 insertions(+), 6 deletions(-)
 create mode 100644 camera/device/3.4/default/UnitTest/NetlinkCmdTest.cpp
 create mode 100644 camera/device/3.4/default/UnitTest/Unitest.cpp
 create mode 100644 camera/device/3.4/default/UnitTest/Unitest.h
 create mode 100644 camera/device/3.4/default/UnitTest/V4L2Test.cpp
 create mode 100644 camera/device/3.4/default/UnitTest/VirtualCameraTest.cpp
 create mode 100644 camera/device/3.4/default/Virtual/CaptureManager.cpp
 create mode 100644 camera/device/3.4/default/Virtual/IVICameraUtils.cpp
 create mode 100644 camera/device/3.4/default/Virtual/LoopbackListener.cpp
 create mode 100644 camera/device/3.4/default/Virtual/MediaControl.cpp
 create mode 100644 camera/device/3.4/default/Virtual/NetlinkUtil.cpp
 create mode 100644 camera/device/3.4/default/Virtual/NodeInfo.cpp
 create mode 100644 camera/device/3.4/default/Virtual/SysCall.cpp
 create mode 100644 camera/device/3.4/default/Virtual/V4L2CameraDevice.cpp
 create mode 100644 camera/device/3.4/default/Virtual/VirtualCameraDevice.cpp
 create mode 100644 camera/device/3.4/default/Virtual/VirtualCameraDeviceSession.cpp
 create mode 100644 camera/device/3.4/default/Virtual/VirtualCameraManager.cpp
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/CaptureManager.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/IVICameraUtils.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/LoopbackListener.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/MediaControl.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/NetlinkUtil.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/NodeInfo.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/SysCall.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/V4L2CameraDevice.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraDevice.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraDeviceSession.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraManager.h
 create mode 100644 camera/device/3.4/default/include/ivi_device_v3_4_impl/v4l2-subdev.h
 create mode 100644 camera/provider/2.4/default/IVICameraProviderImpl_2_4.cpp
 create mode 100644 camera/provider/2.4/default/IVICameraProviderImpl_2_4.h
 create mode 100644 camera/provider/2.4/default/android.hardware.camera.provider@2.4-ivi-service.rc
 create mode 100644 camera/provider/2.4/default/ivi-service.cpp

diff --git a/camera/device/3.4/default/Android.bp b/camera/device/3.4/default/Android.bp
index 9f0c77739..7bd8c175f 100644
--- a/camera/device/3.4/default/Android.bp
+++ b/camera/device/3.4/default/Android.bp
@@ -35,6 +35,12 @@ cc_library_headers {
     export_include_dirs: ["include/ext_device_v3_4_impl"],
 }
 
+cc_library_headers {
+    name: "camera.device@3.4-ivi-impl_headers",
+    vendor: true,
+    export_include_dirs: ["include/ivi_device_v3_4_impl"],
+}
+
 cc_library_shared {
     name: "camera.device@3.4-impl",
     defaults: ["hidl_defaults"],
@@ -115,3 +121,110 @@ cc_library_shared {
         "libfmq",
     ],
 }
+
+cc_library_shared {
+    name: "camera.device@3.4-ivi-impl",
+    defaults: ["hidl_defaults"],
+    proprietary: true,
+    vendor: true,
+    srcs: [
+        "Virtual/VirtualCameraDevice.cpp",
+        "Virtual/VirtualCameraDeviceSession.cpp",
+        "Virtual/VirtualCameraManager.cpp",
+        "Virtual/V4L2CameraDevice.cpp",
+        "Virtual/CaptureManager.cpp",
+        "Virtual/IVICameraUtils.cpp",
+        "Virtual/MediaControl.cpp",
+        "Virtual/NodeInfo.cpp",
+        "Virtual/SysCall.cpp",
+        "Virtual/NetlinkUtil.cpp",
+        "Virtual/LoopbackListener.cpp",
+    ],
+    shared_libs: [
+        "libhidlbase",
+        "libutils",
+        "libcutils",
+        "camera.device@3.2-impl",
+        "camera.device@3.3-impl",
+        "android.hardware.camera.device@3.2",
+        "android.hardware.camera.device@3.3",
+        "android.hardware.camera.device@3.4",
+        "android.hardware.camera.provider@2.4",
+        "android.hardware.graphics.mapper@2.0",
+        "android.hardware.graphics.mapper@3.0",
+        "android.hardware.graphics.mapper@4.0",
+        "liblog",
+        "libgralloctypes",
+        "libhardware",
+        "libcamera_metadata",
+        "libfmq",
+        "libsync",
+        "libyuv",
+        "libjpeg",
+        "libexif",
+        "libtinyxml2",
+    ],
+    static_libs: [
+        "android.hardware.camera.common@1.0-helper",
+    ],
+    local_include_dirs: ["include/ivi_device_v3_4_impl"],
+    export_shared_lib_headers: [
+        "libfmq",
+    ],
+}
+
+cc_binary {
+    name: "camera_test",
+    defaults: ["hidl_defaults"],
+    proprietary: true,
+    vendor: true,
+    srcs: [
+        // "VirtualCameraDevice.cpp",
+        // "VirtualCameraDeviceSession.cpp",
+        // "VirtualCameraManager.cpp",
+        // "V4L2CameraDevice.cpp",
+        // "CaptureManager.cpp",
+        // "IVICameraUtils.cpp",
+        // "MediaControl.cpp",
+        // "NodeInfo.cpp",
+        // "SysCall.cpp",
+        // "NetlinkUtil.cpp",
+        // "LoopbackListener.cpp",
+        "UnitTest/Unitest.cpp",
+        "UnitTest/V4L2Test.cpp",
+        "UnitTest/VirtualCameraTest.cpp",
+        "UnitTest/NetlinkCmdTest.cpp",
+    ],
+    shared_libs: [
+        "libhidlbase",
+        "libutils",
+        "libcutils",
+        "camera.device@3.2-impl",
+        "camera.device@3.3-impl",
+        "camera.device@3.4-ivi-impl",
+        "android.hardware.camera.device@3.2",
+        "android.hardware.camera.device@3.3",
+        "android.hardware.camera.device@3.4",
+        "android.hardware.camera.provider@2.4",
+        "android.hardware.graphics.mapper@2.0",
+        "android.hardware.graphics.mapper@3.0",
+        "android.hardware.graphics.mapper@4.0",
+        "liblog",
+        "libgralloctypes",
+        "libhardware",
+        "libcamera_metadata",
+        "libfmq",
+        "libsync",
+        "libyuv",
+        "libjpeg",
+        "libexif",
+        "libtinyxml2",
+    ],
+    static_libs: [
+        "android.hardware.camera.common@1.0-helper",
+    ],
+    local_include_dirs: ["include/ivi_device_v3_4_impl"],
+    export_shared_lib_headers: [
+        "libfmq",
+    ],
+}
diff --git a/camera/device/3.4/default/ExternalCameraDevice.cpp b/camera/device/3.4/default/ExternalCameraDevice.cpp
index 6cd5fdf4f..677b49632 100644
--- a/camera/device/3.4/default/ExternalCameraDevice.cpp
+++ b/camera/device/3.4/default/ExternalCameraDevice.cpp
@@ -946,11 +946,9 @@ void ExternalCameraDevice::updateFpsBounds(
     }
 
     getFrameRateList(fd, fpsUpperBound, &format);
-    // HAL tries to support even if the Camera sensor retuns
-    // empty supported frame rate list. This will help to
-    // support different types of Cameras since some
-    // USB Cameras will not return the proper frame rates.
-    outFmts.push_back(format);
+    if (!format.frameRates.empty()) {
+        outFmts.push_back(format);
+    }
 }
 
 void ExternalCameraDevice::initSupportedFormatsLocked(int fd) {
diff --git a/camera/device/3.4/default/UnitTest/NetlinkCmdTest.cpp b/camera/device/3.4/default/UnitTest/NetlinkCmdTest.cpp
new file mode 100644
index 000000000..47b2c3e17
--- /dev/null
+++ b/camera/device/3.4/default/UnitTest/NetlinkCmdTest.cpp
@@ -0,0 +1,61 @@
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+#include <sys/socket.h>
+#include <linux/netlink.h>
+
+#define MYMGRP 22
+
+int testNetlinkCmd() {
+    struct nlmsghdr nlh;
+    struct sockaddr_nl sa;
+    struct msghdr msg;
+    struct iovec iov[2];
+    char buffer[4096];
+
+    int nlSock = socket(AF_NETLINK, SOCK_RAW, NETLINK_USERSOCK);
+    if (nlSock < 0) {
+        perror("socket");
+        return 1;
+    }
+
+    memset(&sa, 0, sizeof(sa));
+    sa.nl_family = AF_NETLINK;
+    sa.nl_groups = (1 << (MYMGRP - 1)); // Set the multicast group for subscription
+
+    if (bind(nlSock, (struct sockaddr *)&sa, sizeof(sa)) < 0) {
+        perror("bind");
+        close(nlSock);
+        return 1;
+    }
+
+    // iov[0].iov_base = buffer;
+    // iov[0].iov_len = sizeof(buffer);
+    iov[0].iov_base = (void *)&nlh;
+    iov[0].iov_len = sizeof(nlh);
+    iov[1].iov_base = (void *)buffer;
+    iov[1].iov_len = sizeof(buffer);
+
+    memset(&msg, 0, sizeof(msg));
+    msg.msg_name = &sa;
+    msg.msg_namelen = sizeof(sa);
+    msg.msg_iov = iov;
+    msg.msg_iovlen = sizeof(iov) / sizeof(iov[0]);
+
+    while (1) {
+        ssize_t len = recvmsg(nlSock, &msg, 0);
+        if (len < 0) {
+            perror("recvmsg");
+            close(nlSock);
+            return 1;
+        }
+
+        // Process received message (contained in 'buffer')
+         printf("Received message: %s\n", (char *)msg.msg_iov[0].iov_base);
+        printf("Received message: %s\n", (char *)msg.msg_iov[1].iov_base);
+    }
+
+    close(nlSock);
+    return 0;
+}
diff --git a/camera/device/3.4/default/UnitTest/Unitest.cpp b/camera/device/3.4/default/UnitTest/Unitest.cpp
new file mode 100644
index 000000000..8ceaee8a0
--- /dev/null
+++ b/camera/device/3.4/default/UnitTest/Unitest.cpp
@@ -0,0 +1,38 @@
+#include "Unitest.h"
+
+// int testOneVirtualCamera(const std::string& virtId)
+// {
+//     sp<VirtualCameraDevice> virtCam = getVirtCamById(virtId);
+//     if (virtCam == nullptr) {
+//         ALOGE("No available virtual camera with id %s", virtId.c_str());
+//         return -1;
+//     }
+
+//     return 0;
+// }
+
+// int testVirtualCamera(sp<CaptureManager> cm)
+// {
+//     std::vector<std::string> virtualIds = cm->getAllVirtualCameraIds();
+//     if (virtualIds.size() == 0) {
+//         ALOGE("No virtual cameras.");
+//         return -1;
+//     }
+
+//     if (testVirtualCamera(virtualIds[0]) != 0) {
+//         ALOGE("testVirtualCamera %s failed.", virtualIds[0].c_str());
+//         return -1;
+//     }
+// }
+
+int main() {
+    // testVirtualCamera();
+    // CaptureManager* cm = CaptureManager::getInstance();
+    // cm->initialize();
+    // cm->printMyself();
+    // while (true) {
+    //     sleep(10);
+    // }
+    testNetlinkCmd();
+    return 0;
+}
\ No newline at end of file
diff --git a/camera/device/3.4/default/UnitTest/Unitest.h b/camera/device/3.4/default/UnitTest/Unitest.h
new file mode 100644
index 000000000..add63a06d
--- /dev/null
+++ b/camera/device/3.4/default/UnitTest/Unitest.h
@@ -0,0 +1,25 @@
+#ifndef V4L2_TEST_H
+#define V4L2_TEST_H
+
+#include "android-base/macros.h"
+
+#include "CaptureManager.h"
+#include "V4L2CameraDevice.h"
+#include "VirtualCameraDevice.h"
+
+using ::android::sp;
+using ::android::hardware::camera::device::V3_4::implementation::CaptureManager;
+using ::android::hardware::camera::device::V3_4::implementation::FrameBuffer;
+using ::android::hardware::camera::device::V3_4::implementation::VirtualCameraDevice;
+
+#include <string>
+void save_image(unsigned char* data, int data_size);
+int testOneV4L2Camera(const std::string& virtId, sp<CaptureManager> cm);
+int testAllV4L2Cameras(sp<CaptureManager> cm);
+int testV4L2();
+
+int testOneVirtualCamera(const std::string& cameraId, sp<CaptureManager> cm);
+int testVirtualCamera();
+int testNetlinkCmd();
+
+#endif
\ No newline at end of file
diff --git a/camera/device/3.4/default/UnitTest/V4L2Test.cpp b/camera/device/3.4/default/UnitTest/V4L2Test.cpp
new file mode 100644
index 000000000..145d746be
--- /dev/null
+++ b/camera/device/3.4/default/UnitTest/V4L2Test.cpp
@@ -0,0 +1,84 @@
+#include "Unitest.h"
+
+void save_image(unsigned char* data, int data_size) {
+    char filename[32];
+    FILE* tmpfd;
+    static int ctr = 0;
+    // uint32_t row;
+
+    sprintf(filename, "/data/imgs/img%03d.ppm", ++ctr);
+
+    tmpfd = fopen(filename, "w");
+    if (!tmpfd) {
+        ALOGE("cannot write file %s %d", filename, data_size);
+        return;
+    }
+    fwrite(data, data_size, 1, tmpfd);
+
+    fclose(tmpfd);
+    ALOGI("Written to output file %s.\n", filename);
+}
+
+int testOneV4L2Camera(const std::string& virtId, sp<CaptureManager> cm) {
+    ALOGI("%s: ----------Test CameraId %s-------------", __FUNCTION__, virtId.c_str());
+    sp<FrameBuffer> buf = new FrameBuffer();
+    buf->mFourcc = V4L2_PIX_FMT_UYVY;
+    buf->mDataSize = buf->mWidth * buf->mHeight * 2 + buf->mWidth * 2;
+    ALOGI("%s: alloc buffer size %d", __FUNCTION__, buf->mDataSize);
+    buf->mData = new uint8_t[buf->mDataSize];
+
+    if (cm->openRequest(virtId) < 0) {
+        ALOGE("openRequest %s failed.", virtId.c_str());
+        return -1;
+    }
+
+    for (int i = 0; i < 5; i++) {
+        ALOGI("enqueueRequest the frame buffer.");
+        if (cm->enqueueRequest(virtId, buf)) {
+            ALOGE("cannot register frame buffer of %s failed.", virtId.c_str());
+            return -1;
+        }
+        ALOGI("Get the frame buffer.");
+        cm->dequeueRequest(buf);
+        if (buf->mData == nullptr) {
+            ALOGE("error to fetch buffer from v4l2 camera.");
+            return -1;
+        }
+        ALOGI("%s: get the frame.", __FUNCTION__);
+        save_image(buf->mData, buf->mDataSize);
+    }
+
+    cm->closeRequest(virtId);
+    ALOGI("%s: ----------Test CameraId %s Done-------", __FUNCTION__, virtId.c_str());
+
+    return 0;
+}
+
+int testAllV4L2Cameras(sp<CaptureManager> cm) {
+    std::vector<std::string> vcamids;
+    cm->getAllVirtualCameraIds(vcamids);
+
+    for (auto i : vcamids) {
+        testOneV4L2Camera(i, cm);
+    }
+    return 0;
+}
+
+int testV4L2()
+{
+    sp<CaptureManager> cm = CaptureManager::getInstance();
+    if (cm == nullptr) {
+        ALOGE("Cannot alloc capture manager.");
+        return -1;
+    }
+    if (cm->initialize() != 0) {
+        ALOGE("Cannot init capture manager.");
+        return -1;
+    }
+
+    cm->printMyself();
+
+    testAllV4L2Cameras(cm);
+
+    return 0;
+}
\ No newline at end of file
diff --git a/camera/device/3.4/default/UnitTest/VirtualCameraTest.cpp b/camera/device/3.4/default/UnitTest/VirtualCameraTest.cpp
new file mode 100644
index 000000000..f4ce6a39b
--- /dev/null
+++ b/camera/device/3.4/default/UnitTest/VirtualCameraTest.cpp
@@ -0,0 +1,74 @@
+#include "Unitest.h"
+
+void save_image(const std::string& prefix, unsigned char* data, int data_size) {
+    char filename[32];
+    FILE* tmpfd;
+    static int ctr = 0;
+    // uint32_t row;
+
+    sprintf(filename, "/data/%s/img%03d.ppm", prefix.c_str(), ++ctr);
+
+    tmpfd = fopen(filename, "w");
+    if (!tmpfd) {
+        ALOGE("cannot write file %s %d", filename, data_size);
+        return;
+    }
+    fwrite(data, data_size, 1, tmpfd);
+
+    fclose(tmpfd);
+    ALOGI("Written to output file %s.\n", filename);
+}
+
+int testOneVirtualCamera(const std::string& cameraId, sp<CaptureManager> cm)
+{
+    ALOGI("Test Virtual Camera %s. CaptureManager here only provides VirtualCameraDevice object.", cameraId.c_str());
+    std::vector<std::string> virtCamIds;
+    cm->getAllVirtualCameraIds(virtCamIds);
+    for (auto id : virtCamIds) {
+        ALOGI("VirtCamId: %s", id.c_str());
+    }
+    sp<VirtualCameraDevice> virtCam = cm->getVirtualCamera(cameraId);
+
+    virtCam->open();
+    virtCam->configureStream();
+    
+    sp<FrameBuffer> buf = new FrameBuffer();
+    buf->mFourcc = V4L2_PIX_FMT_UYVY;
+    buf->mDataSize = buf->mWidth * buf->mHeight * 2 + buf->mWidth * 2;
+    ALOGI("%s: alloc buffer size %d", __FUNCTION__, buf->mDataSize);
+
+    for (int i = 0; i < 5; i++) {
+        if (virtCam->enqueueFrame(buf)) {
+            ALOGE("cannot register frame buffer of %s failed.", cameraId.c_str());
+            return -1;
+        }
+        ALOGI("Get the frame buffer.");
+        virtCam->dequeueFrame(buf);
+        if (buf->mData == nullptr) {
+            ALOGE("error to fetch buffer from v4l2 camera.");
+            return -1;
+        }
+        ALOGI("%s: get the frame.", __FUNCTION__);
+        save_image("virtcam", buf->mData, buf->mDataSize);
+    }
+    virtCam->close();
+
+    return 0;
+}
+
+int testVirtualCamera()
+{
+    sp<CaptureManager> cm = CaptureManager::getInstance();
+    if (cm == nullptr) {
+        ALOGE("Cannot alloc capture manager.");
+        return -1;
+    }
+    if (cm->initialize() != 0) {
+        ALOGE("Cannot init capture manager.");
+        return -1;
+    }
+
+    testOneVirtualCamera("10", cm);
+
+    return 0;
+}
\ No newline at end of file
diff --git a/camera/device/3.4/default/Virtual/CaptureManager.cpp b/camera/device/3.4/default/Virtual/CaptureManager.cpp
new file mode 100644
index 000000000..bb347df8f
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/CaptureManager.cpp
@@ -0,0 +1,344 @@
+#define LOG_TAG "IVICameraDevManager@3.4"
+
+#include <log/log.h>
+#include <algorithm>
+#include <regex>
+#include <vector>
+
+#include <sys/types.h>
+#include <dirent.h>
+#include <linux/videodev2.h>
+
+#include "MediaControl.h"
+#include "CaptureManager.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+const int kMaxDevicePathLen = 256;
+const std::string kVirtualLoopbackId = "50";
+const std::string kDevicePath="/dev/";
+constexpr char kPrefix[] = "video";
+constexpr int kPrefixLen = sizeof(kPrefix) - 1;
+// constexpr int kDevicePrefixLen = sizeof(kDevicePath) + kPrefixLen + 1;
+
+const int kMaxV4L2Devices = 16;
+//Hard code here, TODO: use config file to define.
+const int kDeviceCounters[kMaxV4L2Devices] = {
+            3, 1, 1, 1,
+            1, 1, 1, 1,
+            1, 1, 1, 1,
+            1, 1, 1, 1};
+
+CaptureManager *CaptureManager::mInstance = nullptr;
+VirtualCameraManager *CaptureManager::mVirtManager = nullptr;
+int CaptureManager::mRefcount = 0;
+
+bool compareCameraId(const sp<V4L2CameraDevice> dev1, const sp<V4L2CameraDevice> dev2)
+{
+    return dev1->getCameraId() < dev2->getCameraId();
+}
+
+int CaptureManager::initialize()
+{
+    Mutex::Autolock _l(mLock);
+    if (mInitialized == true) {
+        return 0;
+    }
+    
+    if (mVirtManager->isInitialized() == false) {
+        ALOGW("%s: virtual camera manager is not initialized.", __FUNCTION__);
+        if (mVirtManager->initialize() == 0) {
+            ALOGW("%s: failed to intialize virtual camera manager", __FUNCTION__);
+            return -1;
+        }
+    }
+
+    // Construct the topology of mipi sensor.
+    ALOGI("%s: MediaControl initializing.", __FUNCTION__);
+    MediaControl* mc = MediaControl::getInstance();
+    if (mc != nullptr) {
+        ALOGI("MediaControl setting: initEntities.");
+        mc->initEntities();
+        mc->resetAllRoutes();
+        mc->createLink();
+    }
+
+    DIR* devdir = opendir(kDevicePath.c_str());
+    if(devdir == 0) {
+        ALOGE("%s: cannot open %s! Exit.", __FUNCTION__, kDevicePath.c_str());
+        return -1;
+    }
+
+    std::vector<sp<V4L2CameraDevice>> v4l2Devices;
+    std::string loopbackPath = "";
+    struct dirent* de;
+    while ((de = readdir(devdir)) != 0) {
+        // Find external v4l devices that's existing before we start watching and add them
+        if (!strncmp(kPrefix, de->d_name, kPrefixLen)) {
+            // TODO: This might reject some valid devices. Ex: internal is 33 and a device named 3
+            //       is added.
+            // std::string deviceId(de->d_name + kPrefixLen);
+            char v4l2DevicePath[kMaxDevicePathLen];
+            snprintf(v4l2DevicePath, kMaxDevicePathLen, "%s%s", kDevicePath.c_str(), de->d_name);
+            ALOGI("V4L device %s found", de->d_name);
+            if (LoopbackDevice::isLoopbackDevice(v4l2DevicePath) == true) {
+                ALOGI("%s: %s is loopback device, skip it...", __FUNCTION__, v4l2DevicePath);
+                loopbackPath = v4l2DevicePath;
+                continue;
+            }
+            sp<V4L2CameraDevice> pDev = new V4L2CameraDevice(v4l2DevicePath);
+            if (pDev == nullptr) {
+                ALOGI("%s: Memory error: Cannot create a device object.", __FUNCTION__);
+                return -2;
+            }
+            v4l2Devices.push_back(pDev);
+            //callback function to update availability of virtual camera device to framework
+        }
+    }
+    closedir(devdir);
+
+    if (v4l2Devices.size() == 0) {
+        ALOGE("%s: No available v4l2 devices under /dev. QUIT.", __FUNCTION__);
+        return -1;
+    }
+    std::sort(v4l2Devices.begin(), v4l2Devices.end(), compareCameraId);
+
+    // sp<VirtualCameraDevice> loopbackDedicated = nullptr;
+    for (int i = 0; i < kMaxV4L2Devices && i < v4l2Devices.size(); i++) {
+        DeviceMapper item;
+        item.mV4L2Device = v4l2Devices[i];
+        //alloc in session, not in initialization.
+        for (int j = 0; j < kDeviceCounters[i]; j++) {
+            sp<VirtualCameraDevice> virtCam = mVirtManager->allocVirtCam();
+            if (virtCam == nullptr) {
+                ALOGE("%s: No more free virtual camera device for v4l2 camera %s", __FUNCTION__, v4l2Devices[i]->getCameraId().c_str());
+            }
+            item.mVirtualDevices[virtCam->getCameraId()] = virtCam;
+
+            std::string deviceName;
+            deviceName = std::string("device@3.4/ivi/") + virtCam->getCameraId();
+            mCameraStatusMap[deviceName] = CameraDeviceStatus::PRESENT;
+        }
+        mMappers[item.mV4L2Device->getCameraId()] = item;
+    }
+
+    if (loopbackPath.empty() != true) {
+        ALOGI("Start up LicCamAgent...");
+        mLicCamAgent = new LicCamAgent();
+        if (mLicCamAgent == nullptr) {
+            ALOGE("%s: failed to create LicCamAgent.", __FUNCTION__);
+            return -1;
+        }
+
+        //bind virtual loopback and loopback device.
+        mVirtManager->createVirtualLoopback(kVirtualLoopbackId);
+        sp<VirtualCameraDevice> virtualLoopback = mVirtManager->getVirtualLoopback();
+        if (virtualLoopback == nullptr) {
+            ALOGE("%s: failed to get virtual loopback %s", __FUNCTION__, kVirtualLoopbackId.c_str());
+        } else {
+            mVirtualLoopMapper.mV4L2Device = v4l2Devices[0];
+            mVirtualLoopMapper.mVirtualDevices[kVirtualLoopbackId] = virtualLoopback;
+            ALOGD("%s kVirtualLoopbackId=%s",
+                __FUNCTION__, kVirtualLoopbackId.c_str());
+        }
+
+        if (mLicCamAgent->initialize(virtualLoopback, loopbackPath) != 0) {
+            ALOGE("%s: failed to initialize LicCamAgent.", __FUNCTION__);
+            return -1;
+        }
+    }
+    mInitialized = true;
+
+    return 0;
+}
+
+sp<VirtualCameraDevice> CaptureManager::getVirtualCamera(const std::string& vid)
+{
+    if (vid == kVirtualLoopbackId)
+        return mVirtualLoopMapper.mVirtualDevices[vid];
+
+    return mVirtManager->getVirtCamByID(vid);
+}
+
+int CaptureManager::getVirtualLoopbackId(std::string& id)
+{
+    id = mVirtualLoopMapper.mVirtualDevices.begin()->first;
+    return 0;
+}
+
+int CaptureManager::getAllV4L2CameraIds(std::vector<std::string>& ids)
+{
+    for (auto iter : mMappers) {
+        ids.push_back(iter.first);
+    }
+    return ids.size();
+}
+
+int CaptureManager::getAllVirtualCameraIds(std::vector<std::string>& ids)
+{
+    return mVirtManager->getVirtCamIDs(ids);
+}
+
+sp<V4L2CameraDevice> CaptureManager::getV4L2Camera(const std::string& id)
+{
+    auto iter = mMappers.find(id);
+    return (iter == mMappers.end()) ? nullptr : mMappers[id].mV4L2Device;
+}
+
+sp<V4L2CameraDevice> CaptureManager::getV4L2CameraByVirtID(const std::string& vid)
+{
+    sp<V4L2CameraDevice> dev = nullptr;
+    for (auto mapEntity : mMappers) {
+        ALOGV("%s: %s", __FUNCTION__, mapEntity.first.c_str());
+        if (mapEntity.second.mVirtualDevices.find(vid) != mapEntity.second.mVirtualDevices.end()) {
+            dev = mapEntity.second.mV4L2Device;
+            break;
+        }
+    }
+
+    return dev;
+}
+
+void CaptureManager::printMyself()
+{
+    ALOGI("%s:", __FUNCTION__);
+    sp<VirtualCameraDevice> vc = getFirstVirtualDevice();
+    ALOGI("GetFirstVirtualDevice: %s", vc->getCameraId().c_str());
+    ALOGI("Total physical devices: %u", (uint32_t)mMappers.size());
+    for (auto iter : mMappers) {
+        ALOGI("Physical cameraId %s -->", iter.first.c_str());
+        for (auto m : iter.second.mVirtualDevices) {
+            ALOGI(" Virtual ID %s", m.second->getCameraId().c_str());
+        }
+    }
+}
+
+int CaptureManager::openRequest(const std::string& vcameraId)
+{
+    int ret = -1;
+    ALOGD("%s: %s", __FUNCTION__, vcameraId.c_str());
+    Mutex::Autolock _l(mLock);
+    // if (isValidVirtualCamera(vcameraId) == false) {
+    //     ALOGE("%s: Invalid virtual camera %s", __FUNCTION__, vcameraId.c_str());
+    //     return -1;
+    // }
+    sp<V4L2CameraDevice> v4l2Cam = nullptr;
+
+    if ( vcameraId == kVirtualLoopbackId) {
+        v4l2Cam = mVirtualLoopMapper.mV4L2Device;
+    } else {
+        v4l2Cam = getV4L2CameraByVirtID(vcameraId);
+    }
+
+    if (v4l2Cam != nullptr) {
+        ret = v4l2Cam->openDev();
+    } else {
+        ALOGE("cannot find the binding v4l2camera.");
+    }
+    return ret;
+}
+
+int CaptureManager::closeRequest(const std::string& vcameraId)
+{
+    //Do not delete mPollingThread, which should be released by ~V4L2CameraDevice()
+    int ret = -1;
+    // Mutex::Autolock _l(mLock);
+    // if (isValidVirtualCamera(vcameraId) == false) {
+    //     ALOGE("%s: Invalid virtual camera %s", __FUNCTION__, vcameraId.c_str());
+    //     return -1;
+    // }
+    sp<V4L2CameraDevice> v4l2Cam = nullptr;
+
+    if (vcameraId == kVirtualLoopbackId) {
+        v4l2Cam = mVirtualLoopMapper.mV4L2Device;
+    } else {
+        v4l2Cam = getV4L2CameraByVirtID(vcameraId);
+    }
+
+    if (v4l2Cam != nullptr) {
+        ret = v4l2Cam->closeDev();
+    }
+
+    return ret;
+}
+
+int CaptureManager::configureRequest(const std::string& vcameraId)
+{
+    Mutex::Autolock _l(mLock);
+    ALOGD("%s: for camera %s", __FUNCTION__, vcameraId.c_str());
+    // physical camera do not need to do configuration by request.
+    
+    sp<V4L2CameraDevice> v4l2Cam = getV4L2CameraByVirtID(vcameraId);
+    if (v4l2Cam != nullptr) {
+        if(v4l2Cam->configureDev() != 0) {
+            ALOGE("%s: fail to configureDev %s", __FUNCTION__, vcameraId.c_str());
+            return -1;
+        }
+    }
+    return 0;
+}
+
+int CaptureManager::streamonRequest(const std::string& vcameraId)
+{
+    ALOGD("%s: for camera %s", __FUNCTION__, vcameraId.c_str());
+    sp<V4L2CameraDevice> v4l2Cam = getV4L2CameraByVirtID(vcameraId);
+    if (v4l2Cam != nullptr) {
+        if(v4l2Cam->streamOnDev() != 0) {
+            ALOGE("%s: fail to configureDev %s", __FUNCTION__, vcameraId.c_str());
+            return -1;
+        }
+    }
+    return 0;
+}
+
+int CaptureManager::streamoffRequest(const std::string& vcameraId)
+{
+    ALOGD("%s: for camera %s", __FUNCTION__, vcameraId.c_str());
+    return 0;
+}
+
+int CaptureManager::enqueueRequest(const std::string& vcameraId, sp<FrameBuffer> buf)
+{
+    Mutex::Autolock _l(mLock);
+    ALOGV("%s: for camera %s", __FUNCTION__, vcameraId.c_str());
+
+    sp<V4L2CameraDevice> v4l2Cam = nullptr;
+    if (vcameraId == kVirtualLoopbackId) {
+        v4l2Cam = mVirtualLoopMapper.mV4L2Device;
+    } else {
+        v4l2Cam = getV4L2CameraByVirtID(vcameraId);
+    }
+    if (v4l2Cam == nullptr) {
+        ALOGE("%s: Empty v4l2 camera when enqueueRequest.", __FUNCTION__);
+        return -1;
+    }
+    buf->mReady = false;
+    return v4l2Cam->registerFrameBuffer(vcameraId, buf);
+}
+
+int CaptureManager::dequeueRequest(sp<FrameBuffer> buf)
+{
+    Mutex::Autolock _l(mLock);
+    ALOGV("%s: for camera", __FUNCTION__);
+
+    //lock wait for buffer ready.
+    std::unique_lock<std::mutex> lk(buf->mReadyMutex);
+    buf->mReadyCondition.wait(lk, [buf]{
+        ALOGV("buffer->mReady = %d", (int)buf->mReady);
+        return (buf->mReady == true); });
+
+    return 0;
+}
+
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
diff --git a/camera/device/3.4/default/Virtual/IVICameraUtils.cpp b/camera/device/3.4/default/Virtual/IVICameraUtils.cpp
new file mode 100644
index 000000000..2d2d96b1f
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/IVICameraUtils.cpp
@@ -0,0 +1,871 @@
+#define LOG_TAG "IVICamUtils@3.4"
+//#define LOG_NDEBUG 0
+#include <log/log.h>
+
+#include <cmath>
+#include <cstring>
+#include <sys/mman.h>
+#include <linux/videodev2.h>
+
+#include <libyuv.h>
+#include <jpeglib.h>
+
+// #include "IVICameraUtils.h"
+#include "./include/ext_device_v3_4_impl/ExternalCameraUtils.h"
+
+namespace {
+buffer_handle_t sEmptyBuffer = nullptr;
+} // Anonymous namespace
+
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+Frame::Frame(uint32_t width, uint32_t height, uint32_t fourcc) :
+        mWidth(width), mHeight(height), mFourcc(fourcc) {}
+
+
+V4L2Frame::V4L2Frame(
+        uint32_t w, uint32_t h, uint32_t fourcc,
+        int bufIdx, int fd, uint32_t dataSize, uint64_t offset) :
+        Frame(w, h, fourcc),
+        mBufferIndex(bufIdx), mFd(fd), mDataSize(dataSize), mOffset(offset) {}
+
+int V4L2Frame::setMapData(uint8_t* data) {
+    mData = data;
+    mMapped = true;
+
+    return 0;
+}
+
+int V4L2Frame::map(uint8_t** data, size_t* dataSize) {
+    if (data == nullptr || dataSize == nullptr) {
+        ALOGE("%s: V4L2 buffer map bad argument: data %p, dataSize %p",
+                __FUNCTION__, data, dataSize);
+        return -EINVAL;
+    }
+
+    std::lock_guard<std::mutex> lk(mLock);
+    if (!mMapped) {
+        // uint64_t tmp_offset = 4153344;
+        // ALOGW("mOffset = 4153344 for debugging.");
+        // if (tmp_offset == mOffset) {
+        //     ALOGW("mmap offset is same.");
+        // }
+        void* addr = mmap(NULL, mDataSize, PROT_READ, MAP_SHARED, mFd, mOffset);
+        // void* addr = mmap(NULL, mDataSize, PROT_READ, MAP_SHARED, mFd, tmp_offset);
+        if (addr == MAP_FAILED) {
+            ALOGE("%s: V4L2 buffer map failed %s",  __FUNCTION__, strerror(errno));
+            return -EINVAL;
+        }
+        mData = static_cast<uint8_t*>(addr);
+        mMapped = true;
+    }
+    *data = mData;
+    *dataSize = mDataSize;
+    ALOGV("%s: V4L map FD %d, data %p size %zu", __FUNCTION__, mFd, mData, mDataSize);
+    return 0;
+}
+
+int V4L2Frame::unmap() {
+    std::lock_guard<std::mutex> lk(mLock);
+/*    if (mMapped) {
+        ALOGV("%s: V4L unmap data %p size %zu", __FUNCTION__, mData, mDataSize);
+        if (munmap(mData, mDataSize) != 0) {
+            ALOGE("%s: V4L2 buffer unmap failed: %s", __FUNCTION__, strerror(errno));
+            return -EINVAL;
+        }
+        mMapped = false;
+    }*/
+    mMapped = false;
+    return 0;
+}
+
+V4L2Frame::~V4L2Frame() {
+    unmap();
+}
+
+int V4L2Frame::getData(uint8_t** outData, size_t* dataSize) {
+    if (mMapped == true) {
+        *outData = mData;
+        *dataSize = mDataSize;
+    }
+    return map(outData, dataSize);
+}
+
+
+AllocatedFrame::AllocatedFrame(
+        uint32_t w, uint32_t h) :
+        Frame(w, h, V4L2_PIX_FMT_YUV420) {};
+
+AllocatedFrame::~AllocatedFrame() {}
+
+int AllocatedFrame::allocate(YCbCrLayout* out) {
+    std::lock_guard<std::mutex> lk(mLock);
+    if ((mWidth % 2) || (mHeight % 2)) {
+        ALOGE("%s: bad dimension %dx%d (not multiple of 2)", __FUNCTION__, mWidth, mHeight);
+        return -EINVAL;
+    }
+
+    uint32_t dataSize = mWidth * mHeight * 3 / 2; // YUV420
+    if (mData.size() != dataSize) {
+        mData.resize(dataSize);
+    }
+
+    if (out != nullptr) {
+        out->y = mData.data();
+        out->yStride = mWidth;
+        uint8_t* cbStart = mData.data() + mWidth * mHeight;
+        uint8_t* crStart = cbStart + mWidth * mHeight / 4;
+        out->cb = cbStart;
+        out->cr = crStart;
+        out->cStride = mWidth / 2;
+        out->chromaStep = 1;
+    }
+    return 0;
+}
+
+int AllocatedFrame::getData(uint8_t** outData, size_t* dataSize) {
+    YCbCrLayout layout;
+    int ret = allocate(&layout);
+    if (ret != 0) {
+        return ret;
+    }
+    *outData = mData.data();
+    *dataSize = mData.size();
+    return 0;
+}
+
+int AllocatedFrame::getLayout(YCbCrLayout* out) {
+    IMapper::Rect noCrop = {0, 0,
+            static_cast<int32_t>(mWidth),
+            static_cast<int32_t>(mHeight)};
+    return getCroppedLayout(noCrop, out);
+}
+
+int AllocatedFrame::getCroppedLayout(const IMapper::Rect& rect, YCbCrLayout* out) {
+    if (out == nullptr) {
+        ALOGE("%s: null out", __FUNCTION__);
+        return -1;
+    }
+
+    std::lock_guard<std::mutex> lk(mLock);
+    if ((rect.left + rect.width) > static_cast<int>(mWidth) ||
+        (rect.top + rect.height) > static_cast<int>(mHeight) ||
+            (rect.left % 2) || (rect.top % 2) || (rect.width % 2) || (rect.height % 2)) {
+        ALOGE("%s: bad rect left %d top %d w %d h %d", __FUNCTION__,
+                rect.left, rect.top, rect.width, rect.height);
+        return -1;
+    }
+
+    out->y = mData.data() + mWidth * rect.top + rect.left;
+    out->yStride = mWidth;
+    uint8_t* cbStart = mData.data() + mWidth * mHeight;
+    uint8_t* crStart = cbStart + mWidth * mHeight / 4;
+    out->cb = cbStart + mWidth * rect.top / 4 + rect.left / 2;
+    out->cr = crStart + mWidth * rect.top / 4 + rect.left / 2;
+    out->cStride = mWidth / 2;
+    out->chromaStep = 1;
+    return 0;
+}
+
+bool isAspectRatioClose(float ar1, float ar2) {
+    const float kAspectRatioMatchThres = 0.025f; // This threshold is good enough to distinguish
+                                                // 4:3/16:9/20:9
+                                                // 1.33 / 1.78 / 2
+    return (std::abs(ar1 - ar2) < kAspectRatioMatchThres);
+}
+
+double SupportedV4L2Format::FrameRate::getDouble() const {
+    return durationDenominator / static_cast<double>(durationNumerator);
+}
+
+::android::hardware::camera::common::V1_0::Status importBufferImpl(
+        /*inout*/std::map<int, CirculatingBuffers>& circulatingBuffers,
+        /*inout*/HandleImporter& handleImporter,
+        int32_t streamId,
+        uint64_t bufId, buffer_handle_t buf,
+        /*out*/buffer_handle_t** outBufPtr,
+        bool allowEmptyBuf) {
+    using ::android::hardware::camera::common::V1_0::Status;
+    if (buf == nullptr && bufId == BUFFER_ID_NO_BUFFER) {
+        if (allowEmptyBuf) {
+            *outBufPtr = &sEmptyBuffer;
+            return Status::OK;
+        } else {
+            ALOGE("%s: bufferId %" PRIu64 " has null buffer handle!", __FUNCTION__, bufId);
+            return Status::ILLEGAL_ARGUMENT;
+        }
+    }
+
+    CirculatingBuffers& cbs = circulatingBuffers[streamId];
+    if (cbs.count(bufId) == 0) {
+        if (buf == nullptr) {
+            ALOGE("%s: bufferId %" PRIu64 " has null buffer handle!", __FUNCTION__, bufId);
+            return Status::ILLEGAL_ARGUMENT;
+        }
+        // Register a newly seen buffer
+        buffer_handle_t importedBuf = buf;
+        handleImporter.importBuffer(importedBuf);
+        if (importedBuf == nullptr) {
+            ALOGE("%s: output buffer for stream %d is invalid!", __FUNCTION__, streamId);
+            return Status::INTERNAL_ERROR;
+        } else {
+            cbs[bufId] = importedBuf;
+        }
+    }
+    *outBufPtr = &cbs[bufId];
+    return Status::OK;
+}
+
+uint32_t getFourCcFromLayout(const YCbCrLayout& layout) {
+    intptr_t cb = reinterpret_cast<intptr_t>(layout.cb);
+    intptr_t cr = reinterpret_cast<intptr_t>(layout.cr);
+    if (std::abs(cb - cr) == 1 && layout.chromaStep == 2) {
+        // Interleaved format
+        if (layout.cb > layout.cr) {
+            return V4L2_PIX_FMT_NV21;
+        } else {
+            return V4L2_PIX_FMT_NV12;
+        }
+    } else if (layout.chromaStep == 1) {
+        // Planar format
+        if (layout.cb > layout.cr) {
+            return V4L2_PIX_FMT_YVU420; // YV12
+        } else {
+            return V4L2_PIX_FMT_YUV420; // YU12
+        }
+    } else {
+        return FLEX_YUV_GENERIC;
+    }
+}
+
+int getCropRect(
+        CroppingType ct, const Size& inSize, const Size& outSize, IMapper::Rect* out) {
+    if (out == nullptr) {
+        ALOGE("%s: out is null", __FUNCTION__);
+        return -1;
+    }
+
+    uint32_t inW = inSize.width;
+    uint32_t inH = inSize.height;
+    uint32_t outW = outSize.width;
+    uint32_t outH = outSize.height;
+
+    // Handle special case where aspect ratio is close to input but scaled
+    // dimension is slightly larger than input
+    float arIn = ASPECT_RATIO(inSize);
+    float arOut = ASPECT_RATIO(outSize);
+    if (isAspectRatioClose(arIn, arOut)) {
+        out->left = 0;
+        out->top = 0;
+        out->width = inW;
+        out->height = inH;
+        return 0;
+    }
+
+    if (ct == VERTICAL) {
+        uint64_t scaledOutH = static_cast<uint64_t>(outH) * inW / outW;
+        if (scaledOutH > inH) {
+            ALOGE("%s: Output size %dx%d cannot be vertically cropped from input size %dx%d",
+                    __FUNCTION__, outW, outH, inW, inH);
+            return -1;
+        }
+        scaledOutH = scaledOutH & ~0x1; // make it multiple of 2
+
+        out->left = 0;
+        out->top = ((inH - scaledOutH) / 2) & ~0x1;
+        out->width = inW;
+        out->height = static_cast<int32_t>(scaledOutH);
+        ALOGV("%s: crop %dx%d to %dx%d: top %d, scaledH %d",
+                __FUNCTION__, inW, inH, outW, outH, out->top, static_cast<int32_t>(scaledOutH));
+    } else {
+        uint64_t scaledOutW = static_cast<uint64_t>(outW) * inH / outH;
+        if (scaledOutW > inW) {
+            ALOGE("%s: Output size %dx%d cannot be horizontally cropped from input size %dx%d",
+                    __FUNCTION__, outW, outH, inW, inH);
+            return -1;
+        }
+        scaledOutW = scaledOutW & ~0x1; // make it multiple of 2
+
+        out->left = ((inW - scaledOutW) / 2) & ~0x1;
+        out->top = 0;
+        out->width = static_cast<int32_t>(scaledOutW);
+        out->height = inH;
+        ALOGV("%s: crop %dx%d to %dx%d: top %d, scaledW %d",
+                __FUNCTION__, inW, inH, outW, outH, out->top, static_cast<int32_t>(scaledOutW));
+    }
+
+    return 0;
+}
+
+int formatConvert(
+        const YCbCrLayout& in, const YCbCrLayout& out, Size sz, uint32_t format) {
+    int ret = 0;
+    switch (format) {
+        case V4L2_PIX_FMT_NV21:
+            ret = libyuv::I420ToNV21(
+                    static_cast<uint8_t*>(in.y),
+                    in.yStride,
+                    static_cast<uint8_t*>(in.cb),
+                    in.cStride,
+                    static_cast<uint8_t*>(in.cr),
+                    in.cStride,
+                    static_cast<uint8_t*>(out.y),
+                    out.yStride,
+                    static_cast<uint8_t*>(out.cr),
+                    out.cStride,
+                    sz.width,
+                    sz.height);
+            if (ret != 0) {
+                ALOGE("%s: convert to NV21 buffer failed! ret %d",
+                            __FUNCTION__, ret);
+                return ret;
+            }
+            break;
+        case V4L2_PIX_FMT_NV12:
+            ret = libyuv::I420ToNV12(
+                    static_cast<uint8_t*>(in.y),
+                    in.yStride,
+                    static_cast<uint8_t*>(in.cb),
+                    in.cStride,
+                    static_cast<uint8_t*>(in.cr),
+                    in.cStride,
+                    static_cast<uint8_t*>(out.y),
+                    out.yStride,
+                    static_cast<uint8_t*>(out.cb),
+                    out.cStride,
+                    sz.width,
+                    sz.height);
+            if (ret != 0) {
+                ALOGE("%s: convert to NV12 buffer failed! ret %d",
+                            __FUNCTION__, ret);
+                return ret;
+            }
+            break;
+        case V4L2_PIX_FMT_YVU420: // YV12
+        case V4L2_PIX_FMT_YUV420: // YU12
+            // TODO: maybe we can speed up here by somehow save this copy?
+            ret = libyuv::I420Copy(
+                    static_cast<uint8_t*>(in.y),
+                    in.yStride,
+                    static_cast<uint8_t*>(in.cb),
+                    in.cStride,
+                    static_cast<uint8_t*>(in.cr),
+                    in.cStride,
+                    static_cast<uint8_t*>(out.y),
+                    out.yStride,
+                    static_cast<uint8_t*>(out.cb),
+                    out.cStride,
+                    static_cast<uint8_t*>(out.cr),
+                    out.cStride,
+                    sz.width,
+                    sz.height);
+            if (ret != 0) {
+                ALOGE("%s: copy to YV12 or YU12 buffer failed! ret %d",
+                            __FUNCTION__, ret);
+                return ret;
+            }
+            break;
+        case FLEX_YUV_GENERIC:
+            // TODO: b/72261744 write to arbitrary flexible YUV layout. Slow.
+            ALOGE("%s: unsupported flexible yuv layout"
+                    " y %p cb %p cr %p y_str %d c_str %d c_step %d",
+                    __FUNCTION__, out.y, out.cb, out.cr,
+                    out.yStride, out.cStride, out.chromaStep);
+            return -1;
+        default:
+            ALOGE("%s: unknown YUV format 0x%x!", __FUNCTION__, format);
+            return -1;
+    }
+    return 0;
+}
+
+int encodeJpegYU12(
+        const Size & inSz, const YCbCrLayout& inLayout,
+        int jpegQuality, const void *app1Buffer, size_t app1Size,
+        void *out, const size_t maxOutSize, size_t &actualCodeSize)
+{
+    /* libjpeg is a C library so we use C-style "inheritance" by
+     * putting libjpeg's jpeg_destination_mgr first in our custom
+     * struct. This allows us to cast jpeg_destination_mgr* to
+     * CustomJpegDestMgr* when we get it passed to us in a callback */
+    struct CustomJpegDestMgr {
+        struct jpeg_destination_mgr mgr;
+        JOCTET *mBuffer;
+        size_t mBufferSize;
+        size_t mEncodedSize;
+        bool mSuccess;
+    } dmgr;
+
+    jpeg_compress_struct cinfo = {};
+    jpeg_error_mgr jerr;
+
+    /* Initialize error handling with standard callbacks, but
+     * then override output_message (to print to ALOG) and
+     * error_exit to set a flag and print a message instead
+     * of killing the whole process */
+    cinfo.err = jpeg_std_error(&jerr);
+
+    cinfo.err->output_message = [](j_common_ptr cinfo) {
+        char buffer[JMSG_LENGTH_MAX];
+
+        /* Create the message */
+        (*cinfo->err->format_message)(cinfo, buffer);
+        ALOGE("libjpeg error: %s", buffer);
+    };
+    cinfo.err->error_exit = [](j_common_ptr cinfo) {
+        (*cinfo->err->output_message)(cinfo);
+        if(cinfo->client_data) {
+            auto & dmgr =
+                *reinterpret_cast<CustomJpegDestMgr*>(cinfo->client_data);
+            dmgr.mSuccess = false;
+        }
+    };
+    /* Now that we initialized some callbacks, let's create our compressor */
+    jpeg_create_compress(&cinfo);
+
+    /* Initialize our destination manager */
+    dmgr.mBuffer = static_cast<JOCTET*>(out);
+    dmgr.mBufferSize = maxOutSize;
+    dmgr.mEncodedSize = 0;
+    dmgr.mSuccess = true;
+    cinfo.client_data = static_cast<void*>(&dmgr);
+
+    /* These lambdas become C-style function pointers and as per C++11 spec
+     * may not capture anything */
+    dmgr.mgr.init_destination = [](j_compress_ptr cinfo) {
+        auto & dmgr = reinterpret_cast<CustomJpegDestMgr&>(*cinfo->dest);
+        dmgr.mgr.next_output_byte = dmgr.mBuffer;
+        dmgr.mgr.free_in_buffer = dmgr.mBufferSize;
+        ALOGV("%s:%d jpeg start: %p [%zu]",
+              __FUNCTION__, __LINE__, dmgr.mBuffer, dmgr.mBufferSize);
+    };
+
+    dmgr.mgr.empty_output_buffer = [](j_compress_ptr cinfo __unused) {
+        ALOGV("%s:%d Out of buffer", __FUNCTION__, __LINE__);
+        return 0;
+    };
+
+    dmgr.mgr.term_destination = [](j_compress_ptr cinfo) {
+        auto & dmgr = reinterpret_cast<CustomJpegDestMgr&>(*cinfo->dest);
+        dmgr.mEncodedSize = dmgr.mBufferSize - dmgr.mgr.free_in_buffer;
+        ALOGV("%s:%d Done with jpeg: %zu", __FUNCTION__, __LINE__, dmgr.mEncodedSize);
+    };
+    cinfo.dest = reinterpret_cast<struct jpeg_destination_mgr*>(&dmgr);
+
+    /* We are going to be using JPEG in raw data mode, so we are passing
+     * straight subsampled planar YCbCr and it will not touch our pixel
+     * data or do any scaling or anything */
+    cinfo.image_width = inSz.width;
+    cinfo.image_height = inSz.height;
+    cinfo.input_components = 3;
+    cinfo.in_color_space = JCS_YCbCr;
+
+    /* Initialize defaults and then override what we want */
+    jpeg_set_defaults(&cinfo);
+
+    jpeg_set_quality(&cinfo, jpegQuality, 1);
+    jpeg_set_colorspace(&cinfo, JCS_YCbCr);
+    cinfo.raw_data_in = 1;
+    cinfo.dct_method = JDCT_IFAST;
+
+    /* Configure sampling factors. The sampling factor is JPEG subsampling 420
+     * because the source format is YUV420. Note that libjpeg sampling factors
+     * are... a little weird. Sampling of Y=2,U=1,V=1 means there is 1 U and
+     * 1 V value for each 2 Y values */
+    cinfo.comp_info[0].h_samp_factor = 2;
+    cinfo.comp_info[0].v_samp_factor = 2;
+    cinfo.comp_info[1].h_samp_factor = 1;
+    cinfo.comp_info[1].v_samp_factor = 1;
+    cinfo.comp_info[2].h_samp_factor = 1;
+    cinfo.comp_info[2].v_samp_factor = 1;
+
+    /* Let's not hardcode YUV420 in 6 places... 5 was enough */
+    int maxVSampFactor = std::max( {
+        cinfo.comp_info[0].v_samp_factor,
+        cinfo.comp_info[1].v_samp_factor,
+        cinfo.comp_info[2].v_samp_factor
+    });
+    int cVSubSampling = cinfo.comp_info[0].v_samp_factor /
+                        cinfo.comp_info[1].v_samp_factor;
+
+    /* Start the compressor */
+    jpeg_start_compress(&cinfo, TRUE);
+
+    /* Compute our macroblock height, so we can pad our input to be vertically
+     * macroblock aligned.
+     * TODO: Does it need to be horizontally MCU aligned too? */
+
+    size_t mcuV = DCTSIZE*maxVSampFactor;
+    size_t paddedHeight = mcuV * ((inSz.height + mcuV - 1) / mcuV);
+
+    /* libjpeg uses arrays of row pointers, which makes it really easy to pad
+     * data vertically (unfortunately doesn't help horizontally) */
+    std::vector<JSAMPROW> yLines (paddedHeight);
+    std::vector<JSAMPROW> cbLines(paddedHeight/cVSubSampling);
+    std::vector<JSAMPROW> crLines(paddedHeight/cVSubSampling);
+
+    uint8_t *py = static_cast<uint8_t*>(inLayout.y);
+    uint8_t *pcr = static_cast<uint8_t*>(inLayout.cr);
+    uint8_t *pcb = static_cast<uint8_t*>(inLayout.cb);
+
+    for(uint32_t i = 0; i < paddedHeight; i++)
+    {
+        /* Once we are in the padding territory we still point to the last line
+         * effectively replicating it several times ~ CLAMP_TO_EDGE */
+        int li = std::min(i, inSz.height - 1);
+        yLines[i]  = static_cast<JSAMPROW>(py + li * inLayout.yStride);
+        if(i < paddedHeight / cVSubSampling)
+        {
+            li = std::min(i, (inSz.height - 1) / cVSubSampling);
+            crLines[i] = static_cast<JSAMPROW>(pcr + li * inLayout.cStride);
+            cbLines[i] = static_cast<JSAMPROW>(pcb + li * inLayout.cStride);
+        }
+    }
+
+    /* If APP1 data was passed in, use it */
+    if(app1Buffer && app1Size)
+    {
+        jpeg_write_marker(&cinfo, JPEG_APP0 + 1,
+             static_cast<const JOCTET*>(app1Buffer), app1Size);
+    }
+
+    /* While we still have padded height left to go, keep giving it one
+     * macroblock at a time. */
+    while (cinfo.next_scanline < cinfo.image_height) {
+        const uint32_t batchSize = DCTSIZE * maxVSampFactor;
+        const uint32_t nl = cinfo.next_scanline;
+        JSAMPARRAY planes[3]{ &yLines[nl],
+                              &cbLines[nl/cVSubSampling],
+                              &crLines[nl/cVSubSampling] };
+
+        uint32_t done = jpeg_write_raw_data(&cinfo, planes, batchSize);
+
+        if (done != batchSize) {
+            ALOGE("%s: compressed %u lines, expected %u (total %u/%u)",
+              __FUNCTION__, done, batchSize, cinfo.next_scanline,
+              cinfo.image_height);
+            return -1;
+        }
+    }
+
+    /* This will flush everything */
+    jpeg_finish_compress(&cinfo);
+
+    /* Grab the actual code size and set it */
+    actualCodeSize = dmgr.mEncodedSize;
+
+    return 0;
+}
+
+Size getMaxThumbnailResolution(const common::V1_0::helper::CameraMetadata& chars) {
+    Size thumbSize { 0, 0 };
+    camera_metadata_ro_entry entry =
+        chars.find(ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES);
+    for(uint32_t i = 0; i < entry.count; i += 2) {
+        Size sz { static_cast<uint32_t>(entry.data.i32[i]),
+                  static_cast<uint32_t>(entry.data.i32[i+1]) };
+        if(sz.width * sz.height > thumbSize.width * thumbSize.height) {
+            thumbSize = sz;
+        }
+    }
+
+    if (thumbSize.width * thumbSize.height == 0) {
+        ALOGW("%s: non-zero thumbnail size not available", __FUNCTION__);
+    }
+
+    return thumbSize;
+}
+
+void freeReleaseFences(hidl_vec<V3_2::CaptureResult>& results) {
+    for (auto& result : results) {
+        if (result.inputBuffer.releaseFence.getNativeHandle() != nullptr) {
+            native_handle_t* handle = const_cast<native_handle_t*>(
+                    result.inputBuffer.releaseFence.getNativeHandle());
+            native_handle_close(handle);
+            native_handle_delete(handle);
+        }
+        for (auto& buf : result.outputBuffers) {
+            if (buf.releaseFence.getNativeHandle() != nullptr) {
+                native_handle_t* handle = const_cast<native_handle_t*>(
+                        buf.releaseFence.getNativeHandle());
+                native_handle_close(handle);
+                native_handle_delete(handle);
+            }
+        }
+    }
+    return;
+}
+
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof(a[0]))
+#define UPDATE(md, tag, data, size)               \
+do {                                              \
+    if ((md).update((tag), (data), (size))) {     \
+        ALOGE("Update " #tag " failed!");         \
+        return BAD_VALUE;                         \
+    }                                             \
+} while (0)
+
+status_t fillCaptureResultCommon(
+        common::V1_0::helper::CameraMetadata &md, nsecs_t timestamp,
+        camera_metadata_ro_entry& activeArraySize) {
+    if (activeArraySize.count < 4) {
+        ALOGE("%s: cannot find active array size!", __FUNCTION__);
+        return -EINVAL;
+    }
+    // android.control
+    // For USB camera, we don't know the AE state. Set the state to converged to
+    // indicate the frame should be good to use. Then apps don't have to wait the
+    // AE state.
+    const uint8_t aeState = ANDROID_CONTROL_AE_STATE_CONVERGED;
+    UPDATE(md, ANDROID_CONTROL_AE_STATE, &aeState, 1);
+
+    const uint8_t ae_lock = ANDROID_CONTROL_AE_LOCK_OFF;
+    UPDATE(md, ANDROID_CONTROL_AE_LOCK, &ae_lock, 1);
+
+    // Set AWB state to converged to indicate the frame should be good to use.
+    const uint8_t awbState = ANDROID_CONTROL_AWB_STATE_CONVERGED;
+    UPDATE(md, ANDROID_CONTROL_AWB_STATE, &awbState, 1);
+
+    const uint8_t awbLock = ANDROID_CONTROL_AWB_LOCK_OFF;
+    UPDATE(md, ANDROID_CONTROL_AWB_LOCK, &awbLock, 1);
+
+    const uint8_t flashState = ANDROID_FLASH_STATE_UNAVAILABLE;
+    UPDATE(md, ANDROID_FLASH_STATE, &flashState, 1);
+
+    // This means pipeline latency of X frame intervals. The maximum number is 4.
+    const uint8_t requestPipelineMaxDepth = 4;
+    UPDATE(md, ANDROID_REQUEST_PIPELINE_DEPTH, &requestPipelineMaxDepth, 1);
+
+    // android.scaler
+    const int32_t crop_region[] = {
+          activeArraySize.data.i32[0], activeArraySize.data.i32[1],
+          activeArraySize.data.i32[2], activeArraySize.data.i32[3],
+    };
+    UPDATE(md, ANDROID_SCALER_CROP_REGION, crop_region, ARRAY_SIZE(crop_region));
+
+    // android.sensor
+    UPDATE(md, ANDROID_SENSOR_TIMESTAMP, &timestamp, 1);
+
+    // android.statistics
+    const uint8_t lensShadingMapMode = ANDROID_STATISTICS_LENS_SHADING_MAP_MODE_OFF;
+    UPDATE(md, ANDROID_STATISTICS_LENS_SHADING_MAP_MODE, &lensShadingMapMode, 1);
+
+    const uint8_t sceneFlicker = ANDROID_STATISTICS_SCENE_FLICKER_NONE;
+    UPDATE(md, ANDROID_STATISTICS_SCENE_FLICKER, &sceneFlicker, 1);
+
+    return OK;
+}
+
+#undef ARRAY_SIZE
+#undef UPDATE
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+
+namespace external {
+namespace common {
+
+namespace {
+    const int kDefaultCameraIdOffset = 100;
+    const int kDefaultJpegBufSize = 5 << 20; // 5MB
+    const int kDefaultNumVideoBuffer = 4;
+    const int kDefaultNumStillBuffer = 2;
+    const int kDefaultOrientation = 0; // suitable for natural landscape displays like tablet/TV
+                                       // For phone devices 270 is better
+} // anonymous namespace
+
+const char* ExternalCameraConfig::kDefaultCfgPath = "/vendor/etc/external_camera_config.xml";
+
+ExternalCameraConfig ExternalCameraConfig::loadFromCfg(const char* cfgPath) {
+    using namespace tinyxml2;
+    ExternalCameraConfig ret;
+
+    XMLDocument configXml;
+    XMLError err = configXml.LoadFile(cfgPath);
+    if (err != XML_SUCCESS) {
+        ALOGE("%s: Unable to load external camera config file '%s'. Error: %s",
+                __FUNCTION__, cfgPath, XMLDocument::ErrorIDToName(err));
+        return ret;
+    } else {
+        ALOGI("%s: load external camera config succeed!", __FUNCTION__);
+    }
+
+    XMLElement *extCam = configXml.FirstChildElement("ExternalCamera");
+    if (extCam == nullptr) {
+        ALOGI("%s: no external camera config specified", __FUNCTION__);
+        return ret;
+    }
+
+    XMLElement *providerCfg = extCam->FirstChildElement("Provider");
+    if (providerCfg == nullptr) {
+        ALOGI("%s: no external camera provider config specified", __FUNCTION__);
+        return ret;
+    }
+
+    XMLElement *cameraIdOffset = providerCfg->FirstChildElement("CameraIdOffset");
+    if (cameraIdOffset != nullptr) {
+        ret.cameraIdOffset = std::atoi(cameraIdOffset->GetText());
+    }
+
+    XMLElement *ignore = providerCfg->FirstChildElement("ignore");
+    if (ignore == nullptr) {
+        ALOGI("%s: no internal ignored device specified", __FUNCTION__);
+        return ret;
+    }
+
+    XMLElement *id = ignore->FirstChildElement("id");
+    while (id != nullptr) {
+        const char* text = id->GetText();
+        if (text != nullptr) {
+            ret.mInternalDevices.insert(text);
+            ALOGI("%s: device %s will be ignored by external camera provider",
+                    __FUNCTION__, text);
+        }
+        id = id->NextSiblingElement("id");
+    }
+
+    XMLElement *deviceCfg = extCam->FirstChildElement("Device");
+    if (deviceCfg == nullptr) {
+        ALOGI("%s: no external camera device config specified", __FUNCTION__);
+        return ret;
+    }
+
+    XMLElement *jpegBufSz = deviceCfg->FirstChildElement("MaxJpegBufferSize");
+    if (jpegBufSz == nullptr) {
+        ALOGI("%s: no max jpeg buffer size specified", __FUNCTION__);
+    } else {
+        ret.maxJpegBufSize = jpegBufSz->UnsignedAttribute("bytes", /*Default*/kDefaultJpegBufSize);
+    }
+
+    XMLElement *numVideoBuf = deviceCfg->FirstChildElement("NumVideoBuffers");
+    if (numVideoBuf == nullptr) {
+        ALOGI("%s: no num video buffers specified", __FUNCTION__);
+    } else {
+        ret.numVideoBuffers =
+                numVideoBuf->UnsignedAttribute("count", /*Default*/kDefaultNumVideoBuffer);
+    }
+
+    XMLElement *numStillBuf = deviceCfg->FirstChildElement("NumStillBuffers");
+    if (numStillBuf == nullptr) {
+        ALOGI("%s: no num still buffers specified", __FUNCTION__);
+    } else {
+        ret.numStillBuffers =
+                numStillBuf->UnsignedAttribute("count", /*Default*/kDefaultNumStillBuffer);
+    }
+
+    XMLElement *fpsList = deviceCfg->FirstChildElement("FpsList");
+    if (fpsList == nullptr) {
+        ALOGI("%s: no fps list specified", __FUNCTION__);
+    } else {
+        if (!updateFpsList(fpsList, ret.fpsLimits)) {
+            return ret;
+        }
+    }
+
+    XMLElement *depth = deviceCfg->FirstChildElement("Depth16Supported");
+    if (depth == nullptr) {
+        ret.depthEnabled = false;
+        ALOGI("%s: depth output is not enabled", __FUNCTION__);
+    } else {
+        ret.depthEnabled = depth->BoolAttribute("enabled", false);
+    }
+
+    if(ret.depthEnabled) {
+        XMLElement *depthFpsList = deviceCfg->FirstChildElement("DepthFpsList");
+        if (depthFpsList == nullptr) {
+            ALOGW("%s: no depth fps list specified", __FUNCTION__);
+        } else {
+            if(!updateFpsList(depthFpsList, ret.depthFpsLimits)) {
+                return ret;
+            }
+        }
+    }
+
+    XMLElement *minStreamSize = deviceCfg->FirstChildElement("MinimumStreamSize");
+    if (minStreamSize == nullptr) {
+       ALOGI("%s: no minimum stream size specified", __FUNCTION__);
+    } else {
+        ret.minStreamSize = {
+                minStreamSize->UnsignedAttribute("width", /*Default*/0),
+                minStreamSize->UnsignedAttribute("height", /*Default*/0)};
+    }
+
+    XMLElement *orientation = deviceCfg->FirstChildElement("Orientation");
+    if (orientation == nullptr) {
+        ALOGI("%s: no sensor orientation specified", __FUNCTION__);
+    } else {
+        ret.orientation = orientation->IntAttribute("degree", /*Default*/kDefaultOrientation);
+    }
+
+    ALOGI("%s: external camera cfg loaded: maxJpgBufSize %d,"
+            " num video buffers %d, num still buffers %d, orientation %d",
+            __FUNCTION__, ret.maxJpegBufSize,
+            ret.numVideoBuffers, ret.numStillBuffers, ret.orientation);
+    for (const auto& limit : ret.fpsLimits) {
+        ALOGI("%s: fpsLimitList: %dx%d@%f", __FUNCTION__,
+                limit.size.width, limit.size.height, limit.fpsUpperBound);
+    }
+    for (const auto& limit : ret.depthFpsLimits) {
+        ALOGI("%s: depthFpsLimitList: %dx%d@%f", __FUNCTION__, limit.size.width, limit.size.height,
+              limit.fpsUpperBound);
+    }
+    ALOGI("%s: minStreamSize: %dx%d" , __FUNCTION__,
+         ret.minStreamSize.width, ret.minStreamSize.height);
+    return ret;
+}
+
+bool ExternalCameraConfig::updateFpsList(tinyxml2::XMLElement* fpsList,
+        std::vector<FpsLimitation>& fpsLimits) {
+    using namespace tinyxml2;
+    std::vector<FpsLimitation> limits;
+    XMLElement* row = fpsList->FirstChildElement("Limit");
+    while (row != nullptr) {
+        FpsLimitation prevLimit{{0, 0}, 1000.0};
+        FpsLimitation limit;
+        limit.size = {row->UnsignedAttribute("width", /*Default*/ 0),
+                      row->UnsignedAttribute("height", /*Default*/ 0)};
+        limit.fpsUpperBound = row->DoubleAttribute("fpsBound", /*Default*/ 1000.0);
+        if (limit.size.width <= prevLimit.size.width ||
+            limit.size.height <= prevLimit.size.height ||
+            limit.fpsUpperBound >= prevLimit.fpsUpperBound) {
+            ALOGE(
+                "%s: FPS limit list must have increasing size and decreasing fps!"
+                " Prev %dx%d@%f, Current %dx%d@%f",
+                __FUNCTION__, prevLimit.size.width, prevLimit.size.height, prevLimit.fpsUpperBound,
+                limit.size.width, limit.size.height, limit.fpsUpperBound);
+            return false;
+        }
+        limits.push_back(limit);
+        row = row->NextSiblingElement("Limit");
+    }
+    fpsLimits = limits;
+    return true;
+}
+
+ExternalCameraConfig::ExternalCameraConfig() :
+        cameraIdOffset(kDefaultCameraIdOffset),
+        maxJpegBufSize(kDefaultJpegBufSize),
+        numVideoBuffers(kDefaultNumVideoBuffer),
+        numStillBuffers(kDefaultNumStillBuffer),
+        depthEnabled(false),
+        orientation(kDefaultOrientation) {
+    fpsLimits.push_back({/*Size*/{ 640,  480}, /*FPS upper bound*/30.0});
+    fpsLimits.push_back({/*Size*/{1280,  720}, /*FPS upper bound*/7.5});
+    fpsLimits.push_back({/*Size*/{1920, 1080}, /*FPS upper bound*/5.0});
+    minStreamSize = {0, 0};
+}
+
+
+} //namespace common
+} //namespace IVICamera
+
+} // namespace camera
+} //namespace hardware
+} //namespace android
\ No newline at end of file
diff --git a/camera/device/3.4/default/Virtual/LoopbackListener.cpp b/camera/device/3.4/default/Virtual/LoopbackListener.cpp
new file mode 100644
index 000000000..1471b71d8
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/LoopbackListener.cpp
@@ -0,0 +1,398 @@
+#define LOG_TAG "LoopbackListener@3.4"
+
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <unistd.h>
+
+#include "NetlinkUtil.h"
+#include "LoopbackListener.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+int LoopbackDevice::configureLoopback(int width, int height, uint32_t pixelFormat)
+{
+    struct v4l2_format fmt;
+    
+    fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT;
+    if (-1 == ioctl(mFd, VIDIOC_G_FMT, &fmt))
+    {
+        ALOGE("%s: Cannot VIDIOC_G_FMT of virtual camera mfd=%d.", __FUNCTION__, mFd);
+        return -1;
+    }
+ 
+    fmt.fmt.pix.width = width;
+    fmt.fmt.pix.height = height;
+    fmt.fmt.pix.pixelformat = pixelFormat;
+    fmt.fmt.pix.sizeimage = (fmt.fmt.pix.width * fmt.fmt.pix.height) >> 1;
+    fmt.fmt.pix.field = V4L2_FIELD_NONE;
+    if (-1 == ioctl(mFd, VIDIOC_S_FMT, &fmt))
+    {
+        ALOGE("%s: Cannot set loopback device.", __FUNCTION__);
+        return -1;
+    }
+
+    return 0;
+}
+
+bool LoopbackDevice::isLoopbackDevice(const std::string& node)
+{
+    bool ret = false;
+    struct stat dev_stat;
+    struct v4l2_capability capability;
+    int fd = open(node.c_str(), O_RDONLY | O_EXCL);
+    if (fd < 0)
+    {
+        ALOGE("%s: Failed to open virtual camera device %s, ignore this device.", __FUNCTION__, node.c_str());
+        return ret;
+    }
+    fstat(fd, &dev_stat);
+    if (!S_ISCHR(dev_stat.st_mode))
+    {
+        ALOGE("%s is not a valid char device.", node.c_str());
+        close(fd);
+        return ret;
+    }
+    if (ioctl(fd, VIDIOC_QUERYCAP, &capability) < 0) {
+        ALOGE("%s: Failed to querycap for virtual device %s\n", __FUNCTION__, node.c_str());
+        close(fd);
+        return ret;
+    }
+    std::string card = (char *)(capability.card);
+    std::string driver = (char *)(capability.driver);
+    ALOGI("%s:Device card %s, driver %s", __FUNCTION__, card.c_str(), driver.c_str());
+
+    if (driver.find("v4l2 loopback") != std::string::npos) {
+        ret = true;
+    }
+    close(fd);
+    return ret;
+}
+
+int LoopbackDevice::openLoopback(const std::string& node)
+{
+    struct stat dev_stat;
+    struct v4l2_capability capability;
+    int cnt = 0;
+    do {
+        mFd = open(node.c_str(), O_WRONLY);
+        if (mFd > 0) {
+            break;
+        }
+        ALOGE("%s: Failed to open loopback device %s, retry...(%d)", __FUNCTION__, node.c_str(), cnt);
+        usleep(700000);
+        cnt++;
+    } while(cnt < 10);
+
+    if (mFd < 0)
+    {
+        ALOGE("%s: Failed to open loopback device %s.", __FUNCTION__, node.c_str());
+        return -1;
+    }
+    fstat(mFd, &dev_stat);
+    if (!S_ISCHR(dev_stat.st_mode))
+    {
+        ALOGE("%s is not a valid char device.", node.c_str());
+        close(mFd);
+        mFd = -1;
+        return -1;
+    }
+    mDeviceName = node;
+    if (ioctl(mFd, VIDIOC_QUERYCAP, &capability) < 0)
+    {
+        ALOGE("%s: Failed to querycap for virtual device %s\n", __FUNCTION__, node.c_str());
+        close(mFd);
+        mFd = -1;
+        return -1;
+    }
+
+    mCardName = (char *)(capability.card);
+    mDriver = (char *)(capability.driver);
+
+    if (mDriver.find("v4l2 loopback") == std::string::npos)
+    {
+        ALOGE("%s: %s is not a v4l2loopback device. Ignore it.\n", __FUNCTION__, node.c_str());
+        close(mFd);
+        mFd = -1;
+        return -1;
+    }
+    mRefcount = 0;
+
+    ALOGI("%s: loopback device %s[%s]\n", __FUNCTION__,
+        mCardName.c_str(),
+        mDeviceName.c_str());
+
+    return 0;
+}
+
+void save_image(unsigned char* data, int data_size) {
+    char filename[32];
+    FILE* tmpfd;
+    static int ctr = 0;
+    // uint32_t row;
+
+    sprintf(filename, "/data/imgs/img%03d.ppm", ++ctr);
+
+    tmpfd = fopen(filename, "w");
+    if (!tmpfd) {
+        ALOGE("cannot write file %s %d", filename, data_size);
+        return;
+    }
+    fwrite(data, data_size, 1, tmpfd);
+
+    fclose(tmpfd);
+    ALOGI("Written to output file %s.\n", filename);
+}
+
+int LoopbackDevice::writeStream(uint8_t* data, int32_t dataSize)
+{
+    if (data == nullptr) {
+        ALOGE("%s: empty data.", __FUNCTION__);
+        return -1;
+    }
+    // save_image(data, dataSize);
+    ALOGV("%s: write mfd %d with size %d", __FUNCTION__, mFd, dataSize);
+    return write(mFd, data, dataSize);
+}
+
+int LoopbackDevice::closeLoopback()
+{
+    close(mFd);
+    mFd = 0;
+    return 0;
+}
+
+LoopbackListener* LoopbackListener::mInstance = nullptr;
+int LoopbackListener::mRefcount = 0;
+
+int LoopbackListener::initialize(sp<VirtualCameraDevice> vcam, const std::string& loopbackPath)
+{
+    ALOGI("%s: bind virtual camera %s to loopback %s", __FUNCTION__, vcam->getCameraId().c_str(), loopbackPath.c_str());
+    if (vcam == nullptr) {
+        ALOGE("%s: failed to fetch virtual camera device.", __FUNCTION__);
+        return -1;
+    }
+    mVirtualCameraDevice = vcam;
+    if (mVirtualCameraDevice == nullptr) {
+        ALOGE("%s: invalid virtual camera device", __FUNCTION__);
+        return -1;
+    }
+    mLoopbackPath = loopbackPath;
+
+    ALOGI("%s: loopback validation.", __FUNCTION__);
+    if (mLoopbackDevice.openLoopback(loopbackPath) < 0) {
+        return -1;
+    }
+    
+    //create the polling thread.
+    mStreamer = new StreamThread(this);
+    if (mStreamer == nullptr) {
+        ALOGE("%s: failed to create mStreamer for loopback.", __FUNCTION__);
+        return -1;
+    }
+    return 0;
+}
+
+DeviceStatus LoopbackListener::handleRequest(const std::string &request, std::string &response)
+{
+    DeviceStatus ret = DEV_ERR;
+    NetlinkRequest nreq;
+    nreq.parse(request);
+    ALOGD("request: %s %s %s", nreq.mRequest.c_str(), nreq.mCardName.c_str(), nreq.mProcessName.c_str());
+    //Ignore listener which is a writing process for image output.
+    if (nreq.mRequest == "open") {
+        response = "OpenDone";
+        if (nreq.mProcessName.find("camera.provider") != std::string::npos
+            || nreq.mProcessName.find("camera_test") != std::string::npos
+            || nreq.mProcessName.find("android.hardwar") != std::string::npos) {
+            ALOGW("%s: ignore program %s", __FUNCTION__, nreq.mProcessName.c_str());
+        } else {
+            mLoopbackDevice.mRefcount++;
+            if (mLoopbackDevice.mRefcount == 1) {
+                //create the polling thread.
+                if (mStreamer == nullptr) {
+                    mStreamer = new StreamThread(this);
+                }
+                if (mStreamer == nullptr) {
+                    mLoopbackDevice.closeLoopback();
+                    ALOGE("%s: failed to create mStreamer for loopback.", __FUNCTION__);
+                    return ret;
+                }
+
+                ALOGD("%s: First start the LoopbackStreamer.", __FUNCTION__);
+                // if (mStreamer == nullptr) {
+                //     mStreamer = new StreamThread(this);
+                // }
+                mStreamer->run("LoopbackStreamer");
+                mStreamer->waitStartComplete();
+            }
+        }
+        ret = DEV_OPEN_SUCC;
+    } else if (nreq.mRequest == "close") {
+        mLoopbackDevice.mRefcount--;
+        if (mLoopbackDevice.mRefcount == 0) {
+            ALOGD("%s: stop the loopback polling thread", __FUNCTION__);
+            mStreamer->stop();
+            mStreamer->join();
+            mStreamer->mStopRequest = false;
+            // mStreamer->mStarted = false;
+        }
+        response = "CloseDone";
+        ret = DEV_CLOSE_SUCC;
+    } else {
+        ALOGW("%s: unsupported command %s", __FUNCTION__, nreq.mRequest.c_str());
+        ret = DEV_IGN;
+    }
+
+    return ret;
+}
+
+int LoopbackListener::StreamThread::stop()
+{
+    {
+        std::lock_guard<std::mutex> lock(mStopMutex);
+        mStopRequest = true;
+        mStopCondition.notify_all();
+    }
+    ALOGI("%s: notify LoopbackStreamer to quit.", __FUNCTION__);
+    return 0;
+}
+
+int LoopbackListener::StreamThread::notifyStartComplete()
+{
+    {
+        std::lock_guard<std::mutex> lock(mStartMutex);
+        mStarted = true;
+        mStartCondition.notify_all();
+    }
+    ALOGI("%s: notify LoopbackStreamer start completed.", __FUNCTION__);
+
+    return 0;
+} 
+
+int LoopbackListener::StreamThread::waitStartComplete()
+{
+    std::unique_lock<std::mutex> lk(mStartMutex);
+    mStartCondition.wait(lk, [this]{
+        return (this->mStarted == true); });
+
+    return 0;
+}
+
+bool LoopbackListener::StreamThread::threadLoop()
+{
+    if (mParent->mVirtualCameraDevice == nullptr) {
+        ALOGE("%s: error: mVirtualCameraDevice == nullptr", __FUNCTION__);
+        return true;
+    }
+    mParent->mVirtualCameraDevice->open();
+    mParent->mVirtualCameraDevice->configureStream();
+    sp<FrameBuffer> buf = new FrameBuffer();
+    if (buf == nullptr) {
+        ALOGE("%s: error cannot alloc frame buffer.", __FUNCTION__);
+        return false;
+    }
+    buf->mFourcc = V4L2_PIX_FMT_UYVY;
+    // buf->mDataSize = buf->mWidth * buf->mHeight * 2 + buf->mWidth * 2;
+    buf->mDataSize = buf->mWidth * buf->mHeight * 2;
+    buf->mData = nullptr; //new uint8_t(buf->mDataSize);
+    if (mParent->mLoopbackDevice.configureLoopback(1920, 1080, V4L2_PIX_FMT_UYVY) < 0) {
+        return false;
+    }
+    ALOGD("LoopbackStreamer starts to loop.");
+    while (true) {
+        {
+            std::unique_lock<std::mutex> lock(mStopMutex);
+            if (mStopRequest == true) {
+                break;
+            }
+        }
+        if (mParent->mVirtualCameraDevice->enqueueFrame(buf)) {
+            ALOGE("%s: cannot register frame buffer of failed.", __FUNCTION__);
+            break;
+        }
+        mParent->mVirtualCameraDevice->dequeueFrame(buf);
+        // int n = mParent->mLoopbackDevice.writeStream(buf->mData, buf->mDataSize);
+        int n = mParent->mLoopbackDevice.writeStream(buf->mData, 1920*1080*2);
+        if (n < 0) {
+            ALOGE("%s: write stream %d bytes", __FUNCTION__, n);
+        }
+        delete(buf->mData);
+        buf->mData = nullptr;
+        if (mParent->mLoopbackDevice.mStreaming == false) {
+            mParent->mLoopbackDevice.mStreaming = true;
+            notifyStartComplete();
+        }
+    }
+    mParent->mVirtualCameraDevice->close();
+
+    return false;
+}
+
+int LicCamAgent::initialize(sp<VirtualCameraDevice> vcam, const std::string& loopbackPath)
+{
+    mListener = LoopbackListener::getInstance();
+    if (mListener == nullptr) {
+        ALOGE("%s: failed to fetch loopback listener.", __FUNCTION__);
+        return -1;
+    }
+    mListener->initialize(vcam, loopbackPath);
+
+    if (mNetlink.openNetlink() < 0) {
+        return -1;
+    }
+    mAgent = new AgentThread(this);
+    ALOGD("Starts LicCamAgent thread");
+    mAgent->run("LicCamAgent");
+    return 0;
+}
+
+int LicCamAgent::AgentThread::stop()
+{
+    {
+        std::lock_guard<std::mutex> lock(mStopMutex);
+        mStopRequest = true;
+        mStopCondition.notify_all();
+    }
+    ALOGD("%s: notify AgentThread to quit.", __FUNCTION__);
+    return 0;
+}
+
+bool LicCamAgent::AgentThread::threadLoop()
+{
+    std::string request, response;
+    //Block access here.
+    mParent->mNetlink.receiveRequest(request);
+    ALOGD("%s: receive request %s", __FUNCTION__, request.c_str());
+    DeviceStatus status = mParent->mListener->handleRequest(request, response);
+    switch(status)
+    {
+        case DEV_OPEN_SUCC:
+            response = "OpenDone";
+            break;
+        case DEV_CLOSE_SUCC:
+            response = "CloseDone";
+            break;
+        case DEV_BUSY:
+            response = "DeviceBusy";
+            break;
+        default:
+            response = "Invalid";
+            break;
+    }
+    ALOGD("%s: send response %s", __FUNCTION__, response.c_str());
+    mParent->mNetlink.sendResponse(response);
+
+    return true;
+}
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
diff --git a/camera/device/3.4/default/Virtual/MediaControl.cpp b/camera/device/3.4/default/Virtual/MediaControl.cpp
new file mode 100644
index 000000000..5b2c4798c
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/MediaControl.cpp
@@ -0,0 +1,799 @@
+/*
+ * Copyright (C) 2011 The Android Open Source Project
+ * Copyright (C) 2015-2021 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "MediaControl.h"
+// #include "VideoCapture.h"
+
+#include <linux/v4l2-mediabus.h>
+#include <linux/videodev2.h>
+
+#include <stack>
+#include <string>
+#include <dirent.h>
+#include <dlfcn.h>
+#include "SysCall.h"
+
+using std::string;
+using std::vector;
+
+#define MAX_SYS_NAME 64
+#define MAX_TARGET_NAME 256
+#define ARRAY_SIZE(array) (sizeof(array) / sizeof((array)[0]))
+
+#define MAX_RETRY 5
+
+struct MediaLink {
+    MediaPad* source;
+    MediaPad* sink;
+    MediaLink* twin;
+    uint32_t flags;
+    uint32_t padding[3];
+};
+
+struct MediaPad {
+    MediaEntity* entity;
+    uint32_t index;
+    uint32_t flags;
+    uint32_t padding[3];
+};
+
+struct MediaEntity {
+    media_entity_desc info;
+    MediaPad* pads;
+    MediaLink* links;
+    unsigned int maxLinks;
+    unsigned int numLinks;
+
+    char devname[32];
+};
+
+MediaControl* MediaControl::sInstance = nullptr;
+std::mutex MediaControl::sLock;
+
+int MediaControl::createLink() {
+    int ret = 0;
+    McFormat formats[] = {
+        {.entityName = "Intel IPU6 CSI-2 1",
+         .pad = 0,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "Intel IPU6 CSI-2 1",
+         .pad = 1,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "isx031 a",
+         .pad = 0,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "isx031 b",
+         .pad = 0,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "isx031 c",
+         .pad = 0,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "isx031 d",
+         .pad = 0,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "TI960 a",
+         .pad = 0,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "TI960 a",
+         .pad = 1,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "TI960 a",
+         .pad = 2,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "TI960 a",
+         .pad = 3,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "TI960 a",
+         .pad = 4,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "Intel IPU6 CSI2 BE SOC 0",
+         .pad = 0,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "Intel IPU6 CSI2 BE SOC 0",
+         .pad = 1,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "Intel IPU6 CSI2 BE SOC 0",
+         .pad = 2,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "Intel IPU6 CSI2 BE SOC 0",
+         .pad = 3,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+        {.entityName = "Intel IPU6 CSI2 BE SOC 0",
+         .pad = 4,
+         .pixelCode = V4L2_MBUS_FMT_UYVY8_1X16,
+         .width = WIDTH,
+         .height = HEIGHT},
+    };
+
+    McLink links[] = {
+        {.srcEntityName = "isx031 a", .srcPad = 0, .sinkEntityName = "TI960 a", .sinkPad = 0},
+        {.srcEntityName = "isx031 b", .srcPad = 0, .sinkEntityName = "TI960 a", .sinkPad = 1},
+        {.srcEntityName = "isx031 c", .srcPad = 0, .sinkEntityName = "TI960 a", .sinkPad = 2},
+        {.srcEntityName = "isx031 d", .srcPad = 0, .sinkEntityName = "TI960 a", .sinkPad = 3},
+        {.srcEntityName = "TI960 a",
+         .srcPad = 4,
+         .sinkEntityName = "Intel IPU6 CSI-2 1",
+         .sinkPad = 0},
+        {.srcEntityName = "Intel IPU6 CSI-2 1",
+         .srcPad = 1,
+         .sinkEntityName = "Intel IPU6 CSI2 BE SOC 0",
+         .sinkPad = 0},
+        {.srcEntityName = "Intel IPU6 CSI2 BE SOC 0",
+         .srcPad = 1,
+         .sinkEntityName = "Intel IPU6 BE SOC capture 0",
+         .sinkPad = 0},
+        {.srcEntityName = "Intel IPU6 CSI2 BE SOC 0",
+         .srcPad = 2,
+         .sinkEntityName = "Intel IPU6 BE SOC capture 1",
+         .sinkPad = 0},
+        {.srcEntityName = "Intel IPU6 CSI2 BE SOC 0",
+         .srcPad = 3,
+         .sinkEntityName = "Intel IPU6 BE SOC capture 2",
+         .sinkPad = 0},
+        {.srcEntityName = "Intel IPU6 CSI2 BE SOC 0",
+         .srcPad = 4,
+         .sinkEntityName = "Intel IPU6 BE SOC capture 3",
+         .sinkPad = 0},
+    };
+
+    for (McFormat& format : formats) {
+        MediaEntity* entity = getEntityByName(format.entityName.c_str());
+        int fd = -1;
+        if (entity) fd = ::open(entity->devname, O_RDWR);
+
+        ALOGD("@%s, set format for %s  pad: %d", __func__, format.entityName.c_str(), format.pad);
+        if (fd >= 0) {
+            v4l2_mbus_framefmt mbusfmt;
+            memset(&mbusfmt, 0, sizeof(mbusfmt));
+            mbusfmt.width = format.width;
+            mbusfmt.height = format.height;
+            mbusfmt.code = format.pixelCode;
+
+            struct v4l2_subdev_format fmt = {};
+            fmt.pad = format.pad;
+            fmt.which = V4L2_SUBDEV_FORMAT_ACTIVE;
+            fmt.format = mbusfmt;
+            fmt.stream = format.stream;
+            ret = ::ioctl(fd, VIDIOC_SUBDEV_S_FMT, &fmt);
+            close(fd);
+            if (ret < 0) {
+                ALOGE("@%s, Fail set format for %s  pad: %d", __func__, format.entityName.c_str(),
+                      format.pad);
+            }
+        } else {
+            // continue link others when fails
+            ALOGE("@%s, Fail set open device %s", __func__, format.entityName.c_str());
+        }
+    }
+
+    for (McLink& link : links) {
+        ALOGD("@%s, set link : %s --> %s", __func__, link.srcEntityName.c_str(),
+              link.sinkEntityName.c_str());
+        ret = -1;
+        int srcEntity = getEntityIdByName(link.srcEntityName.c_str());
+        int sinkEntity = getEntityIdByName(link.sinkEntityName.c_str());
+        if (srcEntity >= 0 && sinkEntity >= 0) {
+            ret = setupLink(srcEntity, link.srcPad, sinkEntity, link.sinkPad, true);
+        }
+        if (ret < 0) {
+            ALOGE("@%s, Fail set link : %s --> %s", __func__, link.srcEntityName.c_str(),
+                  link.sinkEntityName.c_str());
+        }
+    }
+    return ret;
+}
+
+void MediaControl::getDeviceName(const char* entityName, string& deviceNodeName, bool isSubDev) {
+    const char* filePrefix = "video";
+    const char* dirPath = "/sys/class/video4linux/";
+    if (isSubDev) filePrefix = "v4l-subdev";
+
+    DIR* dp = opendir(dirPath);
+    if (dp == nullptr) {
+        ALOGE("@%s, Fail open : %s", __func__, dirPath);
+    }
+
+    struct dirent* dirp = nullptr;
+    while ((dirp = readdir(dp)) != nullptr) {
+        if ((dirp->d_type == DT_LNK) &&
+            (strncmp(dirp->d_name, filePrefix, strlen(filePrefix)) == 0)) {
+            string subDeviceName = dirPath;
+            subDeviceName += dirp->d_name;
+            subDeviceName += "/name";
+            int fd = open(subDeviceName.c_str(), O_RDONLY);
+            if (fd < 0) {
+                ALOGE("@%s, Fail open : %s", __func__, subDeviceName.c_str());
+            }
+
+            char buf[128] = {'\0'};
+            int len = read(fd, buf, sizeof(buf));
+            close(fd);
+            len--;  // remove "\n"
+            if (len == (int)strlen(entityName) && memcmp(buf, entityName, len) == 0) {
+                deviceNodeName = "/dev/";
+                deviceNodeName += dirp->d_name;
+                break;
+            }
+        }
+    }
+    closedir(dp);
+}
+
+MediaControl* MediaControl::getMediaControlInstance() {
+    MediaControl* mediaControlInstance = nullptr;
+    int retryCount = 0;
+    for (int i = 0; i < MEDIA_DEVICE_MAX_NUM; i++) {
+        std::string fileName = MEDIA_CTL_DEV_NAME;
+        fileName.append(std::to_string(i));
+
+        struct stat fileStat = {};
+        int ret = stat(fileName.c_str(), &fileStat);
+        if (ret != 0) {
+            ALOGE("%s: There is no file %s", __func__, fileName.c_str());
+            retryCount++;
+            usleep(20000);
+            if(retryCount >  MAX_RETRY) {
+                ALOGE("%s fail to find media node \n",__func__);
+                return nullptr;
+            }
+            continue;
+        }
+        ALOGI("Opening media device(%s)", fileName.c_str());
+        SysCall* sc = SysCall::getInstance();
+
+        int fd = sc->open(fileName.c_str(), O_RDWR);
+        if (fd < 0) {
+            ALOGE("%s, Open media device(%s) failed: %s", __func__, fileName.c_str(),
+                  strerror(errno));
+            break;
+        }
+
+        media_device_info info;
+        ret = sc->ioctl(fd, MEDIA_IOC_DEVICE_INFO, &info);
+        if ((ret != -1) &&
+            (0 == strncmp(info.driver, MEDIA_DRIVER_NAME, strlen(MEDIA_DRIVER_NAME)))) {
+            mediaControlInstance = new MediaControl(fileName.c_str());
+        }
+
+        if (sc->close(fd) < 0) {
+            ALOGE("Failed to close media device %s:%s", fileName.c_str(), strerror(errno));
+        }
+
+        if (mediaControlInstance) {
+            ALOGE("%s: media device name:%s", __func__, fileName.c_str());
+            break;
+        }
+    }
+
+    return mediaControlInstance;
+}
+
+MediaControl* MediaControl::getInstance() {
+    std::unique_lock<std::mutex> lock(sLock);
+    if (!sInstance) {
+        sInstance = getMediaControlInstance();
+    }
+    return sInstance;
+}
+
+void MediaControl::releaseInstance() {
+    std::unique_lock<std::mutex> lock(sLock);
+
+    if (sInstance) {
+        delete sInstance;
+        sInstance = nullptr;
+    }
+}
+
+MediaControl::MediaControl(const char* devName) : mDevName(devName) {}
+
+MediaControl::~MediaControl() {}
+
+int MediaControl::initEntities() {
+    mEntities.reserve(100);
+
+    int ret = enumInfo();
+    if (ret != 0) {
+        ALOGE("Enum Info failed.\n");
+        return -1;
+    }
+
+    return 0;
+}
+
+void MediaControl::clearEntities() {
+    auto entity = mEntities.begin();
+    while (entity != mEntities.end()) {
+        delete[] entity->pads;
+        entity->pads = nullptr;
+        delete[] entity->links;
+        entity->links = nullptr;
+        entity = mEntities.erase(entity);
+    }
+}
+
+MediaEntity* MediaControl::getEntityByName(const char* name) {
+    for (auto& entity : mEntities) {
+        if (strcmp(name, entity.info.name) == 0) {
+            return &entity;
+        }
+    }
+
+    return nullptr;
+}
+
+int MediaControl::getEntityIdByName(const char* name) {
+    MediaEntity* entity = getEntityByName(name);
+    if (!entity) {
+        return -1;
+    }
+
+    return entity->info.id;
+}
+
+int MediaControl::resetAllLinks() {
+    for (auto& entity : mEntities) {
+        for (uint32_t j = 0; j < entity.numLinks; j++) {
+            MediaLink* link = &entity.links[j];
+
+            if (link->flags & MEDIA_LNK_FL_IMMUTABLE ||
+                link->source->entity->info.id != entity.info.id) {
+                continue;
+            }
+            int ret = setupLink(link->source, link->sink, link->flags & ~MEDIA_LNK_FL_ENABLED);
+
+            if (ret < 0) return ret;
+        }
+    }
+
+    return 0;
+}
+
+int MediaControl::SetRouting(int fd, v4l2_subdev_route* routes, uint32_t numRoutes) {
+    if (!routes) {
+        ALOGE("%s: Device node %d routes is nullptr", __func__, fd);
+        return -EINVAL;
+    }
+
+    v4l2_subdev_routing r = {routes, numRoutes, {0}};
+
+    int ret = ::ioctl(fd, VIDIOC_SUBDEV_S_ROUTING, &r);
+    if (ret < 0) {
+        ALOGE("%s: Device node %d IOCTL VIDIOC_SUBDEV_S_ROUTING error: %s", __func__, fd,
+              strerror(errno));
+        return ret;
+    }
+
+    return ret;
+}
+
+int MediaControl::GetRouting(int fd, v4l2_subdev_route* routes, uint32_t* numRoutes) {
+    if (!routes || !numRoutes) {
+        ALOGE("%s: Device node %d routes or numRoutes is nullptr", __func__, fd);
+        return -EINVAL;
+    }
+
+    v4l2_subdev_routing r = {routes, *numRoutes, {0}};
+
+    int ret = ::ioctl(fd, VIDIOC_SUBDEV_G_ROUTING, &r);
+    if (ret < 0) {
+        ALOGE("%s: Device node %d IOCTL VIDIOC_SUBDEV_G_ROUTING error: %s", __func__, fd,
+              strerror(errno));
+        return ret;
+    }
+
+    *numRoutes = r.num_routes;
+
+    return ret;
+}
+
+int MediaControl::resetAllRoutes() {
+    for (MediaEntity& entity : mEntities) {
+        struct v4l2_subdev_route routes[entity.info.pads];
+        uint32_t numRoutes = entity.info.pads;
+
+        string subDeviceNodeName;
+        subDeviceNodeName.clear();
+        getDeviceName(entity.info.name, subDeviceNodeName, true);
+        if (subDeviceNodeName.find("/dev/") == std::string::npos) {
+            continue;
+        }
+
+        int fd = ::open(subDeviceNodeName.c_str(), O_RDWR);
+        int ret = GetRouting(fd, routes, &numRoutes);
+        if (ret != 0) {
+            close(fd);
+            continue;
+        }
+
+        for (uint32_t j = 0; j < numRoutes; j++) {
+            routes[j].flags &= ~V4L2_SUBDEV_ROUTE_FL_ACTIVE;
+        }
+
+        ret = SetRouting(fd, routes, numRoutes);
+        if (ret < 0) {
+            ALOGW("@%s, setRouting ret:%d", __func__, ret);
+        }
+        close(fd);
+    }
+
+    return 0;
+}
+
+int MediaControl::setupLink(MediaPad* source, MediaPad* sink, uint32_t flags) {
+    MediaLink* link = nullptr;
+    media_link_desc ulink;
+    uint32_t i;
+    int ret = 0;
+
+    SysCall* sc = SysCall::getInstance();
+    int fd = openDevice();
+    if (fd < 0) goto done;
+
+    for (i = 0; i < source->entity->numLinks; i++) {
+        link = &source->entity->links[i];
+
+        if (link->source->entity == source->entity && link->source->index == source->index &&
+            link->sink->entity == sink->entity && link->sink->index == sink->index)
+            break;
+    }
+
+    if (i == source->entity->numLinks) {
+        ALOGE("%s: Link not found", __func__);
+        ret = -ENOENT;
+        goto done;
+    }
+
+    /* source pad */
+    memset(&ulink, 0, sizeof(media_link_desc));
+    ulink.source.entity = source->entity->info.id;
+    ulink.source.index = source->index;
+    ulink.source.flags = MEDIA_PAD_FL_SOURCE;
+
+    /* sink pad */
+    ulink.sink.entity = sink->entity->info.id;
+    ulink.sink.index = sink->index;
+    ulink.sink.flags = MEDIA_PAD_FL_SINK;
+
+    if (link) ulink.flags = flags | (link->flags & MEDIA_LNK_FL_IMMUTABLE);
+
+    ret = sc->ioctl(fd, MEDIA_IOC_SETUP_LINK, &ulink);
+    if (ret == -1) {
+        ret = -errno;
+        ALOGE("Unable to setup link (%s)", strerror(errno));
+        goto done;
+    }
+
+    if (link) {
+        link->flags = ulink.flags;
+        link->twin->flags = ulink.flags;
+    }
+
+    ret = 0;
+
+done:
+    closeDevice(fd);
+    return ret;
+}
+
+int MediaControl::setupLink(uint32_t srcEntity, uint32_t srcPad, uint32_t sinkEntity,
+                            uint32_t sinkPad, bool enable) {
+    ALOGD("@%s srcEntity %d srcPad %d sinkEntity %d sinkPad %d enable %d", __func__, srcEntity,
+          srcPad, sinkEntity, sinkPad, enable);
+
+    for (auto& entity : mEntities) {
+        for (uint32_t j = 0; j < entity.numLinks; j++) {
+            MediaLink* link = &entity.links[j];
+
+            if ((link->source->entity->info.id == srcEntity) && (link->source->index == srcPad) &&
+                (link->sink->entity->info.id == sinkEntity) && (link->sink->index == sinkPad)) {
+                if (enable)
+                    link->flags |= MEDIA_LNK_FL_ENABLED;
+                else
+                    link->flags &= ~MEDIA_LNK_FL_ENABLED;
+
+                return setupLink(link->source, link->sink, link->flags);
+            }
+        }
+    }
+
+    return -1;
+}
+
+int MediaControl::openDevice() {
+    int fd;
+    SysCall* sc = SysCall::getInstance();
+    if(sc == nullptr) return -1;
+    fd = sc->open(mDevName.c_str(), O_RDWR);
+    if (fd < 0) {
+        ALOGE("Failed to open media device %s: %s", mDevName.c_str(), strerror(errno));
+        return -1;
+    }
+
+    return fd;
+}
+
+void MediaControl::closeDevice(int fd) {
+    if (fd < 0) return;
+
+    SysCall* sc = SysCall::getInstance();
+    if(sc == nullptr) return;
+    if (sc->close(fd) < 0) {
+        ALOGE("Failed to close media device %s: %s", mDevName.c_str(), strerror(errno));
+    }
+}
+
+int MediaControl::enumInfo() {
+    SysCall* sc = SysCall::getInstance();
+    if(sc == nullptr) return 0;
+    if (mEntities.size() > 0) return 0;
+
+    int fd = openDevice();
+    if (fd < 0) {
+        ALOGE("Open device failed.");
+        return fd;
+    }
+
+    media_device_info info;
+    int ret = sc->ioctl(fd, MEDIA_IOC_DEVICE_INFO, &info);
+    if (ret < 0) {
+        ALOGE("Unable to retrieve media device information for device %s (%s)", mDevName.c_str(),
+              strerror(errno));
+        goto done;
+    }
+
+    ret = enumEntities(fd);
+    if (ret < 0) {
+        ALOGE("Unable to enumerate entities for device %s", mDevName.c_str());
+        goto done;
+    }
+
+    // ALOGD("Found %lu entities, enumerating pads and links", mEntities.size());
+
+    ret = enumLinks(fd);
+    if (ret < 0) {
+        ALOGE("Unable to enumerate pads and linksfor device %s", mDevName.c_str());
+        goto done;
+    }
+
+    ret = 0;
+
+done:
+    closeDevice(fd);
+    return ret;
+}
+
+int MediaControl::enumEntities(int fd) {
+    MediaEntity entity;
+    uint32_t id;
+    int ret;
+
+    SysCall* sc = SysCall::getInstance();
+    if(sc == nullptr) return EINVAL;
+    for (id = 0, ret = 0;; id = entity.info.id) {
+        memset(&entity, 0, sizeof(MediaEntity));
+        entity.info.id = id | MEDIA_ENT_ID_FLAG_NEXT;
+
+        ret = sc->ioctl(fd, MEDIA_IOC_ENUM_ENTITIES, &entity.info);
+        if (ret < 0) {
+            ret = errno != EINVAL ? -errno : 0;
+            break;
+        }
+
+        /* Number of links (for outbound links) plus number of pads (for
+         * inbound links) is a good safe initial estimate of the total
+         * number of links.
+         */
+        entity.maxLinks = entity.info.pads + entity.info.links;
+
+        entity.pads = new MediaPad[entity.info.pads];
+        entity.links = new MediaLink[entity.maxLinks];
+        getDevnameFromSysfs(&entity);
+        mEntities.push_back(entity);
+
+        /* Note: carefully to move the follow setting. It must be behind of
+         * push_back to mEntities:
+         * 1. if entity is not pushed back to mEntities, getEntityById will
+         * return NULL.
+         * 2. we can't set entity.pads[i].entity to &entity direct. Because,
+         * entity is stack variable, its scope is just this function.
+         */
+        for (uint32_t i = 0; i < entity.info.pads; ++i) {
+            entity.pads[i].entity = getEntityById(entity.info.id);
+        }
+    }
+
+    return ret;
+}
+
+int MediaControl::getDevnameFromSysfs(MediaEntity* entity) {
+    char sysName[MAX_SYS_NAME] = {'\0'};
+    char target[MAX_TARGET_NAME] = {'\0'};
+    int ret;
+
+    if (!entity) {
+        ALOGE("entity is null.");
+        return -EINVAL;
+    }
+
+    ret = snprintf(sysName, MAX_SYS_NAME, "/sys/dev/char/%u:%u", entity->info.v4l.major,
+                   entity->info.v4l.minor);
+    if (ret <= 0) {
+        ALOGE("create sysName failed ret %d.", ret);
+        return -EINVAL;
+    }
+
+    ret = readlink(sysName, target, MAX_TARGET_NAME);
+    if (ret <= 0) {
+        ALOGE("readlink sysName %s failed ret %d.", sysName, ret);
+        return -EINVAL;
+    }
+
+    char* d = strrchr(target, '/');
+    if (!d) {
+        ALOGE("target is invalid %s.", target);
+        return -EINVAL;
+    }
+    d++; /* skip '/' */
+
+    char* t = strstr(d, "dvb");
+    if (t && t == d) {
+        t = strchr(t, '.');
+        if (!t) {
+            ALOGE("target is invalid %s.", target);
+            return -EINVAL;
+        }
+        *t = '/';
+        d += 3; /* skip "dvb" */
+        snprintf(entity->devname, sizeof(entity->devname), "/dev/dvb/adapter%s", d);
+    } else {
+        snprintf(entity->devname, sizeof(entity->devname), "/dev/%s", d);
+    }
+
+    return 0;
+}
+
+int MediaControl::enumLinks(int fd) {
+    int ret = 0;
+
+    SysCall* sc = SysCall::getInstance();
+    if(sc == nullptr) return -EINVAL;
+    for (auto& entity : mEntities) {
+        media_links_enum links;
+        uint32_t i;
+
+        links.entity = entity.info.id;
+        links.pads = new media_pad_desc[entity.info.pads];
+        links.links = new media_link_desc[entity.info.links];
+
+        if (sc->ioctl(fd, MEDIA_IOC_ENUM_LINKS, &links) < 0) {
+            ret = -errno;
+            ALOGE("Unable to enumerate pads and links (%s).", strerror(errno));
+            delete[] links.pads;
+            delete[] links.links;
+            return ret;
+        }
+
+        for (i = 0; i < entity.info.pads; ++i) {
+            entity.pads[i].entity = getEntityById(entity.info.id);
+            entity.pads[i].index = links.pads[i].index;
+            entity.pads[i].flags = links.pads[i].flags;
+        }
+
+        for (i = 0; i < entity.info.links; ++i) {
+            media_link_desc* link = &links.links[i];
+            MediaLink* fwdlink;
+            MediaLink* backlink;
+            MediaEntity* source;
+            MediaEntity* sink;
+
+            source = getEntityById(link->source.entity);
+            sink = getEntityById(link->sink.entity);
+
+            if (source == nullptr || sink == nullptr) {
+                ALOGE("WARNING entity %u link %u src %u/%u to %u/%u is invalid!", entity.info.id, i,
+                      link->source.entity, link->source.index, link->sink.entity, link->sink.index);
+                ret = -EINVAL;
+            } else {
+                fwdlink = entityAddLink(source);
+                if (fwdlink) {
+                    fwdlink->source = &source->pads[link->source.index];
+                    fwdlink->sink = &sink->pads[link->sink.index];
+                    fwdlink->flags = link->flags;
+                }
+
+                backlink = entityAddLink(sink);
+                if (backlink) {
+                    backlink->source = &source->pads[link->source.index];
+                    backlink->sink = &sink->pads[link->sink.index];
+                    backlink->flags = link->flags;
+                }
+
+                if (fwdlink) fwdlink->twin = backlink;
+                if (backlink) backlink->twin = fwdlink;
+            }
+        }
+
+        delete[] links.pads;
+        delete[] links.links;
+    }
+
+    return ret;
+}
+
+MediaLink* MediaControl::entityAddLink(MediaEntity* entity) {
+    if (entity->numLinks >= entity->maxLinks) {
+        uint32_t maxLinks = entity->maxLinks * 2;
+        MediaLink* links = new MediaLink[maxLinks];
+
+        memcpy(links, entity->links, sizeof(MediaLink) * entity->maxLinks);
+        delete[] entity->links;
+
+        for (uint32_t i = 0; i < entity->numLinks; ++i) {
+            links[i].twin->twin = &links[i];
+        }
+
+        entity->maxLinks = maxLinks;
+        entity->links = links;
+    }
+
+    return &entity->links[entity->numLinks++];
+}
+
+MediaEntity* MediaControl::getEntityById(uint32_t id) {
+    bool next = id & MEDIA_ENT_ID_FLAG_NEXT;
+
+    id &= ~MEDIA_ENT_ID_FLAG_NEXT;
+
+    for (uint32_t i = 0; i < mEntities.size(); i++) {
+        if ((mEntities[i].info.id == id && !next) || (mEntities[0].info.id > id && next)) {
+            return &mEntities[i];
+        }
+    }
+
+    return nullptr;
+}
diff --git a/camera/device/3.4/default/Virtual/NetlinkUtil.cpp b/camera/device/3.4/default/Virtual/NetlinkUtil.cpp
new file mode 100644
index 000000000..c45930b1e
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/NetlinkUtil.cpp
@@ -0,0 +1,176 @@
+#define LOG_TAG "NetlinkUtil@3.4"
+
+#include <vector>
+#include <string>
+
+#include <unistd.h>
+#include <stdlib.h>
+#include <stdlib.h>
+#include <netinet/in.h>
+#include <linux/netlink.h>
+#include <string.h>
+#include <log/log.h>
+
+#include "NetlinkUtil.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+#define NLMSG_SPACE_SIZE 1024
+
+int NetlinkUtil::openNetlink() {
+    struct sockaddr_nl addr;
+    int group = NETLINK_GRP;
+
+    mSock = socket(AF_NETLINK, SOCK_RAW, NETLINK_USERSOCK);
+    if (mSock < 0)
+    {
+        ALOGE("%s: Main: netlink sock < 0.", __FUNCTION__);
+        return mSock;
+    }
+
+    memset((void *)&addr, 0, sizeof(addr));
+    addr.nl_family = AF_NETLINK;
+    addr.nl_pid = getpid();
+
+    if (bind(mSock, (struct sockaddr *)&addr, sizeof(addr)) < 0)
+    {
+        ALOGE("%s bind < 0.", __FUNCTION__);
+        close(mSock);
+        return -1;
+    }
+
+    if (setsockopt(mSock, 270, NETLINK_ADD_MEMBERSHIP, &group, sizeof(group)) < 0)
+    {
+        ALOGE("%s setsockopt < 0.", __FUNCTION__);
+        close(mSock);
+        return -1;
+    }
+
+    return mSock;
+}
+
+int NetlinkUtil::closeNetlink() {
+    if (mSock > 0) {
+        close(mSock);
+    }
+    mSock = -1;
+    return 0;
+}
+
+int NetlinkUtil::receiveRequest(std::string &request)
+{
+    struct sockaddr_nl nladdr;
+    struct msghdr msg;
+    struct iovec iov[2];
+    struct nlmsghdr nlh;
+    char buffer[128];
+    int ret = 0;
+
+    bzero(buffer, sizeof(char) * 128);
+    iov[0].iov_base = (void *)&nlh;
+    iov[0].iov_len = sizeof(nlh);
+    iov[1].iov_base = (void *)buffer;
+    iov[1].iov_len = sizeof(buffer);
+    msg.msg_name = (void *)&(nladdr);
+    msg.msg_namelen = sizeof(nladdr);
+    msg.msg_iov = iov;
+    msg.msg_iovlen = sizeof(iov) / sizeof(iov[0]);
+    //TODO: change the accessing method to nonblock.
+    ret = recvmsg(mSock, &msg, 0);
+    if (ret < 0)
+    {
+        ALOGE("%s: Failed to recv message from v4l2loopback driver.", __FUNCTION__);
+    }
+    else
+    {
+        request = (char *)msg.msg_iov[1].iov_base;
+        ALOGI("%s: received msg %s", __FUNCTION__, request.c_str());
+    }
+
+    return ret;
+}
+
+int NetlinkUtil::sendResponse(const std::string &response)
+{
+    struct msghdr msg;
+    struct nlmsghdr *nlh = NULL;
+    struct iovec iov;
+
+    nlh = (struct nlmsghdr *)malloc(NLMSG_SPACE(NLMSG_SPACE_SIZE));
+    if (nlh == NULL)
+    {
+        ALOGE("%s: Cannot malloc space for nlh.", __FUNCTION__);
+        return -1;
+    }
+    memset(nlh, 0, NLMSG_SPACE_SIZE);
+
+    nlh->nlmsg_len = NLMSG_SPACE(NLMSG_SPACE_SIZE);
+    nlh->nlmsg_pid = getpid();
+    nlh->nlmsg_type = NLMSG_NOOP;
+    nlh->nlmsg_flags = 0;
+
+    strcpy((char *)(NLMSG_DATA(nlh)), response.c_str());
+
+    memset(&iov, 0, sizeof(iov));
+    iov.iov_base = (void *)nlh;
+    iov.iov_len = nlh->nlmsg_len;
+    memset(&msg, 0, sizeof(msg));
+    msg.msg_iov = &iov;
+    msg.msg_iovlen = 1;
+
+    sendmsg(mSock, &msg, 0);
+    free(nlh);
+
+    return 0;
+}
+
+int NetlinkRequest::parse(const std::string &request)
+{
+    char token = '&';
+    std::vector<std::string> res;
+    if (request.empty())
+        return -1;
+
+    if (split(request, token, res) < 4) {
+        ALOGE("%s:Incorrect request: size==0", __FUNCTION__);
+        return -1;
+    }
+    mProcessId = atoi(res[0].c_str());
+    mProcessName = res[1];
+    mRequest = res[2];
+    mCardName = res[3];
+
+    return 0;
+}
+
+int NetlinkRequest::split(const std::string &request, char token, std::vector<std::string> &segments)
+{
+    char split = token;
+    if (request.empty())
+        return -1;
+
+    std::string strs = request + split;
+    size_t pos = strs.find(split);
+
+    while (pos != strs.npos)
+    {
+        std::string temp = strs.substr(0, pos);
+        segments.push_back(temp);
+        strs = strs.substr(pos + 1, strs.size());
+        pos = strs.find(split);
+    }
+
+    return segments.size();
+}
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
\ No newline at end of file
diff --git a/camera/device/3.4/default/Virtual/NodeInfo.cpp b/camera/device/3.4/default/Virtual/NodeInfo.cpp
new file mode 100644
index 000000000..bc5a61842
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/NodeInfo.cpp
@@ -0,0 +1,57 @@
+/*
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "NodeInfo.h"
+#include <string.h>
+
+#define ARRAY_SIZE(array) (sizeof(array) / sizeof((array)[0]))
+
+const VideoNodeInfo gVideoNodeInfos[] = {
+    {VIDEO_GENERIC, "VIDEO_GENERIC", "Generic"},
+    {VIDEO_GENERIC_MEDIUM_EXPO, "VIDEO_GENERIC_MEDIUM_EXPO", "GenericMediumExpo"},
+    {VIDEO_GENERIC_SHORT_EXPO, "VIDEO_GENERIC_SHORT_EXPO", "GenericShortExpo"},
+    // CSI_META_S
+    {VIDEO_CSI_META, "VIDEO_CSI_META", "CsiMeta"},
+    // CSI_META_E
+
+    {VIDEO_PIXEL_ARRAY, "VIDEO_PIXEL_ARRAY", "PixelArray"},
+    {VIDEO_PIXEL_BINNER, "VIDEO_PIXEL_BINNER", "PixelBinner"},
+    {VIDEO_PIXEL_SCALER, "VIDEO_PIXEL_SCALER", "PixelScaler"},
+
+    {VIDEO_ISYS_RECEIVER, "VIDEO_ISYS_RECEIVER", "ISysReceiver"},
+    {VIDEO_ISYS_RECEIVER_BACKEND, "VIDEO_ISYS_RECEIVER_BACKEND", "CsiBE"},
+};
+
+const char* GetNodeName(VideoNodeType nodeType) {
+    int size = ARRAY_SIZE(gVideoNodeInfos);
+    for (int i = 0; i < size; i++) {
+        if (gVideoNodeInfos[i].type == nodeType) {
+            return gVideoNodeInfos[i].shortName;
+        }
+    }
+    return "InvalidNode";
+}
+
+VideoNodeType GetNodeType(const char* nodeName) {
+    int size = ARRAY_SIZE(gVideoNodeInfos);
+    for (int i = 0; i < size; i++) {
+        if (strcmp(gVideoNodeInfos[i].fullName, nodeName) == 0) {
+            return gVideoNodeInfos[i].type;
+        }
+    }
+
+    return VIDEO_GENERIC;
+}
diff --git a/camera/device/3.4/default/Virtual/SysCall.cpp b/camera/device/3.4/default/Virtual/SysCall.cpp
new file mode 100644
index 000000000..b66e0e60b
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/SysCall.cpp
@@ -0,0 +1,171 @@
+/*
+ * Copyright (C) 2015-2021 Intel Corporation.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "SysCall.h"
+#include <stdio.h>
+#include <utils/Log.h>
+
+static int sCreatedCount = 0;
+bool SysCall::sIsInitialized = false;
+SysCall* SysCall::sInstance = nullptr;
+// Guard for singleton instance creation
+std::mutex SysCall::sLock;
+
+/*static*/ SysCall* SysCall::getInstance() {
+    std::unique_lock<std::mutex> lock(sLock);
+    if (!sIsInitialized) {
+        // Use real sys call as default
+        sInstance = new SysCall();
+        sIsInitialized = true;
+    }
+    return sInstance;
+}
+
+void SysCall::updateInstance(SysCall* newSysCall) {
+    ALOGI("%s", __func__);
+    std::unique_lock<std::mutex> lock(sLock);
+    if (sIsInitialized) {
+        sIsInitialized = false;
+    }
+    sInstance = newSysCall;
+    if (newSysCall != nullptr) sIsInitialized = true;
+}
+
+SysCall::SysCall() {
+    sCreatedCount++;
+    ALOGI("Syscall was created %d time", sCreatedCount);
+}
+
+SysCall::~SysCall() {
+    sCreatedCount--;
+    ALOGI("Syscall was destructed %d time", sCreatedCount);
+}
+
+int SysCall::open(const char* pathname, int flags) {
+    return ::open(pathname, flags);
+}
+
+int SysCall::close(int fd) {
+    return ::close(fd);
+}
+
+void* SysCall::mmap(void* addr, size_t len, int prot, int flag, int filedes, off_t off) {
+    return ::mmap(addr, len, prot, flag, filedes, off);
+}
+
+int SysCall::munmap(void* addr, size_t len) {
+    return ::munmap(addr, len);
+}
+
+int SysCall::ioctl(int fd, int request, struct media_device_info* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct media_link_desc* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct media_links_enum* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct media_links_desc* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct media_entity_desc* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct v4l2_capability* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, v4l2_fmtdesc* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, enum v4l2_buf_type* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct v4l2_format* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct v4l2_requestbuffers* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct v4l2_buffers* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct v4l2_buffer* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct v4l2_subdev_format* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct v4l2_subdev_stream* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+int SysCall::ioctl(int fd, int request, struct v4l2_streamon_info* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_ext_controls* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_control* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_queryctrl* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_subdev_selection* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_subdev_routing* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_querymenu* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_event_subscription* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_event* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, struct v4l2_exportbuffer* arg) {
+    return ioctl(fd, request, reinterpret_cast<void*>(arg));
+}
+
+int SysCall::ioctl(int fd, int request, void* arg) {
+    int ret = 0;
+    do {
+        ret = ::ioctl(fd, request, arg);
+    } while (-1 == ret && EINTR == errno);
+
+    return ret;
+}
+
+int SysCall::poll(struct pollfd* pfd, nfds_t nfds, int timeout) {
+    int ret = 0;
+    do {
+        ret = ::poll(pfd, nfds, timeout);
+    } while (-1 == ret && EINTR == errno);
+
+    return ret;
+}
diff --git a/camera/device/3.4/default/Virtual/V4L2CameraDevice.cpp b/camera/device/3.4/default/Virtual/V4L2CameraDevice.cpp
new file mode 100644
index 000000000..b02185986
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/V4L2CameraDevice.cpp
@@ -0,0 +1,440 @@
+#define LOG_TAG "IVIV4L2CameraDevice@3.4"
+
+#include <log/log.h>
+#include <algorithm>
+#include <regex>
+#include <vector>
+
+#include <fcntl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+
+#include "V4L2CameraDevice.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+// constexpr int MAX_RETRY = 3;
+// constexpr int OPEN_RETRY_SLEEP_US = 100000;  // 100ms
+
+const std::regex kDevicePathRE("/dev/video([0-9]+)");
+
+V4L2CameraDevice::V4L2CameraDevice(const std::string& devicePath) {
+    std::smatch sm;
+    mDevicePath = devicePath;
+    if (std::regex_match(devicePath, sm, kDevicePathRE)) {
+        mCameraId = std::to_string(std::stoi(sm[1]));
+    } else {
+        ALOGE("%s: device path match filed for %s", __FUNCTION__, mDevicePath.c_str());
+        return;
+    }
+    ALOGI("%s: create v4l2 caemra device %s", __FUNCTION__, devicePath.c_str());
+    mFd = -1;
+    memset(mRingBuffer, 0, sizeof(FrameBuffer) * RING_BUFFER_SIZE);
+    mFormat.fmt.pix.width = 1920;
+    mFormat.fmt.pix.height = 1080;
+    mFormat.fmt.pix.pixelformat = V4L2_PIX_FMT_UYVY;
+    // mFormat.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
+    // mFormat.frameRate.durationNumerator = 1;
+    // mFormat.frameRate.durationDenominator = 30;
+    mPollingThread = new StreamThread(this);
+    if (mPollingThread == nullptr) {
+        ALOGE("%s: Failed to create polling thread for device %s", __FUNCTION__, mCameraId.c_str());
+    }
+    mPollingThread->mParent = this;
+    mBufferType = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+}
+
+V4L2CameraDevice::~V4L2CameraDevice() {
+    // TODO: need to inform all virtual cameras?
+    // if (mPollingThread != nullptr) {
+    //     mPollingThread->stop();
+    // }
+
+    // if (mFd >= 0) {
+    //     close(mFd);
+    // }
+}
+
+/*
+ * Private methods for video device ops.
+ */
+int V4L2CameraDevice::openDev() {
+    ALOGD("%s", __FUNCTION__);
+    Mutex::Autolock _l(mLock);
+    if (mRefcount == 0) {
+        mFd = open(mDevicePath.c_str(), O_RDWR|O_NONBLOCK);
+        // mFd = open(mDevicePath.c_str(), O_RDWR);
+        if (mFd <= 0) {
+            ALOGE("%s: v4l2 device open %s failed", __FUNCTION__, mDevicePath.c_str());
+            return -1;
+        }
+        struct v4l2_capability capability;
+        int ret = ioctl(mFd, VIDIOC_QUERYCAP, &capability);
+        if (ret < 0) {
+            ALOGW("%s v4l2 QUERYCAP failed", __FUNCTION__);
+            mBufferType = V4L2_BUF_TYPE_VIDEO_OUTPUT;
+        } else if ((capability.capabilities & V4L2_CAP_VIDEO_CAPTURE_MPLANE) != 0) {
+            mBufferType = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+            ALOGD("V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE");
+        } else if ((capability.capabilities & V4L2_CAP_VIDEO_CAPTURE) != 0) {
+            mBufferType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+            ALOGD("V4L2_BUF_TYPE_VIDEO_CAPTURE");
+        } else {
+            mBufferType = V4L2_BUF_TYPE_VIDEO_OUTPUT;
+        }
+
+        struct v4l2_fmtdesc fmt;
+        fmt.type = mBufferType;
+        while (ioctl(mFd, VIDIOC_ENUM_FMT, &fmt) == 0) {
+            fmt.index++;
+            if (fmt.pixelformat == V4L2_PIX_FMT_UYVY) {
+                ALOGD("%s: set mFormat.fmt.pix.pixelformat to V4L2_PIX_FMT_UYVY", __FUNCTION__);
+                mFormat.fmt.pix.pixelformat = fmt.pixelformat;
+                break;
+            }
+        }
+        mPollingThread->run("V4L2Polling");
+    }
+    mRefcount++;
+
+    ALOGD("%s: open cameraId %s, path=%s, mfd=%d", __FUNCTION__, mCameraId.c_str(),
+          mDevicePath.c_str(), mFd);
+
+    return mFd;
+}
+
+int V4L2CameraDevice::closeDev() {
+    {
+        Mutex::Autolock _l(mLock);
+        mRefcount--;
+    }
+
+    ALOGD("%s: closedev with mRefcount=%d", __FUNCTION__, mRefcount);
+    if (mRefcount == 0) {
+        mPollingThread->stop();
+        mPollingThread->join();
+        mPollingThread->reset();
+        close(mFd);
+    }
+
+    return 0;
+}
+
+int V4L2CameraDevice::configureDev() {
+    ALOGD("%s", __FUNCTION__);
+    // v4l2_format fmt;
+    // fmt.fmt.pix.width = 1920;
+    // fmt.fmt.pix.height = 1080;
+    // fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_UYVY;
+    // fmt.type = mBufferType;
+    mFormat.type = mBufferType;
+    return configureDev(mFormat);
+}
+
+int V4L2CameraDevice::configureDev(const v4l2_format& v4l2Fmt) {
+    ALOGD("%s", __FUNCTION__);
+    // Mutex::Autolock _l(mLock);
+    if (mStreaming == true) {
+        ALOGW("%s: cannot configure the stream for device %s, the device is streaming.",
+              __FUNCTION__, mCameraId.c_str());
+        return -1;
+    }
+    mFormat = v4l2Fmt;
+    // Set format
+    if (mFormat.type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) {
+        mFormat.fmt.pix_mp.num_planes = 1;
+        mFormat.fmt.pix_mp.plane_fmt[0].bytesperline = (mFormat.fmt.pix.width * 2 + 15) & ~(16 - 1);
+        mFormat.fmt.pix_mp.plane_fmt[0].sizeimage =
+                mFormat.fmt.pix_mp.plane_fmt[0].bytesperline * mFormat.fmt.pix.height;
+        ALOGD("configureDev fmt.fmt.pix_mp.plane_fmt[0].sizeimage=%d",
+              mFormat.fmt.pix_mp.plane_fmt[0].sizeimage);
+    } else {
+        mFormat.fmt.pix.field = V4L2_FIELD_NONE;
+        ALOGD("mostly likely uvc fmt.fmt.pix.width=%u fmt.fmt.pix.height=%u", mFormat.fmt.pix.width,
+              mFormat.fmt.pix.height);
+    }
+
+    int ret = ioctl(mFd, VIDIOC_S_FMT, &mFormat);
+    if (ret < 0) {
+        ALOGE("%s: S_FMT ioctl failed: %s", __FUNCTION__, strerror(errno));
+        return -errno;
+    }
+    ALOGD("%s: S_FMT expect %c%c%c%c %dx%d, got %c%c%c%c %dx%d", __FUNCTION__,
+          v4l2Fmt.fmt.pix.pixelformat & 0xFF, (v4l2Fmt.fmt.pix.pixelformat >> 8) & 0xFF,
+          (v4l2Fmt.fmt.pix.pixelformat >> 16) & 0xFF, (v4l2Fmt.fmt.pix.pixelformat >> 24) & 0xFF,
+          v4l2Fmt.fmt.pix.width, v4l2Fmt.fmt.pix.height, mFormat.fmt.pix.pixelformat & 0xFF,
+          (mFormat.fmt.pix.pixelformat >> 8) & 0xFF, (mFormat.fmt.pix.pixelformat >> 16) & 0xFF,
+          (mFormat.fmt.pix.pixelformat >> 24) & 0xFF, mFormat.fmt.pix.width,
+          mFormat.fmt.pix.height);
+
+    // We do not check the fps which by default 30.
+    v4l2_requestbuffers req_buffers{};
+    req_buffers.type = mBufferType;
+    req_buffers.memory = V4L2_MEMORY_MMAP;
+    req_buffers.count = REQUEST_BUFFER_COUNT;
+    if (ioctl(mFd, VIDIOC_REQBUFS, &req_buffers) < 0) {
+        ALOGE("%s: VIDIOC_REQBUFS failed: %s", __FUNCTION__, strerror(errno));
+        return -errno;
+    }
+
+    // query buffers and queue buffers
+    for (uint32_t i = 0; i < req_buffers.count; i++) {
+        struct v4l2_buffer buffer = {
+                .index = i, .type = V4L2_BUF_TYPE_VIDEO_CAPTURE, .memory = V4L2_MEMORY_MMAP};
+
+        if (mBufferType == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) {
+            struct v4l2_plane planes[1];
+            buffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+            buffer.m.planes = planes;
+            buffer.length = 1;
+        }
+
+        if (ioctl(mFd, VIDIOC_QUERYBUF, &buffer) < 0) {
+            ALOGE("%s: QUERYBUF %d failed: %s", __FUNCTION__, i, strerror(errno));
+            return -errno;
+        }
+        mRingBuffer[i].mWidth = 1920;
+        mRingBuffer[i].mHeight = 1080;
+
+        if (mBufferType == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) {
+            mRingBuffer[i].mDataSize = buffer.m.planes[0].length;
+            mRingBuffer[i].mData = (uint8_t*)mmap(NULL, mRingBuffer[i].mDataSize, PROT_READ, MAP_SHARED,
+                                            mFd, buffer.m.planes[0].m.mem_offset);
+            ALOGD("i=%d: buffer.m.planes[0].length=%d, buffer.length=%d, buffer.m.offset=%d",
+                i, buffer.m.planes[0].length, buffer.length, buffer.m.planes[0].m.mem_offset);
+        } else {
+            mRingBuffer[i].mDataSize = (buffer.bytesused == 0) ? buffer.length : buffer.bytesused;
+            mRingBuffer[i].mData = (uint8_t*)mmap(NULL, mRingBuffer[i].mDataSize, PROT_READ, MAP_SHARED,
+                                            mFd, buffer.m.offset);
+            ALOGD("i=%d: buffer.m.offset=%d buffer.length=%d buffer.bytesused=%d",
+                    i, buffer.m.offset, buffer.length, buffer.bytesused);
+        }
+        if (mRingBuffer[i].mData == MAP_FAILED) {
+            ALOGE("%s: error in mmap.", __FUNCTION__);
+            return -1;
+        }
+        ALOGD("%s: QBUF %d", __FUNCTION__, i);
+        if (ioctl(mFd, VIDIOC_QBUF, &buffer) < 0) {
+            ALOGE("%s: QBUF %d failed: %s", __FUNCTION__, i, strerror(errno));
+            return -errno;
+        }
+    }
+
+    return 0;
+}
+
+int V4L2CameraDevice::streamOnDev() {
+    ALOGD("%s", __FUNCTION__);
+    // Mutex::Autolock _l(mLock);
+
+    int ret = ioctl(mFd, VIDIOC_STREAMON, &mBufferType);
+    if (ret < 0) {
+        ALOGE("%s: VIDIOC_STREAMON ioctl failed: %s", __FUNCTION__, strerror(errno));
+        return -errno;
+    }
+
+    ALOGD("Streamed on. %d", mBufferType);
+    mStreaming = true;
+    return ret;
+}
+
+int V4L2CameraDevice::streamOffDev() {
+    ALOGD("%s", __FUNCTION__);
+    // VIDIOC_STREAMOFF
+    // Mutex::Autolock _l(mLock);
+    if (ioctl(mFd, VIDIOC_STREAMOFF, &mBufferType) < 0) {
+        ALOGE("%s: STREAMOFF failed: %s", __FUNCTION__, strerror(errno));
+        return -errno;
+    }
+
+    for (int idx = 0; idx < RING_BUFFER_SIZE; idx++) {
+        munmap(mRingBuffer[idx].mData, mRingBuffer[idx].mDataSize);
+    }
+
+    // VIDIOC_REQBUFS: clear buffers
+    v4l2_requestbuffers req_buffers{};
+    req_buffers.type = mBufferType;
+    req_buffers.memory = V4L2_MEMORY_MMAP;
+    req_buffers.count = 0;
+    if (ioctl(mFd, VIDIOC_REQBUFS, &req_buffers) < 0) {
+        ALOGE("%s: REQBUFS failed: %s", __FUNCTION__, strerror(errno));
+        return -errno;
+    }
+
+    mStreaming = false;
+    // ALOGI("i2cset -y -f 15 0x3d 0x01 0x01 b");
+    // system("i2cset -y -f 15 0x3d 0x01 0x01 b");
+    return 0;
+}
+
+int V4L2CameraDevice::enqueueFrame(int idx) {
+    ALOGV("%s idx=%d", __FUNCTION__, idx);
+    Mutex::Autolock _l(mLock);
+    if (idx < 0 || idx >= REQUEST_BUFFER_COUNT) {
+        ALOGE("%s: index %d exceeds the limitation %d", __FUNCTION__, idx, RING_BUFFER_SIZE);
+        return -1;
+    }
+    v4l2_buffer buffer{};
+    buffer.type = mBufferType;
+    buffer.memory = V4L2_MEMORY_MMAP;
+    buffer.index = idx;
+    if (mBufferType == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) {
+        struct v4l2_plane planes[1];
+        buffer.m.planes = planes;
+        buffer.length = 1;
+        buffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        // buffer.m.planes[0].bytesused = 1920*1080*2;
+    }
+    if (TEMP_FAILURE_RETRY(ioctl(mFd, VIDIOC_QBUF, &buffer)) < 0) {
+        ALOGE("%s: QBUF fails", __FUNCTION__);
+        return -1;
+    }
+    return 0;
+}
+
+int V4L2CameraDevice::dequeueFrame() {
+    ALOGV("%s", __FUNCTION__);
+    Mutex::Autolock _l(mLock);
+    v4l2_buffer buffer{};
+    // int idx = -1;
+
+    buffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    buffer.memory = V4L2_MEMORY_MMAP;
+    if (mBufferType == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) {
+        struct v4l2_plane planes[1];
+        buffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        buffer.m.planes = planes;
+        buffer.length = 1;
+    }
+
+    if (ioctl(mFd, VIDIOC_DQBUF, &buffer) != 0) {
+        ALOGE("%s: VIDIOC_DQBUF fails: %s", __FUNCTION__, strerror(errno));
+        return -1;
+    }
+
+    // idx = buffer.index;
+    // mRingBuffer[idx].mWidth = 1920;
+    // mRingBuffer[idx].mHeight = 1080;
+    // mRingBuffer[idx].mDataSize = (mBufferType == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE)
+    //                                      ? buffer.m.planes[0].length : buffer.m.offset;
+
+    // mRingBuffer[idx].mData = (uint8_t*)mmap(NULL, mRingBuffer[idx].mDataSize, PROT_READ,
+    // MAP_SHARED, mFd, buffer.bytesused); if (mRingBuffer[idx].mData == nullptr) {
+    //     ALOGE("%s: error in mmap.", __FUNCTION__);
+    //     return -1;
+    // }
+
+    // ALOGE("%s: %d index in mmap with datasize: %d, buffer.byteused=%d.", __FUNCTION__, idx,
+    // mRingBuffer[idx].mDataSize, buffer.bytesused); ALOGE("%s: buffer.m.offset=%d,
+    // buffer.m.planes[0].length=%d.", __FUNCTION__, buffer.m.offset, buffer.m.planes[0].length);
+    // ALOGE("%s: index in mmap with datasize: %p.", __FUNCTION__, mRingBuffer[idx].mData);
+
+    return buffer.index;
+}
+
+// V4L2CameraDevice::StreamThread::StreamThread()
+
+bool V4L2CameraDevice::StreamThread::threadLoop() {
+    ALOGI("%s: threadLoop starts up. mfd=%d", __FUNCTION__, mParent->mFd);
+    if (mParent->mFd <= 0) {
+        ALOGE("%s: cannot open the real device", __FUNCTION__);
+        return false;
+    }
+
+    // configure and set v4l2device.
+    if (mParent->configureDev() < 0) {
+        ALOGE("%s: cannot configure the real device", __FUNCTION__);
+        return false;
+    }
+
+    if (mParent->streamOnDev() < 0) {
+        ALOGE("%s: cannot stream the real device", __FUNCTION__);
+        return false;
+    }
+
+    fd_set fds;
+    int fd = mParent->mFd;
+    FD_ZERO(&fds);
+    FD_SET(fd, &fds);
+
+    while (true) {
+        {
+            std::unique_lock<std::mutex> lock(mStopMutex);
+            if (mStopRequest == true) {
+                break;
+            }
+        }
+
+        timeval tv;
+        tv.tv_sec = 1;
+        tv.tv_usec = 0; // 10ms
+        int ret = select(fd + 1, &fds, nullptr, nullptr, &tv);
+        if (ret == -1) {
+            ALOGE("%s Error: select failed.", __FUNCTION__);
+            break;
+        } else if (ret == 0) {
+            // No data available, continue the loop
+            continue;
+        }
+
+        int idx = mParent->dequeueFrame();
+        if (idx == -1) {
+            ALOGE("%s: incorrect dequeued frame index.", __FUNCTION__);
+            continue;
+        }
+
+        for (auto iter : mParent->mVirtualBuffers) {
+            sp<FrameBuffer> virtBuffer = iter.second;
+            std::lock_guard<std::mutex> lock(virtBuffer->mReadyMutex);
+
+            if (virtBuffer->mData == nullptr) {
+                virtBuffer->mData = new uint8_t[mParent->mRingBuffer[idx].mDataSize];
+                virtBuffer->mDataSize = mParent->mRingBuffer[idx].mDataSize;
+            }
+            ALOGV("%s: memcpy buf[%d]. virtbuf size: %d, src size: %d", __FUNCTION__, idx,
+                  virtBuffer->mDataSize, mParent->mRingBuffer[idx].mDataSize);
+            memcpy(virtBuffer->mData, mParent->mRingBuffer[idx].mData, virtBuffer->mDataSize);
+            virtBuffer->mWidth = mParent->mRingBuffer[idx].mWidth;
+            virtBuffer->mHeight = mParent->mRingBuffer[idx].mHeight;
+            virtBuffer->mFourcc = mParent->mRingBuffer[idx].mFourcc;
+
+            virtBuffer->mReady = true;
+            ALOGV("%s notify...", __FUNCTION__);
+            virtBuffer->mReadyCondition.notify_one();
+        }
+
+        //mParent->mVirtualBuffers.clear();
+        mParent->enqueueFrame(idx);
+    }
+
+    if (mParent->streamOffDev() < 0) {
+        ALOGE("%s: cannot streamoff device", __FUNCTION__);
+        return false;
+    }
+    ALOGI("%s: Thread quits.", __FUNCTION__);
+
+    return false;
+}
+
+int V4L2CameraDevice::StreamThread::stop() {
+    {
+        std::lock_guard<std::mutex> lock(mStopMutex);
+        mStopRequest = true;
+        mStopCondition.notify_all();
+    }
+    ALOGI("%s: notify polling thread of cameraId %s to quit.", __FUNCTION__,
+          mParent->mCameraId.c_str());
+    return 0;
+}
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
diff --git a/camera/device/3.4/default/Virtual/VirtualCameraDevice.cpp b/camera/device/3.4/default/Virtual/VirtualCameraDevice.cpp
new file mode 100644
index 000000000..cb4344001
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/VirtualCameraDevice.cpp
@@ -0,0 +1,1024 @@
+
+#define LOG_TAG "IVIVirtCamDev@3.4"
+//#define LOG_NDEBUG 0
+#include <log/log.h>
+
+#include <algorithm>
+#include <array>
+#include <regex>
+
+#include "android-base/macros.h"
+#include "CameraMetadata.h"
+#include "../../3.2/default/include/convert.h"
+#include "CaptureManager.h"
+#include "VirtualCameraDevice.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof(a[0]))
+
+#define UPDATE(tag, data, size)                    \
+do {                                               \
+  if (metadata->update((tag), (data), (size))) {   \
+    ALOGE("Update " #tag " failed!");              \
+    return -EINVAL;                                \
+  }                                                \
+} while (0)
+
+const std::array<uint32_t, /*size*/ 3> kSupportedFourCCs{
+    {V4L2_PIX_FMT_UYVY, V4L2_PIX_FMT_YUYV, V4L2_PIX_FMT_Z16}};  // double braces required in C++11
+
+VirtualCameraDevice::VirtualCameraDevice(const std::string& cameraId)
+{
+    mCameraId = cameraId;
+    mDeviceStatus = INVALID;
+    mCfg = ExternalCameraConfig::loadFromCfg("/vendor/etc/external_camera_config.xml");
+    mCaptureManager = CaptureManager::getInstance();
+}
+
+VirtualCameraDevice::~VirtualCameraDevice() {
+    delete mCaptureManager;
+    mCaptureManager = nullptr;
+}
+
+bool VirtualCameraDevice::isInitFailedLocked() {
+    if (!mInitialized) {
+        status_t ret = initCameraCharacteristics();
+        if (ret != OK) {
+            ALOGE("%s: init camera characteristics failed: errorno %d", __FUNCTION__, ret);
+            mInitFailed = true;
+        }
+        mInitialized = true;
+    }
+    return mInitFailed;
+}
+
+Return<void> VirtualCameraDevice::getResourceCost(
+        ICameraDevice::getResourceCost_cb _hidl_cb) {
+    CameraResourceCost resCost;
+    // Set lower value of resourceCost 100->25 to allow 4 apps access 4 different camera devices.
+    // Otherwise, resourceCost exceed MaxCost of CameraService, and causes app evicted.
+    resCost.resourceCost = 25;
+    _hidl_cb(Status::OK, resCost);
+    return Void();
+}
+
+Return<void> VirtualCameraDevice::dumpState(const ::android::hardware::hidl_handle&)
+{
+    return Void();
+}
+
+Return<void> VirtualCameraDevice::getCameraCharacteristics(ICameraDevice::getCameraCharacteristics_cb _hidl_cb)
+{
+    // Mutex::Autolock _l(mLock);
+    V3_2::CameraMetadata hidlChars;
+
+    if (isInitFailedLocked()) {
+        _hidl_cb(Status::INTERNAL_ERROR, hidlChars);
+        return Void();
+    }
+
+    const camera_metadata_t* rawMetadata = mCameraCharacteristics.getAndLock();
+    V3_2::implementation::convertToHidl(rawMetadata, &hidlChars);
+    _hidl_cb(Status::OK, hidlChars);
+    mCameraCharacteristics.unlock(rawMetadata);
+    return Void();
+}
+
+bool VirtualCameraDevice::isInitFailed()
+{
+    if (!mInitialized) {
+        status_t ret = initCameraCharacteristics();
+        if (ret != OK) {
+            ALOGE("%s: init camera characteristics failed: errorno %d", __FUNCTION__, ret);
+            mInitFailed = true;
+        }
+        mInitialized = true;
+    }
+    return mInitFailed;
+}
+
+Return<void> VirtualCameraDevice::open(const sp<ICameraDeviceCallback>& callback, ICameraDevice::open_cb _hidl_cb)
+{
+    Status status = Status::OK;
+    //Need to translate this call to Physical device ?
+    sp<VirtualCameraDeviceSession> session = nullptr;
+
+    if (callback == nullptr) {
+        ALOGE("%s: cannot open camera %s. callback is null!",
+                __FUNCTION__, mCameraId.c_str());
+        _hidl_cb(Status::ILLEGAL_ARGUMENT, nullptr);
+        return Void();
+    }
+
+    if (isInitFailed()) {
+        ALOGE("%s: cannot open camera %s. camera init failed!",
+                __FUNCTION__, mCameraId.c_str());
+        _hidl_cb(Status::INTERNAL_ERROR, nullptr);
+        return Void();
+    }
+
+    mLock.lock();
+    ALOGD("%s: Initializing device for camera %s", __FUNCTION__, mCameraId.c_str());
+    session = mSession.promote();
+    if (session != nullptr && !session->isClosed()) {
+        ALOGE("%s: cannot open an already opened camera!", __FUNCTION__);
+        mLock.unlock();
+        _hidl_cb(Status::CAMERA_IN_USE, nullptr);
+        return Void();
+    }
+
+    //Request to open mapping physical device
+    if(mCaptureManager->openRequest(mCameraId) <= 0) {
+        ALOGE("%s: failed to open physical camera ", __FUNCTION__);
+        mLock.unlock();
+        _hidl_cb(Status::INTERNAL_ERROR, nullptr);
+        return Void();
+    }
+
+    session = createSession(
+            callback, mSupportedFormats, mCroppingType,
+            mCameraCharacteristics, mCameraId);
+    if (session == nullptr) {
+        ALOGE("%s: camera device session allocation failed", __FUNCTION__);
+        mLock.unlock();
+        _hidl_cb(Status::INTERNAL_ERROR, nullptr);
+        return Void();
+    }
+    if (session->isInitFailed()) {
+        ALOGE("%s: camera device session init failed", __FUNCTION__);
+        session = nullptr;
+        mLock.unlock();
+        _hidl_cb(Status::INTERNAL_ERROR, nullptr);
+        return Void();
+    }
+
+    mSession = session;
+    mLock.unlock();
+
+    _hidl_cb(status, session->getInterface());
+    return Void();
+}
+
+
+status_t VirtualCameraDevice::initCameraCharacteristics() {
+    // Mutex::AutoLock _l(parent->mLock);
+    if (mInitialized == true) {
+        ALOGW("%s: device has been initialized.", __FUNCTION__);
+        return OK;
+    }
+
+    // Write fix camera characteristic values for android hal.
+    // initDefaultCharsKeys
+    // Call V4L2CameraDevice::initDefaultCharsKeys
+    status_t ret = initDefaultCharsKeys(&mCameraCharacteristics);
+    if (ret != OK) {
+        ALOGE("%s: init default characteristics key failed: errorno %d", __FUNCTION__, ret);
+        mCameraCharacteristics.clear();
+        return ret;
+    }
+
+    ret = initCameraControlsCharsKeys(&mCameraCharacteristics);
+    if (ret != OK) {
+        ALOGE("%s: init camera control characteristics key failed: errorno %d", __FUNCTION__, ret);
+        mCameraCharacteristics.clear();
+        return ret;
+    }
+
+    ret = initOutputCharsKeys(&mCameraCharacteristics);
+    if (ret != OK) {
+        ALOGE("%s: init output characteristics key failed: errorno %d", __FUNCTION__, ret);
+        mCameraCharacteristics.clear();
+        return ret;
+    }
+
+    ret = initAvailableCapabilities(&mCameraCharacteristics);
+    if (ret != OK) {
+        ALOGE("%s: init available capabilities key failed: errorno %d", __FUNCTION__, ret);
+        mCameraCharacteristics.clear();
+        return ret;
+    }
+
+    return OK;
+}
+
+
+status_t VirtualCameraDevice::initAvailableCapabilities(
+        ::android::hardware::camera::common::V1_0::helper::CameraMetadata* metadata) {
+    
+    if (mSupportedFormats.empty()) {
+        ALOGE("%s: Supported formats list is empty", __FUNCTION__);
+        return UNKNOWN_ERROR;
+    }
+
+    bool hasDepth = false;
+    bool hasColor = false;
+    for (const auto& fmt : mSupportedFormats) {
+        switch (fmt.fourcc) {
+            case V4L2_PIX_FMT_Z16: hasDepth = true; break;
+            case V4L2_PIX_FMT_MJPEG: hasColor = true; break;
+            case V4L2_PIX_FMT_YUYV: hasColor = true; break;
+            case V4L2_PIX_FMT_UYVY: hasColor = true; break;
+            default: ALOGW("%s: Unsupported format found", __FUNCTION__);
+        }
+    }
+
+    std::vector<uint8_t> availableCapabilities;
+    if (hasDepth) {
+        availableCapabilities.push_back(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_DEPTH_OUTPUT);
+    }
+    if (hasColor) {
+        availableCapabilities.push_back(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE);
+    }
+    if(!availableCapabilities.empty()) {
+        UPDATE(ANDROID_REQUEST_AVAILABLE_CAPABILITIES, availableCapabilities.data(),
+            availableCapabilities.size());
+    }
+    return OK;
+}
+
+
+status_t VirtualCameraDevice::initDefaultCharsKeys(::android::hardware::camera::common::V1_0::helper::CameraMetadata* metadata)
+{
+    const uint8_t hardware_level = ANDROID_INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL;
+    UPDATE(ANDROID_INFO_SUPPORTED_HARDWARE_LEVEL, &hardware_level, 1);
+
+    // android.colorCorrection
+    const uint8_t availableAberrationModes[] = {
+        ANDROID_COLOR_CORRECTION_ABERRATION_MODE_OFF};
+    UPDATE(ANDROID_COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES,
+           availableAberrationModes, ARRAY_SIZE(availableAberrationModes));
+
+    // android.control
+    const uint8_t antibandingMode =
+        ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO;
+    UPDATE(ANDROID_CONTROL_AE_AVAILABLE_ANTIBANDING_MODES,
+           &antibandingMode, 1);
+
+    const int32_t controlMaxRegions[] = {/*AE*/ 0, /*AWB*/ 0, /*AF*/ 0};
+    UPDATE(ANDROID_CONTROL_MAX_REGIONS, controlMaxRegions,
+           ARRAY_SIZE(controlMaxRegions));
+
+    const uint8_t videoStabilizationMode =
+        ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF;
+    UPDATE(ANDROID_CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES,
+           &videoStabilizationMode, 1);
+
+    const uint8_t awbAvailableMode = ANDROID_CONTROL_AWB_MODE_AUTO;
+    UPDATE(ANDROID_CONTROL_AWB_AVAILABLE_MODES, &awbAvailableMode, 1);
+
+    const uint8_t aeAvailableMode = ANDROID_CONTROL_AE_MODE_ON;
+    UPDATE(ANDROID_CONTROL_AE_AVAILABLE_MODES, &aeAvailableMode, 1);
+
+    const uint8_t availableFffect = ANDROID_CONTROL_EFFECT_MODE_OFF;
+    UPDATE(ANDROID_CONTROL_AVAILABLE_EFFECTS, &availableFffect, 1);
+
+    const uint8_t controlAvailableModes[] = {ANDROID_CONTROL_MODE_OFF,
+                                             ANDROID_CONTROL_MODE_AUTO};
+    UPDATE(ANDROID_CONTROL_AVAILABLE_MODES, controlAvailableModes,
+           ARRAY_SIZE(controlAvailableModes));
+
+    // android.edge
+    const uint8_t edgeMode = ANDROID_EDGE_MODE_OFF;
+    UPDATE(ANDROID_EDGE_AVAILABLE_EDGE_MODES, &edgeMode, 1);
+
+    // android.flash
+    const uint8_t flashInfo = ANDROID_FLASH_INFO_AVAILABLE_FALSE;
+    UPDATE(ANDROID_FLASH_INFO_AVAILABLE, &flashInfo, 1);
+
+    // android.hotPixel
+    const uint8_t hotPixelMode = ANDROID_HOT_PIXEL_MODE_OFF;
+    UPDATE(ANDROID_HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES, &hotPixelMode, 1);
+
+    // android.jpeg
+    // TODO: revoke jpeg.
+    const int32_t jpegAvailableThumbnailSizes[] = {0, 0,
+                                                  240, 180};
+    UPDATE(ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES, jpegAvailableThumbnailSizes,
+           ARRAY_SIZE(jpegAvailableThumbnailSizes));
+
+    const int32_t jpegMaxSize = mCfg.maxJpegBufSize;
+    UPDATE(ANDROID_JPEG_MAX_SIZE, &jpegMaxSize, 1);
+
+    // android.lens
+    const uint8_t focusDistanceCalibration =
+            ANDROID_LENS_INFO_FOCUS_DISTANCE_CALIBRATION_UNCALIBRATED;
+    UPDATE(ANDROID_LENS_INFO_FOCUS_DISTANCE_CALIBRATION, &focusDistanceCalibration, 1);
+
+    const uint8_t opticalStabilizationMode =
+        ANDROID_LENS_OPTICAL_STABILIZATION_MODE_OFF;
+    UPDATE(ANDROID_LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION,
+           &opticalStabilizationMode, 1);
+
+    const uint8_t facing = ANDROID_LENS_FACING_EXTERNAL;
+    UPDATE(ANDROID_LENS_FACING, &facing, 1);
+
+    // android.noiseReduction
+    const uint8_t noiseReductionMode = ANDROID_NOISE_REDUCTION_MODE_OFF;
+    UPDATE(ANDROID_NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES,
+           &noiseReductionMode, 1);
+    UPDATE(ANDROID_NOISE_REDUCTION_MODE, &noiseReductionMode, 1);
+
+    const int32_t partialResultCount = 1;
+    UPDATE(ANDROID_REQUEST_PARTIAL_RESULT_COUNT, &partialResultCount, 1);
+
+    // This means pipeline latency of X frame intervals. The maximum number is 4.
+    const uint8_t requestPipelineMaxDepth = 4;
+    UPDATE(ANDROID_REQUEST_PIPELINE_MAX_DEPTH, &requestPipelineMaxDepth, 1);
+
+    // Three numbers represent the maximum numbers of different types of output
+    // streams simultaneously. The types are raw sensor, processed (but not
+    // stalling), and processed (but stalling). For usb limited mode, raw sensor
+    // is not supported. Stalling stream is JPEG. Non-stalling streams are
+    // YUV_420_888 or YV12.
+    const int32_t requestMaxNumOutputStreams[] = {
+            /*RAW*/0,
+            /*Processed*/2,
+            /*Stall*/1};
+    UPDATE(ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS, requestMaxNumOutputStreams,
+           ARRAY_SIZE(requestMaxNumOutputStreams));
+
+    // Limited mode doesn't support reprocessing.
+    const int32_t requestMaxNumInputStreams = 0;
+    UPDATE(ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS, &requestMaxNumInputStreams,
+           1);
+
+    // android.scaler
+    // TODO: b/72263447 V4L2_CID_ZOOM_*
+    const float scalerAvailableMaxDigitalZoom[] = {1};
+    UPDATE(ANDROID_SCALER_AVAILABLE_MAX_DIGITAL_ZOOM,
+           scalerAvailableMaxDigitalZoom,
+           ARRAY_SIZE(scalerAvailableMaxDigitalZoom));
+
+    const uint8_t croppingType = ANDROID_SCALER_CROPPING_TYPE_CENTER_ONLY;
+    UPDATE(ANDROID_SCALER_CROPPING_TYPE, &croppingType, 1);
+
+    const int32_t testPatternModes[] = {
+        ANDROID_SENSOR_TEST_PATTERN_MODE_OFF};
+    UPDATE(ANDROID_SENSOR_AVAILABLE_TEST_PATTERN_MODES, testPatternModes,
+           ARRAY_SIZE(testPatternModes));
+
+    const uint8_t timestampSource = ANDROID_SENSOR_INFO_TIMESTAMP_SOURCE_UNKNOWN;
+    UPDATE(ANDROID_SENSOR_INFO_TIMESTAMP_SOURCE, &timestampSource, 1);
+
+    // Orientation is a bit odd for external camera, but consider it as the orientation
+    // between the external camera sensor (which is usually landscape) and the device's
+    // natural display orientation. For devices with natural landscape display (ex: tablet/TV), the
+    // orientation should be 0. For devices with natural portrait display (phone), the orientation
+    // should be 270.
+    const int32_t orientation = mCfg.orientation;
+    UPDATE(ANDROID_SENSOR_ORIENTATION, &orientation, 1);
+
+    // android.shading
+    const uint8_t availabeMode = ANDROID_SHADING_MODE_OFF;
+    UPDATE(ANDROID_SHADING_AVAILABLE_MODES, &availabeMode, 1);
+
+    // android.statistics
+    const uint8_t faceDetectMode = ANDROID_STATISTICS_FACE_DETECT_MODE_OFF;
+    UPDATE(ANDROID_STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES, &faceDetectMode,
+           1);
+
+    const int32_t maxFaceCount = 0;
+    UPDATE(ANDROID_STATISTICS_INFO_MAX_FACE_COUNT, &maxFaceCount, 1);
+
+    const uint8_t availableHotpixelMode =
+        ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE_OFF;
+    UPDATE(ANDROID_STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES,
+           &availableHotpixelMode, 1);
+
+    const uint8_t lensShadingMapMode =
+        ANDROID_STATISTICS_LENS_SHADING_MAP_MODE_OFF;
+    UPDATE(ANDROID_STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES,
+           &lensShadingMapMode, 1);
+
+    // android.sync
+    const int32_t maxLatency = ANDROID_SYNC_MAX_LATENCY_UNKNOWN;
+    UPDATE(ANDROID_SYNC_MAX_LATENCY, &maxLatency, 1);
+
+    /* Other sensor/RAW realted keys:
+     * android.sensor.info.colorFilterArrangement -> no need if we don't do RAW
+     * android.sensor.info.physicalSize           -> not available
+     * android.sensor.info.whiteLevel             -> not available/not needed
+     * android.sensor.info.lensShadingApplied     -> not needed
+     * android.sensor.info.preCorrectionActiveArraySize -> not available/not needed
+     * android.sensor.blackLevelPattern           -> not available/not needed
+     */
+    const int32_t availableRequestKeys[] = {
+        ANDROID_COLOR_CORRECTION_ABERRATION_MODE,
+        ANDROID_CONTROL_AE_ANTIBANDING_MODE,
+        ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION,
+        ANDROID_CONTROL_AE_LOCK,
+        ANDROID_CONTROL_AE_MODE,
+        ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER,
+        ANDROID_CONTROL_AE_TARGET_FPS_RANGE,
+        ANDROID_CONTROL_AF_MODE,
+        ANDROID_CONTROL_AF_TRIGGER,
+        ANDROID_CONTROL_AWB_LOCK,
+        ANDROID_CONTROL_AWB_MODE,
+        ANDROID_CONTROL_CAPTURE_INTENT,
+        ANDROID_CONTROL_EFFECT_MODE,
+        ANDROID_CONTROL_MODE,
+        ANDROID_CONTROL_SCENE_MODE,
+        ANDROID_CONTROL_VIDEO_STABILIZATION_MODE,
+        ANDROID_FLASH_MODE,
+        ANDROID_JPEG_ORIENTATION,
+        ANDROID_JPEG_QUALITY,
+        ANDROID_JPEG_THUMBNAIL_QUALITY,
+        ANDROID_JPEG_THUMBNAIL_SIZE,
+        ANDROID_LENS_OPTICAL_STABILIZATION_MODE,
+        ANDROID_NOISE_REDUCTION_MODE,
+        ANDROID_SCALER_CROP_REGION,
+        ANDROID_SENSOR_TEST_PATTERN_MODE,
+        ANDROID_STATISTICS_FACE_DETECT_MODE,
+        ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE};
+    UPDATE(ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS, availableRequestKeys,
+           ARRAY_SIZE(availableRequestKeys));
+    
+    const int32_t availableResultKeys[] = {
+        ANDROID_COLOR_CORRECTION_ABERRATION_MODE,
+        ANDROID_CONTROL_AE_ANTIBANDING_MODE,
+        ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION,
+        ANDROID_CONTROL_AE_LOCK,
+        ANDROID_CONTROL_AE_MODE,
+        ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER,
+        ANDROID_CONTROL_AE_STATE,
+        ANDROID_CONTROL_AE_TARGET_FPS_RANGE,
+        ANDROID_CONTROL_AF_MODE,
+        ANDROID_CONTROL_AF_STATE,
+        ANDROID_CONTROL_AF_TRIGGER,
+        ANDROID_CONTROL_AWB_LOCK,
+        ANDROID_CONTROL_AWB_MODE,
+        ANDROID_CONTROL_AWB_STATE,
+        ANDROID_CONTROL_CAPTURE_INTENT,
+        ANDROID_CONTROL_EFFECT_MODE,
+        ANDROID_CONTROL_MODE,
+        ANDROID_CONTROL_SCENE_MODE,
+        ANDROID_CONTROL_VIDEO_STABILIZATION_MODE,
+        ANDROID_FLASH_MODE,
+        ANDROID_FLASH_STATE,
+        ANDROID_JPEG_ORIENTATION,
+        ANDROID_JPEG_QUALITY,
+        ANDROID_JPEG_THUMBNAIL_QUALITY,
+        ANDROID_JPEG_THUMBNAIL_SIZE,
+        ANDROID_LENS_OPTICAL_STABILIZATION_MODE,
+        ANDROID_NOISE_REDUCTION_MODE,
+        ANDROID_REQUEST_PIPELINE_DEPTH,
+        ANDROID_SCALER_CROP_REGION,
+        ANDROID_SENSOR_TIMESTAMP,
+        ANDROID_STATISTICS_FACE_DETECT_MODE,
+        ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE,
+        ANDROID_STATISTICS_LENS_SHADING_MAP_MODE,
+        ANDROID_STATISTICS_SCENE_FLICKER};
+    UPDATE(ANDROID_REQUEST_AVAILABLE_RESULT_KEYS, availableResultKeys,
+           ARRAY_SIZE(availableResultKeys));
+
+    UPDATE(ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS,
+           AVAILABLE_CHARACTERISTICS_KEYS_3_4.data(),
+           AVAILABLE_CHARACTERISTICS_KEYS_3_4.size());
+
+    return OK;
+}
+
+status_t VirtualCameraDevice::initCameraControlsCharsKeys(::android::hardware::camera::common::V1_0::helper::CameraMetadata* metadata)
+{
+    const int32_t controlAeCompensationRange[] = {0, 0};
+    UPDATE(ANDROID_CONTROL_AE_COMPENSATION_RANGE, controlAeCompensationRange,
+           ARRAY_SIZE(controlAeCompensationRange));
+    const camera_metadata_rational_t controlAeCompensationStep[] = {{0, 1}};
+    UPDATE(ANDROID_CONTROL_AE_COMPENSATION_STEP, controlAeCompensationStep,
+           ARRAY_SIZE(controlAeCompensationStep));
+
+
+    // TODO: Check V4L2_CID_AUTO_FOCUS_*.
+    const uint8_t afAvailableModes[] = {ANDROID_CONTROL_AF_MODE_AUTO,
+                                        ANDROID_CONTROL_AF_MODE_OFF};
+    UPDATE(ANDROID_CONTROL_AF_AVAILABLE_MODES, afAvailableModes,
+           ARRAY_SIZE(afAvailableModes));
+
+    // TODO: V4L2_CID_SCENE_MODE
+    const uint8_t availableSceneMode = ANDROID_CONTROL_SCENE_MODE_DISABLED;
+    UPDATE(ANDROID_CONTROL_AVAILABLE_SCENE_MODES, &availableSceneMode, 1);
+
+    // TODO: V4L2_CID_3A_LOCK
+    const uint8_t aeLockAvailable = ANDROID_CONTROL_AE_LOCK_AVAILABLE_FALSE;
+    UPDATE(ANDROID_CONTROL_AE_LOCK_AVAILABLE, &aeLockAvailable, 1);
+    const uint8_t awbLockAvailable = ANDROID_CONTROL_AWB_LOCK_AVAILABLE_FALSE;
+    UPDATE(ANDROID_CONTROL_AWB_LOCK_AVAILABLE, &awbLockAvailable, 1);
+
+    // TODO: V4L2_CID_ZOOM_*
+    const float scalerAvailableMaxDigitalZoom[] = {1};
+    UPDATE(ANDROID_SCALER_AVAILABLE_MAX_DIGITAL_ZOOM,
+           scalerAvailableMaxDigitalZoom,
+           ARRAY_SIZE(scalerAvailableMaxDigitalZoom));
+
+    return OK;
+}
+
+template <size_t SIZE>
+status_t VirtualCameraDevice::initOutputCharsKeysByFormat(
+        ::android::hardware::camera::common::V1_0::helper::CameraMetadata* metadata,
+        uint32_t fourcc, const std::array<int, SIZE>& halFormats,
+        int streamConfigTag, int streamConfiguration, int minFrameDuration, int stallDuration) {
+    if (mSupportedFormats.empty()) {
+        ALOGE("%s: Init supported format list failed", __FUNCTION__);
+        return UNKNOWN_ERROR;
+    }
+
+    std::vector<int32_t> streamConfigurations;
+    std::vector<int64_t> minFrameDurations;
+    std::vector<int64_t> stallDurations;
+
+    for (const auto& supportedFormat : mSupportedFormats) {
+        if (supportedFormat.width != 1920) {
+            continue;
+        }
+        if (supportedFormat.fourcc != fourcc) {
+            // Skip 4CCs not meant for the halFormats
+            continue;
+        }
+
+        for (const auto& format : halFormats) {
+            ALOGD("streamconf [%dx%d] %d %s", supportedFormat.width, supportedFormat.height, __LINE__, __FILE__);
+            streamConfigurations.push_back(format);
+            streamConfigurations.push_back(supportedFormat.width);
+            streamConfigurations.push_back(supportedFormat.height);
+            streamConfigurations.push_back(streamConfigTag);
+        }
+
+        int64_t minFrameDuration = std::numeric_limits<int64_t>::max();
+        for (const auto& fr : supportedFormat.frameRates) {
+            // 1000000000LL < (2^32 - 1) and
+            // fr.durationNumerator is uint32_t, so no overflow here
+            int64_t frameDuration = 1000000000LL * fr.durationNumerator /
+                    fr.durationDenominator;
+            if (frameDuration < minFrameDuration) {
+                minFrameDuration = frameDuration;
+            }
+        }
+
+        for (const auto& format : halFormats) {
+            minFrameDurations.push_back(format);
+            minFrameDurations.push_back(supportedFormat.width);
+            minFrameDurations.push_back(supportedFormat.height);
+            minFrameDurations.push_back(minFrameDuration);
+        }
+
+        // The stall duration is 0 for non-jpeg formats. For JPEG format, stall
+        // duration can be 0 if JPEG is small. Here we choose 1 sec for JPEG.
+        // TODO: b/72261675. Maybe set this dynamically
+        for (const auto& format : halFormats) {
+            const int64_t NS_TO_SECOND = 1000000000;
+            int64_t stall_duration =
+                    (format == HAL_PIXEL_FORMAT_BLOB) ? NS_TO_SECOND : 0;
+            stallDurations.push_back(format);
+            stallDurations.push_back(supportedFormat.width);
+            stallDurations.push_back(supportedFormat.height);
+            stallDurations.push_back(stall_duration);
+        }
+    }
+
+    UPDATE(streamConfiguration, streamConfigurations.data(), streamConfigurations.size());
+
+    UPDATE(minFrameDuration, minFrameDurations.data(), minFrameDurations.size());
+
+    UPDATE(stallDuration, stallDurations.data(), stallDurations.size());
+
+    return true;
+}
+
+
+bool VirtualCameraDevice::calculateMinFps(
+        ::android::hardware::camera::common::V1_0::helper::CameraMetadata* metadata) {
+    std::set<int32_t> framerates;
+    int32_t minFps = std::numeric_limits<int32_t>::max();
+
+    for (const auto& supportedFormat : mSupportedFormats) {
+        for (const auto& fr : supportedFormat.frameRates) {
+            int32_t frameRateInt = static_cast<int32_t>(fr.getDouble());
+            if (minFps > frameRateInt) {
+                minFps = frameRateInt;
+            }
+            framerates.insert(frameRateInt);
+        }
+    }
+
+    std::vector<int32_t> fpsRanges;
+    // FPS ranges
+    for (const auto& framerate : framerates) {
+        // Empirical: webcams often have close to 2x fps error and cannot support fixed fps range
+        fpsRanges.push_back(framerate / 2);
+        fpsRanges.push_back(framerate);
+    }
+    minFps /= 2;
+    int64_t maxFrameDuration = 1000000000LL / minFps;
+
+    UPDATE(ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES, fpsRanges.data(), fpsRanges.size());
+
+    UPDATE(ANDROID_SENSOR_INFO_MAX_FRAME_DURATION, &maxFrameDuration, 1);
+
+    return true;
+}
+
+status_t VirtualCameraDevice::initOutputCharsKeys(
+        ::android::hardware::camera::common::V1_0::helper::CameraMetadata* metadata) {
+    //TODO : get camera instance from CaptureManager later
+     unique_fd fd(::open("/dev/video0", O_RDWR));
+        if (fd.get() < 0) {
+            ALOGE("%s: v4l2 device open failed", __FUNCTION__);
+            return DEAD_OBJECT;
+        }
+    initSupportedFormatsLocked(fd.get());
+    if (mSupportedFormats.empty()) {
+        ALOGE("%s: Init supported format list failed", __FUNCTION__);
+        return UNKNOWN_ERROR;
+    }
+    std::array<int, /*size*/ 3> halFormats{{HAL_PIXEL_FORMAT_BLOB, HAL_PIXEL_FORMAT_YCbCr_420_888,
+                                            HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED}};
+    if (mSupportedFormats.empty()) {
+        ALOGE("%s: init supported format list failed.", __FUNCTION__);
+        return UNKNOWN_ERROR;
+    }
+
+    for (const auto& supportedFormat : mSupportedFormats) {
+        switch (supportedFormat.fourcc) {
+        case V4L2_PIX_FMT_YUYV:
+            initOutputCharsKeysByFormat(metadata, V4L2_PIX_FMT_YUYV, halFormats,
+                                        ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+                                        ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+                                        ANDROID_SCALER_AVAILABLE_MIN_FRAME_DURATIONS,
+                                        ANDROID_SCALER_AVAILABLE_STALL_DURATIONS);
+            break;
+        case V4L2_PIX_FMT_UYVY:
+            initOutputCharsKeysByFormat(metadata, V4L2_PIX_FMT_UYVY, halFormats,
+                                        ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+                                        ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+                                        ANDROID_SCALER_AVAILABLE_MIN_FRAME_DURATIONS,
+                                        ANDROID_SCALER_AVAILABLE_STALL_DURATIONS);
+            break;
+        default:
+            ALOGW("%s: format %c%c%c%c is not supported!", __FUNCTION__,
+                  supportedFormat.fourcc & 0xFF, (supportedFormat.fourcc >> 8) & 0xFF,
+                  (supportedFormat.fourcc >> 16) & 0xFF, (supportedFormat.fourcc >> 24) & 0xFF);
+        }
+    }
+
+    // Caculate fps, we set it as fixed 30fps.
+    calculateMinFps(metadata);
+    int32_t activeArraySize[] = {0, 0, 1920, 1080};
+    int32_t pixelArraySize[] = {0, 0, 1920, 1080};
+    UPDATE(ANDROID_SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE, activeArraySize,
+           ARRAY_SIZE(activeArraySize));
+    UPDATE(ANDROID_SENSOR_INFO_ACTIVE_ARRAY_SIZE, activeArraySize, ARRAY_SIZE(activeArraySize));
+    UPDATE(ANDROID_SENSOR_INFO_PIXEL_ARRAY_SIZE, pixelArraySize, ARRAY_SIZE(pixelArraySize));
+
+    return OK;
+}
+
+
+void VirtualCameraDevice::getFrameRateList(
+        int fd, double fpsUpperBound, SupportedV4L2Format* format) {
+    format->frameRates.clear();
+
+    v4l2_frmivalenum frameInterval{
+            .index = 0,
+            .pixel_format = format->fourcc,
+            .width = format->width,
+            .height = format->height,
+    };
+
+    for (frameInterval.index = 0;
+            TEMP_FAILURE_RETRY(ioctl(fd, VIDIOC_ENUM_FRAMEINTERVALS, &frameInterval)) == 0;
+            ++frameInterval.index) {
+        if (frameInterval.type == V4L2_FRMIVAL_TYPE_DISCRETE) {
+            if (frameInterval.discrete.numerator != 0) {
+                SupportedV4L2Format::FrameRate fr = {
+                        frameInterval.discrete.numerator,
+                        frameInterval.discrete.denominator};
+                double framerate = fr.getDouble();
+                if (framerate > fpsUpperBound) {
+                    continue;
+                }
+                ALOGV("index:%d, format:%c%c%c%c, w %d, h %d, framerate %f",
+                    frameInterval.index,
+                    frameInterval.pixel_format & 0xFF,
+                    (frameInterval.pixel_format >> 8) & 0xFF,
+                    (frameInterval.pixel_format >> 16) & 0xFF,
+                    (frameInterval.pixel_format >> 24) & 0xFF,
+                    frameInterval.width, frameInterval.height, framerate);
+                format->frameRates.push_back(fr);
+            }
+        }
+    }
+
+    if (format->frameRates.empty()) {
+        ALOGE("%s: failed to get supported frame rates for format:%c%c%c%c w %d h %d",
+                __FUNCTION__,
+                frameInterval.pixel_format & 0xFF,
+                (frameInterval.pixel_format >> 8) & 0xFF,
+                (frameInterval.pixel_format >> 16) & 0xFF,
+                (frameInterval.pixel_format >> 24) & 0xFF,
+                frameInterval.width, frameInterval.height);
+        //Only for mipi uyvy case.
+        SupportedV4L2Format::FrameRate fr = {1, 30};
+        format->frameRates.push_back(fr);
+    }
+}
+
+void VirtualCameraDevice::trimSupportedFormats(
+        CroppingType cropType,
+        /*inout*/std::vector<SupportedV4L2Format>* pFmts) {
+    std::vector<SupportedV4L2Format>& sortedFmts = *pFmts;
+    if (cropType == VERTICAL) {
+        std::sort(sortedFmts.begin(), sortedFmts.end(),
+                [](const SupportedV4L2Format& a, const SupportedV4L2Format& b) -> bool {
+                    if (a.width == b.width) {
+                        return a.height < b.height;
+                    }
+                    return a.width < b.width;
+                });
+    } else {
+        std::sort(sortedFmts.begin(), sortedFmts.end(),
+                [](const SupportedV4L2Format& a, const SupportedV4L2Format& b) -> bool {
+                    if (a.height == b.height) {
+                        return a.width < b.width;
+                    }
+                    return a.height < b.height;
+                });
+    }
+
+    if (sortedFmts.size() == 0) {
+        ALOGE("%s: input format list is empty!", __FUNCTION__);
+        return;
+    }
+
+    const auto& maxSize = sortedFmts[sortedFmts.size() - 1];
+    float maxSizeAr = ASPECT_RATIO(maxSize);
+
+    // Remove formats that has aspect ratio not croppable from largest size
+    std::vector<SupportedV4L2Format> out;
+    for (const auto& fmt : sortedFmts) {
+        float ar = ASPECT_RATIO(fmt);
+        if (isAspectRatioClose(ar, maxSizeAr)) {
+            out.push_back(fmt);
+        } else if (cropType == HORIZONTAL && ar < maxSizeAr) {
+            out.push_back(fmt);
+        } else if (cropType == VERTICAL && ar > maxSizeAr) {
+            out.push_back(fmt);
+        } else {
+            ALOGV("%s: size (%d,%d) is removed due to unable to crop %s from (%d,%d)",
+                __FUNCTION__, fmt.width, fmt.height,
+                cropType == VERTICAL ? "vertically" : "horizontally",
+                maxSize.width, maxSize.height);
+        }
+    }
+    sortedFmts = out;
+}
+
+
+std::vector<SupportedV4L2Format> VirtualCameraDevice::getCandidateSupportedFormatsLocked(
+    int fd, CroppingType cropType,
+    const std::vector<ExternalCameraConfig::FpsLimitation>& fpsLimits,
+    const std::vector<ExternalCameraConfig::FpsLimitation>& depthFpsLimits,
+    const Size& minStreamSize,
+    bool depthEnabled) {
+    std::vector<SupportedV4L2Format> outFmts;
+    struct v4l2_fmtdesc fmtdesc {
+        .index = 0,
+        .type = V4L2_BUF_TYPE_VIDEO_CAPTURE};
+    int ret = 0;
+
+    //Set mBufferType to capture or mplane.
+    v4l2_capability caps;
+    if (ioctl(fd, VIDIOC_QUERYCAP, &caps)) {
+        ALOGE("Cannot QUERYCAP the device file.");
+        return outFmts;
+    }
+
+    if ((caps.capabilities & V4L2_CAP_VIDEO_CAPTURE) != 0) {
+        ALOGD("Device buffer type V4L2_CAP_VIDEO_CAPTURE");
+        fmtdesc.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+    } else if ((caps.capabilities & V4L2_CAP_VIDEO_CAPTURE_MPLANE) != 0) {
+        ALOGD("Device buffer type V4L2_CAP_VIDEO_CAPTURE_MPLANE");
+        fmtdesc.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        SupportedV4L2Format format {
+            .width = 1920,
+            .height = 1080,
+            .fourcc = V4L2_PIX_FMT_UYVY,
+        };
+        updateFpsBounds(fd, cropType, fpsLimits, format, outFmts);
+        trimSupportedFormats(cropType, &outFmts);
+        return outFmts;
+    }
+
+    while (ret == 0) {
+        ret = TEMP_FAILURE_RETRY(ioctl(fd, VIDIOC_ENUM_FMT, &fmtdesc));
+        ALOGV("index:%d,ret:%d, format:%c%c%c%c", fmtdesc.index, ret,
+                fmtdesc.pixelformat & 0xFF,
+                (fmtdesc.pixelformat >> 8) & 0xFF,
+                (fmtdesc.pixelformat >> 16) & 0xFF,
+                (fmtdesc.pixelformat >> 24) & 0xFF);
+        if (ret == 0 && !(fmtdesc.flags & V4L2_FMT_FLAG_EMULATED)) {
+            auto it = std::find (
+                    kSupportedFourCCs.begin(), kSupportedFourCCs.end(), fmtdesc.pixelformat);
+            if (it != kSupportedFourCCs.end()) {
+                // Found supported format
+                v4l2_frmsizeenum frameSize {
+                        .index = 0,
+                        .pixel_format = fmtdesc.pixelformat};
+                for (; TEMP_FAILURE_RETRY(ioctl(fd, VIDIOC_ENUM_FRAMESIZES, &frameSize)) == 0;
+                        ++frameSize.index) {
+                    if (frameSize.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+                        ALOGV("index:%d, format:%c%c%c%c, w %d, h %d", frameSize.index,
+                            fmtdesc.pixelformat & 0xFF,
+                            (fmtdesc.pixelformat >> 8) & 0xFF,
+                            (fmtdesc.pixelformat >> 16) & 0xFF,
+                            (fmtdesc.pixelformat >> 24) & 0xFF,
+                            frameSize.discrete.width, frameSize.discrete.height);
+                        // Disregard h > w formats so all aspect ratio (h/w) <= 1.0
+                        // This will simplify the crop/scaling logic down the road
+                        if (frameSize.discrete.height > frameSize.discrete.width) {
+                            continue;
+                        }
+                        // Discard all formats which is smaller than minStreamSize
+                        if (frameSize.discrete.width < minStreamSize.width
+                            || frameSize.discrete.height < minStreamSize.height) {
+                            continue;
+                        }
+                        SupportedV4L2Format format {
+                            .width = frameSize.discrete.width,
+                            .height = frameSize.discrete.height,
+                            .fourcc = fmtdesc.pixelformat
+                        };
+
+                        if (format.fourcc == V4L2_PIX_FMT_Z16 && depthEnabled) {
+                            updateFpsBounds(fd, cropType, depthFpsLimits, format, outFmts);
+                        } else {
+                            updateFpsBounds(fd, cropType, fpsLimits, format, outFmts);
+                        }
+                    }
+                }
+            }
+        }
+        fmtdesc.index++;
+    }
+    trimSupportedFormats(cropType, &outFmts);
+    return outFmts;
+}
+
+
+void VirtualCameraDevice::updateFpsBounds(
+    int fd, CroppingType cropType,
+    const std::vector<ExternalCameraConfig::FpsLimitation>& fpsLimits, SupportedV4L2Format format,
+    std::vector<SupportedV4L2Format>& outFmts) {
+    double fpsUpperBound = -1.0;
+    for (const auto& limit : fpsLimits) {
+        if (cropType == VERTICAL) {
+            if (format.width <= limit.size.width) {
+                fpsUpperBound = limit.fpsUpperBound;
+                break;
+            }
+        } else {  // HORIZONTAL
+            if (format.height <= limit.size.height) {
+                fpsUpperBound = limit.fpsUpperBound;
+                break;
+            }
+        }
+    }
+    if (fpsUpperBound < 0.f) {
+        return;
+    }
+
+    getFrameRateList(fd, fpsUpperBound, &format);
+    // HAL tries to support even if the Camera sensor retuns
+    // empty supported frame rate list. This will help to
+    // support different types of Cameras since some
+    // USB Cameras will not return the proper frame rates.
+    outFmts.push_back(format);
+}
+
+void VirtualCameraDevice::initSupportedFormatsLocked(int fd) {
+    std::vector<SupportedV4L2Format> horizontalFmts = getCandidateSupportedFormatsLocked(
+        fd, HORIZONTAL, mCfg.fpsLimits, mCfg.depthFpsLimits, mCfg.minStreamSize, mCfg.depthEnabled);
+    std::vector<SupportedV4L2Format> verticalFmts = getCandidateSupportedFormatsLocked(
+        fd, VERTICAL, mCfg.fpsLimits, mCfg.depthFpsLimits, mCfg.minStreamSize, mCfg.depthEnabled);
+
+    size_t horiSize = horizontalFmts.size();
+    size_t vertSize = verticalFmts.size();
+
+    if (horiSize == 0 && vertSize == 0) {
+        ALOGE("%s: cannot find suitable cropping type!", __FUNCTION__);
+        return;
+    }
+
+    if (horiSize == 0) {
+        mSupportedFormats = verticalFmts;
+        mCroppingType = VERTICAL;
+        return;
+    } else if (vertSize == 0) {
+        mSupportedFormats = horizontalFmts;
+        mCroppingType = HORIZONTAL;
+        return;
+    }
+
+    const auto& maxHoriSize = horizontalFmts[horizontalFmts.size() - 1];
+    const auto& maxVertSize = verticalFmts[verticalFmts.size() - 1];
+
+    // Try to keep largest possible output size
+    // When they are the same or ambiguous, pick the one support more sizes
+    if (maxHoriSize.width == maxVertSize.width &&
+            maxHoriSize.height == maxVertSize.height) {
+        if (horiSize > vertSize) {
+            mSupportedFormats = horizontalFmts;
+            mCroppingType = HORIZONTAL;
+        } else {
+            mSupportedFormats = verticalFmts;
+            mCroppingType = VERTICAL;
+        }
+    } else if (maxHoriSize.width >= maxVertSize.width &&
+            maxHoriSize.height >= maxVertSize.height) {
+        mSupportedFormats = horizontalFmts;
+        mCroppingType = HORIZONTAL;
+    } else if (maxHoriSize.width <= maxVertSize.width &&
+            maxHoriSize.height <= maxVertSize.height) {
+        mSupportedFormats = verticalFmts;
+        mCroppingType = VERTICAL;
+    } else {
+        if (horiSize > vertSize) {
+            mSupportedFormats = horizontalFmts;
+            mCroppingType = HORIZONTAL;
+        } else {
+            mSupportedFormats = verticalFmts;
+            mCroppingType = VERTICAL;
+        }
+    }
+}
+
+
+sp<VirtualCameraDeviceSession> VirtualCameraDevice::createSession(
+        const sp<ICameraDeviceCallback>& cb,
+        const std::vector<SupportedV4L2Format>& sortedFormats,
+        const CroppingType& croppingType,
+        const common::V1_0::helper::CameraMetadata& chars,
+        const std::string& cameraId) {
+    return new VirtualCameraDeviceSession(
+            cb, sortedFormats, croppingType, chars, cameraId);
+}
+
+int VirtualCameraDevice::open()
+{
+    return mCaptureManager->openRequest(mCameraId);
+}
+
+int VirtualCameraDevice::close()
+{
+    //mV4L2CameraDevice refcount-- if still other virtual camera device in use
+    //Really close if it's the last virtual camera device using it.
+    // return mV4L2CameraDevice->close();
+    mCaptureManager->closeRequest(mCameraId);
+    return 0;
+}
+
+int VirtualCameraDevice::configureStream()
+{
+    return 0;
+}
+
+int VirtualCameraDevice::streamOff()
+{
+    return 0;
+}
+
+int VirtualCameraDevice::streamOn()
+{
+    return 0;
+}
+
+int VirtualCameraDevice::dequeueFrame(sp<FrameBuffer> frame)
+{
+
+    return mCaptureManager->dequeueRequest(frame);
+}
+
+int VirtualCameraDevice::enqueueFrame(sp<FrameBuffer> frame)
+{
+    if (frame == nullptr) {
+        ALOGW("Null frame for enqueue, alloc one.");
+        frame = new FrameBuffer();
+        frame->mFourcc = V4L2_PIX_FMT_UYVY;
+        frame->mDataSize = frame->mWidth * frame->mHeight * 2 + frame->mWidth * 2;
+        frame->mData = new uint8_t[frame->mDataSize];
+    }
+    return mCaptureManager->enqueueRequest(mCameraId, frame);
+}
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
diff --git a/camera/device/3.4/default/Virtual/VirtualCameraDeviceSession.cpp b/camera/device/3.4/default/Virtual/VirtualCameraDeviceSession.cpp
new file mode 100644
index 000000000..cfdd9e914
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/VirtualCameraDeviceSession.cpp
@@ -0,0 +1,2465 @@
+#define LOG_TAG "VirtCamDevSsn@3.4"
+//#define LOG_NDEBUG 0
+#define ATRACE_TAG ATRACE_TAG_CAMERA
+#include <log/log.h>
+
+#include <inttypes.h>
+#include "VirtualCameraDeviceSession.h"
+#include "VirtualCameraManager.h"
+
+#include "CaptureManager.h"
+#include "android-base/macros.h"
+#include <utils/Timers.h>
+#include <utils/Trace.h>
+#include <linux/videodev2.h>
+#include <sync/sync.h>
+
+#define HAVE_JPEG // required for libyuv.h to export MJPEG decode APIs
+#include <libyuv.h>
+
+#include <jpeglib.h>
+
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+namespace {
+// Size of request/result metadata fast message queue. Change to 0 to always use hwbinder buffer.
+static constexpr size_t kMetadataMsgQueueSize = 1 << 18 /* 256kB */;
+
+// const int kBadFramesAfterStreamOn = 0; // drop x frames after streamOn to get rid of some initial
+                                       // bad frames. TODO: develop a better bad frame detection
+                                       // method
+// constexpr int MAX_RETRY = 15; // Allow retry some ioctl failures a few times to account for some
+                             // webcam showing temporarily ioctl failures.
+// constexpr int IOCTL_RETRY_SLEEP_US = 33000; // 33ms * MAX_RETRY = 0.5 seconds
+
+// Constants for tryLock during dumpstate
+static constexpr int kDumpLockRetries = 50;
+static constexpr int kDumpLockSleep = 60000;
+
+bool tryLock(Mutex& mutex)
+{
+    bool locked = false;
+    for (int i = 0; i < kDumpLockRetries; ++i) {
+        if (mutex.tryLock() == NO_ERROR) {
+            locked = true;
+            break;
+        }
+        usleep(kDumpLockSleep);
+    }
+    return locked;
+}
+
+bool tryLock(std::mutex& mutex)
+{
+    bool locked = false;
+    for (int i = 0; i < kDumpLockRetries; ++i) {
+        if (mutex.try_lock()) {
+            locked = true;
+            break;
+        }
+        usleep(kDumpLockSleep);
+    }
+    return locked;
+}
+
+} // Anonymous namespace
+
+
+// Static instances
+const int VirtualCameraDeviceSession::kMaxProcessedStream;
+const int VirtualCameraDeviceSession::kMaxStallStream;
+HandleImporter VirtualCameraDeviceSession::sHandleImporter;
+
+VirtualCameraDeviceSession::VirtualCameraDeviceSession(
+        const sp<ICameraDeviceCallback>& callback,
+        const std::vector<SupportedV4L2Format>& sortedFormats,
+        const CroppingType& croppingType,
+        const common::V1_0::helper::CameraMetadata& chars,
+        const std::string& cameraId) :
+        mCallback(callback),
+        mCameraCharacteristics(chars),
+        mSupportedFormats(sortedFormats),
+        mCroppingType(croppingType),
+        mCameraId(cameraId),
+        mMaxThumbResolution(getMaxThumbResolution()),
+        mMaxJpegResolution(getMaxJpegResolution()) {
+        mVirtManager = VirtualCameraManager::getInstance();
+}
+
+
+bool VirtualCameraDeviceSession::initialize() {
+// TODO : need to get filled from physical device info
+    mExifMake = "Generic UVC webcam";
+    mExifModel = "Generic UVC webcam";
+
+    initOutputThread();
+    if (mOutputThread == nullptr) {
+        ALOGE("%s: init OutputThread failed!", __FUNCTION__);
+        return true;
+    }
+     mOutputThread->setExifMakeModel(mExifMake, mExifModel);
+
+    status_t status = initDefaultRequests();
+    if (status != OK) {
+        ALOGE("%s: init default requests failed!", __FUNCTION__);
+        return true;
+    }
+
+    mRequestMetadataQueue = std::make_unique<RequestMetadataQueue>(
+            kMetadataMsgQueueSize, false /* non blocking */);
+    if (!mRequestMetadataQueue->isValid()) {
+        ALOGE("%s: invalid request fmq", __FUNCTION__);
+        return true;
+    }
+    mResultMetadataQueue = std::make_shared<ResultMetadataQueue>(
+            kMetadataMsgQueueSize, false /* non blocking */);
+    if (!mResultMetadataQueue->isValid()) {
+        ALOGE("%s: invalid result fmq", __FUNCTION__);
+        return true;
+    }
+
+    // TODO: check is PRIORITY_DISPLAY enough?
+    mOutputThread->run("ExtCamOut", PRIORITY_DISPLAY);
+    return false;
+}
+
+bool VirtualCameraDeviceSession::isInitFailed() {
+    Mutex::Autolock _l(mLock);
+    if (!mInitialized) {
+        mInitFail = initialize();
+        mInitialized = true;
+    }
+    return mInitFail;
+}
+
+void VirtualCameraDeviceSession::initOutputThread() {
+    mOutputThread = new OutputThread(this, mCroppingType, mCameraCharacteristics);
+}
+
+void VirtualCameraDeviceSession::closeOutputThread() {
+    closeOutputThreadImpl();
+}
+
+void VirtualCameraDeviceSession::closeOutputThreadImpl() {
+    if (mOutputThread) {
+        mOutputThread->flush();
+        mOutputThread->requestExit();
+        mOutputThread->join();
+        mOutputThread.clear();
+    }
+}
+
+Status VirtualCameraDeviceSession::initStatus() const {
+    Mutex::Autolock _l(mLock);
+    Status status = Status::OK;
+    if (mInitFail || mClosed) {
+        ALOGI("%s: sesssion initFailed %d closed %d", __FUNCTION__, mInitFail, mClosed);
+        status = Status::INTERNAL_ERROR;
+    }
+    return status;
+}
+
+VirtualCameraDeviceSession::~VirtualCameraDeviceSession() {
+    if (!isClosed()) {
+        ALOGE("VirtualCameraDeviceSession deleted before close!");
+        close(/*callerIsDtor*/true);
+    }
+}
+
+
+void VirtualCameraDeviceSession::dumpState(const native_handle_t* handle) {
+    if (handle->numFds != 1 || handle->numInts != 0) {
+        ALOGE("%s: handle must contain 1 FD and 0 integers! Got %d FDs and %d ints",
+                __FUNCTION__, handle->numFds, handle->numInts);
+        return;
+    }
+    int fd = handle->data[0];
+
+    bool intfLocked = tryLock(mInterfaceLock);
+    if (!intfLocked) {
+        dprintf(fd, "!! VirtualCameraDeviceSession interface may be deadlocked !!\n");
+    }
+
+    if (isClosed()) {
+        dprintf(fd, "External camera %s is closed\n", mCameraId.c_str());
+        return;
+    }
+
+    bool streaming = false;
+    size_t v4L2BufferCount = 0;
+    SupportedV4L2Format streamingFmt;
+    {
+        bool sessionLocked = tryLock(mLock);
+        if (!sessionLocked) {
+            dprintf(fd, "!! VirtualCameraDeviceSession mLock may be deadlocked !!\n");
+        }
+        streaming = mV4l2Streaming;
+        streamingFmt = mV4l2StreamingFmt;
+        v4L2BufferCount = mV4L2BufferCount;
+
+        if (sessionLocked) {
+            mLock.unlock();
+        }
+    }
+
+    std::unordered_set<uint32_t>  inflightFrames;
+    {
+        bool iffLocked = tryLock(mInflightFramesLock);
+        if (!iffLocked) {
+            dprintf(fd,
+                    "!! VirtualCameraDeviceSession mInflightFramesLock may be deadlocked !!\n");
+        }
+        inflightFrames = mInflightFrames;
+        if (iffLocked) {
+            mInflightFramesLock.unlock();
+        }
+    }
+
+    // dprintf(fd, "Virtual camera %s V4L2 FD %d, cropping type %s, %s\n",
+    //         mCameraId.c_str(), mV4l2Fd.get(),
+    //         (mCroppingType == VERTICAL) ? "vertical" : "horizontal",
+    //         streaming ? "streaming" : "not streaming");
+    if (streaming) {
+        // TODO: dump fps later
+        dprintf(fd, "Current V4L2 format %c%c%c%c %dx%d @ %ffps\n",
+                streamingFmt.fourcc & 0xFF,
+                (streamingFmt.fourcc >> 8) & 0xFF,
+                (streamingFmt.fourcc >> 16) & 0xFF,
+                (streamingFmt.fourcc >> 24) & 0xFF,
+                streamingFmt.width, streamingFmt.height,
+                mV4l2StreamingFps);
+
+        size_t numDequeuedV4l2Buffers = 0;
+        {
+            std::lock_guard<std::mutex> lk(mV4l2BufferLock);
+            numDequeuedV4l2Buffers = mNumDequeuedV4l2Buffers;
+        }
+        dprintf(fd, "V4L2 buffer queue size %zu, dequeued %zu\n",
+                v4L2BufferCount, numDequeuedV4l2Buffers);
+    }
+
+    dprintf(fd, "In-flight frames (not sorted):");
+    for (const auto& frameNumber : inflightFrames) {
+        dprintf(fd, "%d, ", frameNumber);
+    }
+    dprintf(fd, "\n");
+    mOutputThread->dump(fd);
+    dprintf(fd, "\n");
+
+    if (intfLocked) {
+        mInterfaceLock.unlock();
+    }
+
+    return;
+}
+
+Return<void> VirtualCameraDeviceSession::constructDefaultRequestSettings(
+        V3_2::RequestTemplate type,
+        V3_2::ICameraDeviceSession::constructDefaultRequestSettings_cb _hidl_cb) {
+    V3_2::CameraMetadata outMetadata;
+    Status status = constructDefaultRequestSettingsRaw(
+            static_cast<RequestTemplate>(type), &outMetadata);
+    _hidl_cb(status, outMetadata);
+    return Void();
+}
+
+Status VirtualCameraDeviceSession::constructDefaultRequestSettingsRaw(RequestTemplate type,
+        V3_2::CameraMetadata *outMetadata) {
+    CameraMetadata emptyMd;
+    Status status = initStatus();
+    if (status != Status::OK) {
+        return status;
+    }
+
+    switch (type) {
+        case RequestTemplate::PREVIEW:
+        case RequestTemplate::STILL_CAPTURE:
+        case RequestTemplate::VIDEO_RECORD:
+        case RequestTemplate::VIDEO_SNAPSHOT: {
+            *outMetadata = mDefaultRequests[type];
+            break;
+        }
+        case RequestTemplate::MANUAL:
+        case RequestTemplate::ZERO_SHUTTER_LAG:
+            // Don't support MANUAL, ZSL templates
+            status = Status::ILLEGAL_ARGUMENT;
+            break;
+        default:
+            ALOGE("%s: unknown request template type %d", __FUNCTION__, static_cast<int>(type));
+            status = Status::ILLEGAL_ARGUMENT;
+            break;
+    }
+    return status;
+}
+
+Return<void> VirtualCameraDeviceSession::configureStreams(
+        const V3_2::StreamConfiguration& streams,
+        ICameraDeviceSession::configureStreams_cb _hidl_cb) {
+    V3_2::HalStreamConfiguration outStreams;
+    V3_3::HalStreamConfiguration outStreams_v33;
+    Mutex::Autolock _il(mInterfaceLock);
+
+    Status status = configureStreams(streams, &outStreams_v33);
+    size_t size = outStreams_v33.streams.size();
+    outStreams.streams.resize(size);
+    for (size_t i = 0; i < size; i++) {
+        outStreams.streams[i] = outStreams_v33.streams[i].v3_2;
+    }
+    _hidl_cb(status, outStreams);
+    return Void();
+}
+
+Return<void> VirtualCameraDeviceSession::configureStreams_3_3(
+        const V3_2::StreamConfiguration& streams,
+        ICameraDeviceSession::configureStreams_3_3_cb _hidl_cb) {
+    V3_3::HalStreamConfiguration outStreams;
+    Mutex::Autolock _il(mInterfaceLock);
+
+    Status status = configureStreams(streams, &outStreams);
+    _hidl_cb(status, outStreams);
+    return Void();
+}
+
+Return<void> VirtualCameraDeviceSession::configureStreams_3_4(
+        const V3_4::StreamConfiguration& requestedConfiguration,
+        ICameraDeviceSession::configureStreams_3_4_cb _hidl_cb)  {
+    V3_2::StreamConfiguration config_v32;
+    V3_3::HalStreamConfiguration outStreams_v33;
+    V3_4::HalStreamConfiguration outStreams;
+    Mutex::Autolock _il(mInterfaceLock);
+
+    config_v32.operationMode = requestedConfiguration.operationMode;
+    config_v32.streams.resize(requestedConfiguration.streams.size());
+    uint32_t blobBufferSize = 0;
+    int numStallStream = 0;
+    for (size_t i = 0; i < config_v32.streams.size(); i++) {
+        config_v32.streams[i] = requestedConfiguration.streams[i].v3_2;
+        if (config_v32.streams[i].format == PixelFormat::BLOB) {
+            blobBufferSize = requestedConfiguration.streams[i].bufferSize;
+            numStallStream++;
+        }
+    }
+
+    // Fail early if there are multiple BLOB streams
+    if (numStallStream > kMaxStallStream) {
+        ALOGE("%s: too many stall streams (expect <= %d, got %d)", __FUNCTION__,
+                kMaxStallStream, numStallStream);
+        _hidl_cb(Status::ILLEGAL_ARGUMENT, outStreams);
+        return Void();
+    }
+
+    Status status = configureStreams(config_v32, &outStreams_v33, blobBufferSize);
+
+    outStreams.streams.resize(outStreams_v33.streams.size());
+    for (size_t i = 0; i < outStreams.streams.size(); i++) {
+        outStreams.streams[i].v3_3 = outStreams_v33.streams[i];
+    }
+    _hidl_cb(status, outStreams);
+    return Void();
+}
+
+Return<void> VirtualCameraDeviceSession::getCaptureRequestMetadataQueue(
+    ICameraDeviceSession::getCaptureRequestMetadataQueue_cb _hidl_cb) {
+    Mutex::Autolock _il(mInterfaceLock);
+    _hidl_cb(*mRequestMetadataQueue->getDesc());
+    return Void();
+}
+
+Return<void> VirtualCameraDeviceSession::getCaptureResultMetadataQueue(
+    ICameraDeviceSession::getCaptureResultMetadataQueue_cb _hidl_cb) {
+    Mutex::Autolock _il(mInterfaceLock);
+    _hidl_cb(*mResultMetadataQueue->getDesc());
+    return Void();
+}
+
+Return<void> VirtualCameraDeviceSession::processCaptureRequest(
+        const hidl_vec<CaptureRequest>& requests,
+        const hidl_vec<BufferCache>& cachesToRemove,
+        ICameraDeviceSession::processCaptureRequest_cb _hidl_cb) {
+    Mutex::Autolock _il(mInterfaceLock);
+    updateBufferCaches(cachesToRemove);
+
+    uint32_t numRequestProcessed = 0;
+    Status s = Status::OK;
+    for (size_t i = 0; i < requests.size(); i++, numRequestProcessed++) {
+        s = processOneCaptureRequest(requests[i]);
+        if (s != Status::OK) {
+            break;
+        }
+    }
+
+    _hidl_cb(s, numRequestProcessed);
+    return Void();
+}
+
+Return<void> VirtualCameraDeviceSession::processCaptureRequest_3_4(
+        const hidl_vec<V3_4::CaptureRequest>& requests,
+        const hidl_vec<V3_2::BufferCache>& cachesToRemove,
+        ICameraDeviceSession::processCaptureRequest_3_4_cb _hidl_cb) {
+    Mutex::Autolock _il(mInterfaceLock);
+    updateBufferCaches(cachesToRemove);
+
+    uint32_t numRequestProcessed = 0;
+    Status s = Status::OK;
+    for (size_t i = 0; i < requests.size(); i++, numRequestProcessed++) {
+        s = processOneCaptureRequest(requests[i].v3_2);
+        if (s != Status::OK) {
+            break;
+        }
+    }
+
+    _hidl_cb(s, numRequestProcessed);
+    return Void();
+}
+
+Return<Status> VirtualCameraDeviceSession::flush() {
+    ATRACE_CALL();
+    Mutex::Autolock _il(mInterfaceLock);
+    Status status = initStatus();
+    if (status != Status::OK) {
+        return status;
+    }
+    mOutputThread->flush();
+    return Status::OK;
+}
+
+Return<void> VirtualCameraDeviceSession::close(bool callerIsDtor) {
+    Mutex::Autolock _il(mInterfaceLock);
+    if (callerIsDtor) {
+        ALOGI("DEBUG");
+    }
+    bool closed = isClosed();
+    if (!closed) {
+        if (callerIsDtor) {
+            closeOutputThreadImpl();
+        } else {
+            closeOutputThread();
+        }
+
+        Mutex::Autolock _l(mLock);
+        // free all buffers
+        {
+            Mutex::Autolock _l(mCbsLock);
+            for(auto pair : mStreamMap) {
+                cleanupBuffersLocked(/*Stream ID*/pair.first);
+            }
+        }
+        v4l2StreamOffLocked();
+        // ALOGV("%s: closing V4L2 camera FD %d", __FUNCTION__, mV4l2Fd.get());
+        // mV4l2Fd.reset();
+
+        sp<VirtualCameraDevice> virtDevice = mVirtManager->getVirtCamByID(mCameraId);
+        if(virtDevice->configureStream() != 0) {
+            ALOGE("%s: failed to congfiure ", __FUNCTION__);
+            return Void();
+        }
+
+        if(virtDevice->close() != 0) {
+            ALOGE("%s: failed to stream on ", __FUNCTION__);
+            return Void();
+        }
+        mClosed = true;
+    }
+    return Void();
+}
+
+Status VirtualCameraDeviceSession::importRequestLocked(
+    const CaptureRequest& request,
+    hidl_vec<buffer_handle_t*>& allBufPtrs,
+    hidl_vec<int>& allFences) {
+    return importRequestLockedImpl(request, allBufPtrs, allFences);
+}
+
+Status VirtualCameraDeviceSession::importBuffer(int32_t streamId,
+        uint64_t bufId, buffer_handle_t buf,
+        /*out*/buffer_handle_t** outBufPtr,
+        bool allowEmptyBuf) {
+    Mutex::Autolock _l(mCbsLock);
+    return importBufferLocked(streamId, bufId, buf, outBufPtr, allowEmptyBuf);
+}
+
+Status VirtualCameraDeviceSession::importBufferLocked(int32_t streamId,
+        uint64_t bufId, buffer_handle_t buf,
+        /*out*/buffer_handle_t** outBufPtr,
+        bool allowEmptyBuf) {
+    return importBufferImpl(
+            mCirculatingBuffers, sHandleImporter, streamId,
+            bufId, buf, outBufPtr, allowEmptyBuf);
+}
+
+Status VirtualCameraDeviceSession::importRequestLockedImpl(
+        const CaptureRequest& request,
+        hidl_vec<buffer_handle_t*>& allBufPtrs,
+        hidl_vec<int>& allFences,
+        bool allowEmptyBuf) {
+    size_t numOutputBufs = request.outputBuffers.size();
+    size_t numBufs = numOutputBufs;
+    // Validate all I/O buffers
+    hidl_vec<buffer_handle_t> allBufs;
+    hidl_vec<uint64_t> allBufIds;
+    allBufs.resize(numBufs);
+    allBufIds.resize(numBufs);
+    allBufPtrs.resize(numBufs);
+    allFences.resize(numBufs);
+    std::vector<int32_t> streamIds(numBufs);
+
+    for (size_t i = 0; i < numOutputBufs; i++) {
+        allBufs[i] = request.outputBuffers[i].buffer.getNativeHandle();
+        allBufIds[i] = request.outputBuffers[i].bufferId;
+        allBufPtrs[i] = &allBufs[i];
+        streamIds[i] = request.outputBuffers[i].streamId;
+    }
+
+    {
+        Mutex::Autolock _l(mCbsLock);
+        for (size_t i = 0; i < numBufs; i++) {
+            Status st = importBufferLocked(
+                    streamIds[i], allBufIds[i], allBufs[i], &allBufPtrs[i],
+                    allowEmptyBuf);
+            if (st != Status::OK) {
+                // Detailed error logs printed in importBuffer
+                return st;
+            }
+        }
+    }
+
+    // All buffers are imported. Now validate output buffer acquire fences
+    for (size_t i = 0; i < numOutputBufs; i++) {
+        if (!sHandleImporter.importFence(
+                request.outputBuffers[i].acquireFence, allFences[i])) {
+            ALOGE("%s: output buffer %zu acquire fence is invalid", __FUNCTION__, i);
+            cleanupInflightFences(allFences, i);
+            return Status::INTERNAL_ERROR;
+        }
+    }
+    return Status::OK;
+}
+
+void VirtualCameraDeviceSession::cleanupInflightFences(
+        hidl_vec<int>& allFences, size_t numFences) {
+    for (size_t j = 0; j < numFences; j++) {
+        sHandleImporter.closeFence(allFences[j]);
+    }
+}
+
+int VirtualCameraDeviceSession::waitForV4L2BufferReturnLocked(std::unique_lock<std::mutex>& lk) {
+    ATRACE_CALL();
+    std::chrono::seconds timeout = std::chrono::seconds(kBufferWaitTimeoutSec);
+    mLock.unlock();
+    auto st = mV4L2BufferReturned.wait_for(lk, timeout);
+    // Here we introduce a order where mV4l2BufferLock is acquired before mLock, while
+    // the normal lock acquisition order is reversed. This is fine because in most of
+    // cases we are protected by mInterfaceLock. The only thread that can cause deadlock
+    // is the OutputThread, where we do need to make sure we don't acquire mLock then
+    // mV4l2BufferLock
+    mLock.lock();
+    if (st == std::cv_status::timeout) {
+        ALOGE("%s: wait for V4L2 buffer return timeout!", __FUNCTION__);
+        return -1;
+    }
+    return 0;
+}
+
+Status VirtualCameraDeviceSession::processOneCaptureRequest(const CaptureRequest& request)  {
+    ATRACE_CALL();
+    Status status = initStatus();
+    if (status != Status::OK) {
+        return status;
+    }
+
+    if (request.inputBuffer.streamId != -1) {
+        ALOGE("%s: external camera does not support reprocessing!", __FUNCTION__);
+        return Status::ILLEGAL_ARGUMENT;
+    }
+
+    Mutex::Autolock _l(mLock);
+    // if (!mV4l2Streaming) {
+    //     ALOGE("%s: cannot process request in streamOff state!", __FUNCTION__);
+    //     return Status::INTERNAL_ERROR;
+    // }
+
+    const camera_metadata_t *rawSettings = nullptr;
+    bool converted = true;
+    CameraMetadata settingsFmq;  // settings from FMQ
+    if (request.fmqSettingsSize > 0) {
+        // non-blocking read; client must write metadata before calling
+        // processOneCaptureRequest
+        settingsFmq.resize(request.fmqSettingsSize);
+        bool read = mRequestMetadataQueue->read(settingsFmq.data(), request.fmqSettingsSize);
+        if (read) {
+            converted = V3_2::implementation::convertFromHidl(settingsFmq, &rawSettings);
+        } else {
+            ALOGE("%s: capture request settings metadata couldn't be read from fmq!", __FUNCTION__);
+            converted = false;
+        }
+    } else {
+        converted = V3_2::implementation::convertFromHidl(request.settings, &rawSettings);
+    }
+
+    if (converted && rawSettings != nullptr) {
+        mLatestReqSetting = rawSettings;
+    }
+
+    if (!converted) {
+        ALOGE("%s: capture request settings metadata is corrupt!", __FUNCTION__);
+        return Status::ILLEGAL_ARGUMENT;
+    }
+
+    if (mFirstRequest && rawSettings == nullptr) {
+        ALOGE("%s: capture request settings must not be null for first request!",
+                __FUNCTION__);
+        return Status::ILLEGAL_ARGUMENT;
+    }
+
+    hidl_vec<buffer_handle_t*> allBufPtrs;
+    hidl_vec<int> allFences;
+    size_t numOutputBufs = request.outputBuffers.size();
+
+    if (numOutputBufs == 0) {
+        ALOGE("%s: capture request must have at least one output buffer!", __FUNCTION__);
+        return Status::ILLEGAL_ARGUMENT;
+    }
+#if 0
+    camera_metadata_entry fpsRange = mLatestReqSetting.find(ANDROID_CONTROL_AE_TARGET_FPS_RANGE);
+    if (fpsRange.count == 2) {
+        double requestFpsMax = fpsRange.data.i32[1];
+        double closestFps = 0.0;
+        double fpsError = 1000.0;
+        bool fpsSupported = false;
+        for (const auto& fr : mV4l2StreamingFmt.frameRates) {
+            double f = fr.getDouble();
+            if (std::fabs(requestFpsMax - f) < 1.0) {
+                fpsSupported = true;
+                break;
+            }
+            if (std::fabs(requestFpsMax - f) < fpsError) {
+                fpsError = std::fabs(requestFpsMax - f);
+                closestFps = f;
+            }
+        }
+        if (!fpsSupported) {
+            /* This can happen in a few scenarios:
+             * 1. The application is sending a FPS range not supported by the configured outputs.
+             * 2. The application is sending a valid FPS range for all cofigured outputs, but
+             *    the selected V4L2 size can only run at slower speed. This should be very rare
+             *    though: for this to happen a sensor needs to support at least 3 different aspect
+             *    ratio outputs, and when (at least) two outputs are both not the main aspect ratio
+             *    of the webcam, a third size that's larger might be picked and runs into this
+             *    issue.
+             */
+            ALOGW("%s: cannot reach fps %d! Will do %f instead",
+                    __FUNCTION__, fpsRange.data.i32[1], closestFps);
+            requestFpsMax = 30.0;
+        }
+        ALOGI("requestFpsMax=%f, mV4l2StreamingFps=%f", requestFpsMax, mV4l2StreamingFps);
+        // if (requestFpsMax != mV4l2StreamingFps) {
+        //     {
+        //         std::unique_lock<std::mutex> lk(mV4l2BufferLock);
+        //         while (mNumDequeuedV4l2Buffers != 0) {
+        //             // Wait until pipeline is idle before reconfigure stream
+        //             int waitRet = waitForV4L2BufferReturnLocked(lk);
+        //             if (waitRet != 0) {
+        //                 ALOGE("%s: wait for pipeline idle failed!", __FUNCTION__);
+        //                 return Status::INTERNAL_ERROR;
+        //             }
+        //         }
+        //     }
+        //     configureV4l2StreamLocked(mV4l2StreamingFmt, requestFpsMax);
+        // }
+    }
+
+#endif
+    status = importRequestLocked(request, allBufPtrs, allFences);
+    if (status != Status::OK) {
+        return status;
+    }
+
+    nsecs_t shutterTs = 0;
+    sp<V4L2Frame> frameIn = dequeueV4l2FrameLocked(&shutterTs);
+    if ( frameIn == nullptr) {
+        ALOGE("%s: V4L2 deque frame failed!", __FUNCTION__);
+        return Status::INTERNAL_ERROR;
+    }
+
+    std::shared_ptr<HalRequest> halReq = std::make_shared<HalRequest>();
+    halReq->frameNumber = request.frameNumber;
+    halReq->setting = mLatestReqSetting;
+    halReq->frameIn = frameIn;
+    halReq->shutterTs = shutterTs;
+    halReq->buffers.resize(numOutputBufs);
+    for (size_t i = 0; i < numOutputBufs; i++) {
+        HalStreamBuffer& halBuf = halReq->buffers[i];
+        int streamId = halBuf.streamId = request.outputBuffers[i].streamId;
+        halBuf.bufferId = request.outputBuffers[i].bufferId;
+        const Stream& stream = mStreamMap[streamId];
+        halBuf.width = stream.width;
+        halBuf.height = stream.height;
+        halBuf.format = stream.format;
+        halBuf.usage = stream.usage;
+        halBuf.bufPtr = allBufPtrs[i];
+        halBuf.acquireFence = allFences[i];
+        halBuf.fenceTimeout = false;
+    }
+    {
+        std::lock_guard<std::mutex> lk(mInflightFramesLock);
+        mInflightFrames.insert(halReq->frameNumber);
+    }
+    // Send request to OutputThread for the rest of processing
+    mOutputThread->submitRequest(halReq);
+    mFirstRequest = false;
+    return Status::OK;
+}
+
+void VirtualCameraDeviceSession::notifyShutter(uint32_t frameNumber, nsecs_t shutterTs) {
+    NotifyMsg msg;
+    msg.type = MsgType::SHUTTER;
+    msg.msg.shutter.frameNumber = frameNumber;
+    msg.msg.shutter.timestamp = shutterTs;
+    mCallback->notify({msg});
+}
+
+void VirtualCameraDeviceSession::notifyError(
+        uint32_t frameNumber, int32_t streamId, ErrorCode ec) {
+    NotifyMsg msg;
+    msg.type = MsgType::ERROR;
+    msg.msg.error.frameNumber = frameNumber;
+    msg.msg.error.errorStreamId = streamId;
+    msg.msg.error.errorCode = ec;
+    mCallback->notify({msg});
+}
+
+//TODO: refactor with processCaptureResult
+Status VirtualCameraDeviceSession::processCaptureRequestError(
+        const std::shared_ptr<HalRequest>& req,
+        /*out*/std::vector<NotifyMsg>* outMsgs,
+        /*out*/std::vector<CaptureResult>* outResults) {
+    ATRACE_CALL();
+    // Return V4L2 buffer to V4L2 buffer queue
+    // sp<V3_4::implementation::V4L2Frame> v4l2Frame =
+    //         static_cast<V3_4::implementation::V4L2Frame*>(req->frameIn.get());
+    // enqueueV4l2Frame(v4l2Frame);
+    enqueueV4l2Frame();
+
+    if (outMsgs == nullptr) {
+        notifyShutter(req->frameNumber, req->shutterTs);
+        notifyError(/*frameNum*/req->frameNumber, /*stream*/-1, ErrorCode::ERROR_REQUEST);
+    } else {
+        NotifyMsg shutter;
+        shutter.type = MsgType::SHUTTER;
+        shutter.msg.shutter.frameNumber = req->frameNumber;
+        shutter.msg.shutter.timestamp = req->shutterTs;
+
+        NotifyMsg error;
+        error.type = MsgType::ERROR;
+        error.msg.error.frameNumber = req->frameNumber;
+        error.msg.error.errorStreamId = -1;
+        error.msg.error.errorCode = ErrorCode::ERROR_REQUEST;
+        outMsgs->push_back(shutter);
+        outMsgs->push_back(error);
+    }
+
+    // Fill output buffers
+    hidl_vec<CaptureResult> results;
+    results.resize(1);
+    CaptureResult& result = results[0];
+    result.frameNumber = req->frameNumber;
+    result.partialResult = 1;
+    result.inputBuffer.streamId = -1;
+    result.outputBuffers.resize(req->buffers.size());
+    for (size_t i = 0; i < req->buffers.size(); i++) {
+        result.outputBuffers[i].streamId = req->buffers[i].streamId;
+        result.outputBuffers[i].bufferId = req->buffers[i].bufferId;
+        result.outputBuffers[i].status = BufferStatus::ERROR;
+        if (req->buffers[i].acquireFence >= 0) {
+            native_handle_t* handle = native_handle_create(/*numFds*/1, /*numInts*/0);
+            handle->data[0] = req->buffers[i].acquireFence;
+            result.outputBuffers[i].releaseFence.setTo(handle, /*shouldOwn*/false);
+        }
+    }
+
+    // update inflight records
+    {
+        std::lock_guard<std::mutex> lk(mInflightFramesLock);
+        mInflightFrames.erase(req->frameNumber);
+    }
+
+    if (outResults == nullptr) {
+        // Callback into framework
+        invokeProcessCaptureResultCallback(results, /* tryWriteFmq */true);
+        freeReleaseFences(results);
+    } else {
+        outResults->push_back(result);
+    }
+    return Status::OK;
+}
+
+Status VirtualCameraDeviceSession::processCaptureResult(std::shared_ptr<HalRequest>& req) {
+    ATRACE_CALL();
+    // Return V4L2 buffer to V4L2 buffer queue
+    // sp<V3_4::implementation::V4L2Frame> v4l2Frame =
+    //         static_cast<V3_4::implementation::V4L2Frame*>(req->frameIn.get());
+    // enqueueV4l2Frame(v4l2Frame);
+    ALOGV("%s %d", __FUNCTION__, __LINE__);
+    enqueueV4l2Frame();
+
+    // NotifyShutter
+    notifyShutter(req->frameNumber, req->shutterTs);
+
+    // Fill output buffers
+    hidl_vec<CaptureResult> results;
+    results.resize(1);
+    CaptureResult& result = results[0];
+    result.frameNumber = req->frameNumber;
+    result.partialResult = 1;
+    result.inputBuffer.streamId = -1;
+    result.outputBuffers.resize(req->buffers.size());
+    for (size_t i = 0; i < req->buffers.size(); i++) {
+        result.outputBuffers[i].streamId = req->buffers[i].streamId;
+        result.outputBuffers[i].bufferId = req->buffers[i].bufferId;
+        if (req->buffers[i].fenceTimeout) {
+            result.outputBuffers[i].status = BufferStatus::ERROR;
+            if (req->buffers[i].acquireFence >= 0) {
+                native_handle_t* handle = native_handle_create(/*numFds*/1, /*numInts*/0);
+                handle->data[0] = req->buffers[i].acquireFence;
+                result.outputBuffers[i].releaseFence.setTo(handle, /*shouldOwn*/false);
+            }
+            notifyError(req->frameNumber, req->buffers[i].streamId, ErrorCode::ERROR_BUFFER);
+        } else {
+            result.outputBuffers[i].status = BufferStatus::OK;
+            // TODO: refactor
+            if (req->buffers[i].acquireFence >= 0) {
+                native_handle_t* handle = native_handle_create(/*numFds*/1, /*numInts*/0);
+                handle->data[0] = req->buffers[i].acquireFence;
+                result.outputBuffers[i].releaseFence.setTo(handle, /*shouldOwn*/false);
+            }
+        }
+    }
+
+    // Fill capture result metadata
+    fillCaptureResult(req->setting, req->shutterTs);
+    const camera_metadata_t *rawResult = req->setting.getAndLock();
+    V3_2::implementation::convertToHidl(rawResult, &result.result);
+    req->setting.unlock(rawResult);
+
+    // update inflight records
+    {
+        std::lock_guard<std::mutex> lk(mInflightFramesLock);
+        mInflightFrames.erase(req->frameNumber);
+    }
+
+    // Callback into framework
+    invokeProcessCaptureResultCallback(results, /* tryWriteFmq */true);
+    freeReleaseFences(results);
+    return Status::OK;
+}
+
+void VirtualCameraDeviceSession::invokeProcessCaptureResultCallback(
+        hidl_vec<CaptureResult> &results, bool tryWriteFmq) {
+    if (mProcessCaptureResultLock.tryLock() != OK) {
+        const nsecs_t NS_TO_SECOND = 1000000000;
+        ALOGV("%s: previous call is not finished! waiting 1s...", __FUNCTION__);
+        if (mProcessCaptureResultLock.timedLock(/* 1s */NS_TO_SECOND) != OK) {
+            ALOGE("%s: cannot acquire lock in 1s, cannot proceed",
+                    __FUNCTION__);
+            return;
+        }
+    }
+    if (tryWriteFmq && mResultMetadataQueue->availableToWrite() > 0) {
+        for (CaptureResult &result : results) {
+            if (result.result.size() > 0) {
+                if (mResultMetadataQueue->write(result.result.data(), result.result.size())) {
+                    result.fmqResultSize = result.result.size();
+                    result.result.resize(0);
+                } else {
+                    ALOGW("%s: couldn't utilize fmq, fall back to hwbinder", __FUNCTION__);
+                    result.fmqResultSize = 0;
+                }
+            } else {
+                result.fmqResultSize = 0;
+            }
+        }
+    }
+    auto status = mCallback->processCaptureResult(results);
+    if (!status.isOk()) {
+        ALOGE("%s: processCaptureResult ERROR : %s", __FUNCTION__,
+              status.description().c_str());
+    }
+
+    mProcessCaptureResultLock.unlock();
+}
+
+VirtualCameraDeviceSession::OutputThread::OutputThread(
+        wp<OutputThreadInterface> parent, CroppingType ct,
+        const common::V1_0::helper::CameraMetadata& chars) :
+        mParent(parent), mCroppingType(ct), mCameraCharacteristics(chars) {}
+
+VirtualCameraDeviceSession::OutputThread::~OutputThread() {}
+
+ void VirtualCameraDeviceSession::OutputThread::setExifMakeModel(
+         const std::string& make, const std::string& model) {
+     mExifMake = make;
+     mExifModel = model;
+ }
+
+int VirtualCameraDeviceSession::OutputThread::cropAndScaleLocked(
+        sp<AllocatedFrame>& in, const Size& outSz, YCbCrLayout* out) {
+    Size inSz = {in->mWidth, in->mHeight};
+
+    int ret;
+    if (inSz == outSz) {
+        ret = in->getLayout(out);
+        if (ret != 0) {
+            ALOGE("%s: failed to get input image layout", __FUNCTION__);
+            return ret;
+        }
+        return ret;
+    }
+
+    // Cropping to output aspect ratio
+    IMapper::Rect inputCrop;
+    ret = getCropRect(mCroppingType, inSz, outSz, &inputCrop);
+    if (ret != 0) {
+        ALOGE("%s: failed to compute crop rect for output size %dx%d",
+                __FUNCTION__, outSz.width, outSz.height);
+        return ret;
+    }
+
+    YCbCrLayout croppedLayout;
+    ret = in->getCroppedLayout(inputCrop, &croppedLayout);
+    if (ret != 0) {
+        ALOGE("%s: failed to crop input image %dx%d to output size %dx%d",
+                __FUNCTION__, inSz.width, inSz.height, outSz.width, outSz.height);
+        return ret;
+    }
+
+    if ((mCroppingType == VERTICAL && inSz.width == outSz.width) ||
+            (mCroppingType == HORIZONTAL && inSz.height == outSz.height)) {
+        // No scale is needed
+        *out = croppedLayout;
+        return 0;
+    }
+
+    auto it = mScaledYu12Frames.find(outSz);
+    sp<AllocatedFrame> scaledYu12Buf;
+    if (it != mScaledYu12Frames.end()) {
+        scaledYu12Buf = it->second;
+    } else {
+        it = mIntermediateBuffers.find(outSz);
+        if (it == mIntermediateBuffers.end()) {
+            ALOGE("%s: failed to find intermediate buffer size %dx%d",
+                    __FUNCTION__, outSz.width, outSz.height);
+            return -1;
+        }
+        scaledYu12Buf = it->second;
+    }
+    // Scale
+    YCbCrLayout outLayout;
+    ret = scaledYu12Buf->getLayout(&outLayout);
+    if (ret != 0) {
+        ALOGE("%s: failed to get output buffer layout", __FUNCTION__);
+        return ret;
+    }
+
+    ret = libyuv::I420Scale(
+            static_cast<uint8_t*>(croppedLayout.y),
+            croppedLayout.yStride,
+            static_cast<uint8_t*>(croppedLayout.cb),
+            croppedLayout.cStride,
+            static_cast<uint8_t*>(croppedLayout.cr),
+            croppedLayout.cStride,
+            inputCrop.width,
+            inputCrop.height,
+            static_cast<uint8_t*>(outLayout.y),
+            outLayout.yStride,
+            static_cast<uint8_t*>(outLayout.cb),
+            outLayout.cStride,
+            static_cast<uint8_t*>(outLayout.cr),
+            outLayout.cStride,
+            outSz.width,
+            outSz.height,
+            // TODO: b/72261744 see if we can use better filter without losing too much perf
+            libyuv::FilterMode::kFilterNone);
+
+    if (ret != 0) {
+        ALOGE("%s: failed to scale buffer from %dx%d to %dx%d. Ret %d",
+                __FUNCTION__, inputCrop.width, inputCrop.height,
+                outSz.width, outSz.height, ret);
+        return ret;
+    }
+
+    *out = outLayout;
+    mScaledYu12Frames.insert({outSz, scaledYu12Buf});
+    return 0;
+}
+
+
+int VirtualCameraDeviceSession::OutputThread::cropAndScaleThumbLocked(
+        sp<AllocatedFrame>& in, const Size &outSz, YCbCrLayout* out) {
+    Size inSz  {in->mWidth, in->mHeight};
+
+    if ((outSz.width * outSz.height) >
+        (mYu12ThumbFrame->mWidth * mYu12ThumbFrame->mHeight)) {
+        ALOGE("%s: Requested thumbnail size too big (%d,%d) > (%d,%d)",
+              __FUNCTION__, outSz.width, outSz.height,
+              mYu12ThumbFrame->mWidth, mYu12ThumbFrame->mHeight);
+        return -1;
+    }
+
+    int ret;
+
+    /* This will crop-and-zoom the input YUV frame to the thumbnail size
+     * Based on the following logic:
+     *  1) Square pixels come in, square pixels come out, therefore single
+     *  scale factor is computed to either make input bigger or smaller
+     *  depending on if we are upscaling or downscaling
+     *  2) That single scale factor would either make height too tall or width
+     *  too wide so we need to crop the input either horizontally or vertically
+     *  but not both
+     */
+
+    /* Convert the input and output dimensions into floats for ease of math */
+    float fWin = static_cast<float>(inSz.width);
+    float fHin = static_cast<float>(inSz.height);
+    float fWout = static_cast<float>(outSz.width);
+    float fHout = static_cast<float>(outSz.height);
+
+    /* Compute the one scale factor from (1) above, it will be the smaller of
+     * the two possibilities. */
+    float scaleFactor = std::min( fHin / fHout, fWin / fWout );
+
+    /* Since we are crop-and-zooming (as opposed to letter/pillar boxing) we can
+     * simply multiply the output by our scaleFactor to get the cropped input
+     * size. Note that at least one of {fWcrop, fHcrop} is going to wind up
+     * being {fWin, fHin} respectively because fHout or fWout cancels out the
+     * scaleFactor calculation above.
+     *
+     * Specifically:
+     *  if ( fHin / fHout ) < ( fWin / fWout ) we crop the sides off
+     * input, in which case
+     *    scaleFactor = fHin / fHout
+     *    fWcrop = fHin / fHout * fWout
+     *    fHcrop = fHin
+     *
+     * Note that fWcrop <= fWin ( because ( fHin / fHout ) * fWout < fWin, which
+     * is just the inequality above with both sides multiplied by fWout
+     *
+     * on the other hand if ( fWin / fWout ) < ( fHin / fHout) we crop the top
+     * and the bottom off of input, and
+     *    scaleFactor = fWin / fWout
+     *    fWcrop = fWin
+     *    fHCrop = fWin / fWout * fHout
+     */
+    float fWcrop = scaleFactor * fWout;
+    float fHcrop = scaleFactor * fHout;
+
+    /* Convert to integer and truncate to an even number */
+    Size cropSz = { 2*static_cast<uint32_t>(fWcrop/2.0f),
+                    2*static_cast<uint32_t>(fHcrop/2.0f) };
+
+    /* Convert to a centered rectange with even top/left */
+    IMapper::Rect inputCrop {
+        2*static_cast<int32_t>((inSz.width - cropSz.width)/4),
+        2*static_cast<int32_t>((inSz.height - cropSz.height)/4),
+        static_cast<int32_t>(cropSz.width),
+        static_cast<int32_t>(cropSz.height) };
+
+    if ((inputCrop.top < 0) ||
+        (inputCrop.top >= static_cast<int32_t>(inSz.height)) ||
+        (inputCrop.left < 0) ||
+        (inputCrop.left >= static_cast<int32_t>(inSz.width)) ||
+        (inputCrop.width <= 0) ||
+        (inputCrop.width + inputCrop.left > static_cast<int32_t>(inSz.width)) ||
+        (inputCrop.height <= 0) ||
+        (inputCrop.height + inputCrop.top > static_cast<int32_t>(inSz.height)))
+    {
+        ALOGE("%s: came up with really wrong crop rectangle",__FUNCTION__);
+        ALOGE("%s: input layout %dx%d to for output size %dx%d",
+             __FUNCTION__, inSz.width, inSz.height, outSz.width, outSz.height);
+        ALOGE("%s: computed input crop +%d,+%d %dx%d",
+             __FUNCTION__, inputCrop.left, inputCrop.top,
+             inputCrop.width, inputCrop.height);
+        return -1;
+    }
+
+    YCbCrLayout inputLayout;
+    ret = in->getCroppedLayout(inputCrop, &inputLayout);
+    if (ret != 0) {
+        ALOGE("%s: failed to crop input layout %dx%d to for output size %dx%d",
+             __FUNCTION__, inSz.width, inSz.height, outSz.width, outSz.height);
+        ALOGE("%s: computed input crop +%d,+%d %dx%d",
+             __FUNCTION__, inputCrop.left, inputCrop.top,
+             inputCrop.width, inputCrop.height);
+        return ret;
+    }
+    ALOGV("%s: crop input layout %dx%d to for output size %dx%d",
+          __FUNCTION__, inSz.width, inSz.height, outSz.width, outSz.height);
+    ALOGV("%s: computed input crop +%d,+%d %dx%d",
+          __FUNCTION__, inputCrop.left, inputCrop.top,
+          inputCrop.width, inputCrop.height);
+
+
+    // Scale
+    YCbCrLayout outFullLayout;
+
+    ret = mYu12ThumbFrame->getLayout(&outFullLayout);
+    if (ret != 0) {
+        ALOGE("%s: failed to get output buffer layout", __FUNCTION__);
+        return ret;
+    }
+
+
+    ret = libyuv::I420Scale(
+            static_cast<uint8_t*>(inputLayout.y),
+            inputLayout.yStride,
+            static_cast<uint8_t*>(inputLayout.cb),
+            inputLayout.cStride,
+            static_cast<uint8_t*>(inputLayout.cr),
+            inputLayout.cStride,
+            inputCrop.width,
+            inputCrop.height,
+            static_cast<uint8_t*>(outFullLayout.y),
+            outFullLayout.yStride,
+            static_cast<uint8_t*>(outFullLayout.cb),
+            outFullLayout.cStride,
+            static_cast<uint8_t*>(outFullLayout.cr),
+            outFullLayout.cStride,
+            outSz.width,
+            outSz.height,
+            libyuv::FilterMode::kFilterNone);
+
+    if (ret != 0) {
+        ALOGE("%s: failed to scale buffer from %dx%d to %dx%d. Ret %d",
+                __FUNCTION__, inputCrop.width, inputCrop.height,
+                outSz.width, outSz.height, ret);
+        return ret;
+    }
+
+    *out = outFullLayout;
+    return 0;
+}
+
+/*
+ * TODO: There needs to be a mechanism to discover allocated buffer size
+ * in the HAL.
+ *
+ * This is very fragile because it is duplicated computation from:
+ * frameworks/av/services/camera/libcameraservice/device3/Camera3Device.cpp
+ *
+ */
+
+/* This assumes mSupportedFormats have all been declared as supporting
+ * HAL_PIXEL_FORMAT_BLOB to the framework */
+Size VirtualCameraDeviceSession::getMaxJpegResolution() const {
+    Size ret { 0, 0 };
+    for(auto & fmt : mSupportedFormats) {
+        if(fmt.width * fmt.height > ret.width * ret.height) {
+            ret = Size { fmt.width, fmt.height };
+        }
+    }
+    return ret;
+}
+
+Size VirtualCameraDeviceSession::getMaxThumbResolution() const {
+    return getMaxThumbnailResolution(mCameraCharacteristics);
+}
+
+ssize_t VirtualCameraDeviceSession::getJpegBufferSize(
+        uint32_t width, uint32_t height) const {
+    // Constant from camera3.h
+    const ssize_t kMinJpegBufferSize = 256 * 1024 + sizeof(CameraBlob);
+    // Get max jpeg size (area-wise).
+    if (mMaxJpegResolution.width == 0) {
+        ALOGE("%s: Do not have a single supported JPEG stream",
+                __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    // Get max jpeg buffer size
+    ssize_t maxJpegBufferSize = 0;
+    camera_metadata_ro_entry jpegBufMaxSize =
+            mCameraCharacteristics.find(ANDROID_JPEG_MAX_SIZE);
+    if (jpegBufMaxSize.count == 0) {
+        ALOGE("%s: Can't find maximum JPEG size in static metadata!",
+              __FUNCTION__);
+        return BAD_VALUE;
+    }
+    maxJpegBufferSize = jpegBufMaxSize.data.i32[0];
+
+    if (maxJpegBufferSize <= kMinJpegBufferSize) {
+        ALOGE("%s: ANDROID_JPEG_MAX_SIZE (%zd) <= kMinJpegBufferSize (%zd)",
+              __FUNCTION__, maxJpegBufferSize, kMinJpegBufferSize);
+        return BAD_VALUE;
+    }
+
+    // Calculate final jpeg buffer size for the given resolution.
+    float scaleFactor = ((float) (width * height)) /
+            (mMaxJpegResolution.width * mMaxJpegResolution.height);
+    ssize_t jpegBufferSize = scaleFactor * (maxJpegBufferSize - kMinJpegBufferSize) +
+            kMinJpegBufferSize;
+    if (jpegBufferSize > maxJpegBufferSize) {
+        jpegBufferSize = maxJpegBufferSize;
+    }
+
+    return jpegBufferSize;
+}
+
+int VirtualCameraDeviceSession::OutputThread::createJpegLocked(
+        HalStreamBuffer &halBuf,
+        const common::V1_0::helper::CameraMetadata& setting)
+{
+    ATRACE_CALL();
+    int ret;
+    auto lfail = [&](auto... args) {
+        ALOGE(args...);
+
+        return 1;
+    };
+    auto parent = mParent.promote();
+    if (parent == nullptr) {
+       ALOGE("%s: session has been disconnected!", __FUNCTION__);
+       return 1;
+    }
+
+    ALOGV("%s: HAL buffer sid: %d bid: %" PRIu64 " w: %u h: %u",
+          __FUNCTION__, halBuf.streamId, static_cast<uint64_t>(halBuf.bufferId),
+          halBuf.width, halBuf.height);
+    ALOGV("%s: HAL buffer fmt: %x usage: %" PRIx64 " ptr: %p",
+          __FUNCTION__, halBuf.format, static_cast<uint64_t>(halBuf.usage),
+          halBuf.bufPtr);
+    ALOGV("%s: YV12 buffer %d x %d",
+          __FUNCTION__,
+          mYu12Frame->mWidth, mYu12Frame->mHeight);
+
+    int jpegQuality, thumbQuality;
+    Size thumbSize;
+    bool outputThumbnail = true;
+
+    if (setting.exists(ANDROID_JPEG_QUALITY)) {
+        camera_metadata_ro_entry entry =
+            setting.find(ANDROID_JPEG_QUALITY);
+        jpegQuality = entry.data.u8[0];
+    } else {
+        return lfail("%s: ANDROID_JPEG_QUALITY not set",__FUNCTION__);
+    }
+
+    if (setting.exists(ANDROID_JPEG_THUMBNAIL_QUALITY)) {
+        camera_metadata_ro_entry entry =
+            setting.find(ANDROID_JPEG_THUMBNAIL_QUALITY);
+        thumbQuality = entry.data.u8[0];
+    } else {
+        return lfail(
+            "%s: ANDROID_JPEG_THUMBNAIL_QUALITY not set",
+            __FUNCTION__);
+    }
+
+    if (setting.exists(ANDROID_JPEG_THUMBNAIL_SIZE)) {
+        camera_metadata_ro_entry entry =
+            setting.find(ANDROID_JPEG_THUMBNAIL_SIZE);
+        thumbSize = Size { static_cast<uint32_t>(entry.data.i32[0]),
+                           static_cast<uint32_t>(entry.data.i32[1])
+        };
+        if (thumbSize.width == 0 && thumbSize.height == 0) {
+            outputThumbnail = false;
+        }
+    } else {
+        return lfail(
+            "%s: ANDROID_JPEG_THUMBNAIL_SIZE not set", __FUNCTION__);
+    }
+
+    /* Cropped and scaled YU12 buffer for main and thumbnail */
+    YCbCrLayout yu12Main;
+    Size jpegSize { halBuf.width, halBuf.height };
+
+    /* Compute temporary buffer sizes accounting for the following:
+     * thumbnail can't exceed APP1 size of 64K
+     * main image needs to hold APP1, headers, and at most a poorly
+     * compressed image */
+    const ssize_t maxThumbCodeSize = 64 * 1024;
+    const ssize_t maxJpegCodeSize = mBlobBufferSize == 0 ?
+            parent->getJpegBufferSize(jpegSize.width, jpegSize.height) :
+            mBlobBufferSize;
+
+    /* Check that getJpegBufferSize did not return an error */
+    if (maxJpegCodeSize < 0) {
+        return lfail(
+            "%s: getJpegBufferSize returned %zd",__FUNCTION__,maxJpegCodeSize);
+    }
+
+
+    /* Hold actual thumbnail and main image code sizes */
+    size_t thumbCodeSize = 0, jpegCodeSize = 0;
+    /* Temporary thumbnail code buffer */
+    std::vector<uint8_t> thumbCode(outputThumbnail ? maxThumbCodeSize : 0);
+
+    YCbCrLayout yu12Thumb;
+    if (outputThumbnail) {
+        ret = cropAndScaleThumbLocked(mYu12Frame, thumbSize, &yu12Thumb);
+
+        if (ret != 0) {
+            return lfail(
+                "%s: crop and scale thumbnail failed!", __FUNCTION__);
+        }
+    }
+
+    /* Scale and crop main jpeg */
+    ret = cropAndScaleLocked(mYu12Frame, jpegSize, &yu12Main);
+
+    if (ret != 0) {
+        return lfail("%s: crop and scale main failed!", __FUNCTION__);
+    }
+
+    /* Encode the thumbnail image */
+    if (outputThumbnail) {
+        ret = encodeJpegYU12(thumbSize, yu12Thumb,
+                thumbQuality, 0, 0,
+                &thumbCode[0], maxThumbCodeSize, thumbCodeSize);
+
+        if (ret != 0) {
+            return lfail("%s: thumbnail encodeJpegYU12 failed with %d",__FUNCTION__, ret);
+        }
+    }
+
+    /* Combine camera characteristics with request settings to form EXIF
+     * metadata */
+    common::V1_0::helper::CameraMetadata meta(mCameraCharacteristics);
+    meta.append(setting);
+
+    /* Generate EXIF object */
+     std::unique_ptr<ExifUtils> utils(ExifUtils::create());
+    /* Make sure it's initialized */
+     utils->initialize();
+
+     utils->setFromMetadata(meta, jpegSize.width, jpegSize.height);
+     utils->setMake(mExifMake);
+     utils->setModel(mExifModel);
+
+     ret = utils->generateApp1(outputThumbnail ? &thumbCode[0] : 0, thumbCodeSize);
+
+     if (!ret) {
+         return lfail("%s: generating APP1 failed", __FUNCTION__);
+     }
+
+    /* Get internal buffer */
+     size_t exifDataSize = utils->getApp1Length();
+     const uint8_t* exifData = utils->getApp1Buffer();
+
+    /* Lock the HAL jpeg code buffer */
+    void *bufPtr = sHandleImporter.lock(
+            *(halBuf.bufPtr), halBuf.usage, maxJpegCodeSize);
+
+    if (!bufPtr) {
+        return lfail("%s: could not lock %zu bytes", __FUNCTION__, maxJpegCodeSize);
+    }
+
+    /* Encode the main jpeg image */
+     ret = encodeJpegYU12(jpegSize, yu12Main,
+             jpegQuality, exifData, exifDataSize,
+             bufPtr, maxJpegCodeSize, jpegCodeSize);
+
+    /* TODO: Not sure this belongs here, maybe better to pass jpegCodeSize out
+     * and do this when returning buffer to parent */
+    CameraBlob blob { CameraBlobId::JPEG, static_cast<uint32_t>(jpegCodeSize) };
+    void *blobDst =
+        reinterpret_cast<void*>(reinterpret_cast<uintptr_t>(bufPtr) +
+                           maxJpegCodeSize -
+                           sizeof(CameraBlob));
+    memcpy(blobDst, &blob, sizeof(CameraBlob));
+
+    /* Unlock the HAL jpeg code buffer */
+    int relFence = sHandleImporter.unlock(*(halBuf.bufPtr));
+    if (relFence >= 0) {
+        halBuf.acquireFence = relFence;
+    }
+
+    /* Check if our JPEG actually succeeded */
+    if (ret != 0) {
+        return lfail(
+            "%s: encodeJpegYU12 failed with %d",__FUNCTION__, ret);
+    }
+
+    ALOGV("%s: encoded JPEG (ret:%d) with Q:%d max size: %zu",
+          __FUNCTION__, ret, jpegQuality, maxJpegCodeSize);
+
+    return 0;
+}
+
+// static int count = 0;
+bool VirtualCameraDeviceSession::OutputThread::threadLoop() {
+    std::shared_ptr<HalRequest> req;
+    auto parent = mParent.promote();
+    if (parent == nullptr) {
+       ALOGE("%s: session has been disconnected!", __FUNCTION__);
+       return false;
+    }
+
+    // TODO: maybe we need to setup a sensor thread to dq/enq v4l frames
+    //       regularly to prevent v4l buffer queue filled with stale buffers
+    //       when app doesn't program a preveiw request
+    waitForNextRequest(&req);
+    if (req == nullptr) {
+        // No new request, wait again
+        return true;
+    }
+
+    auto onDeviceError = [&](auto... args) {
+        ALOGE(args...);
+        parent->notifyError(
+                req->frameNumber, /*stream*/-1, ErrorCode::ERROR_DEVICE);
+        signalRequestDone();
+        return false;
+    };
+
+    if (req->frameIn->mFourcc != V4L2_PIX_FMT_MJPEG
+        && req->frameIn->mFourcc != V4L2_PIX_FMT_Z16
+        && req->frameIn->mFourcc != V4L2_PIX_FMT_YUYV
+        && req->frameIn->mFourcc != V4L2_PIX_FMT_UYVY
+        ) {
+        return onDeviceError("%s: do not support V4L2 format %c%c%c%c", __FUNCTION__,
+                req->frameIn->mFourcc & 0xFF,
+                (req->frameIn->mFourcc >> 8) & 0xFF,
+                (req->frameIn->mFourcc >> 16) & 0xFF,
+                (req->frameIn->mFourcc >> 24) & 0xFF);
+    }
+
+    // ALOGI("%s: request frameIn V4L2 format %c%c%c%c", __FUNCTION__,
+    //             req->frameIn->mFourcc & 0xFF,
+    //             (req->frameIn->mFourcc >> 8) & 0xFF,
+    //             (req->frameIn->mFourcc >> 16) & 0xFF,
+    //             (req->frameIn->mFourcc >> 24) & 0xFF);
+
+    int res = requestBufferStart(req->buffers);
+    if (res != 0) {
+        ALOGE("%s: send BufferRequest failed! res %d", __FUNCTION__, res);
+        return onDeviceError("%s: failed to send buffer request!", __FUNCTION__);
+    }
+
+    std::unique_lock<std::mutex> lk(mBufferLock);
+    // Convert input V4L2 frame to YU12 of the same size
+    // TODO: see if we can save some computation by converting to YV12 here
+    uint8_t* inData;
+    size_t inDataSize;
+    if (req->frameIn->getData(&inData, &inDataSize) != 0) {
+        lk.unlock();
+        return onDeviceError("%s: V4L2 buffer map failed", __FUNCTION__);
+    }
+
+    // TODO: in some special case maybe we can decode jpg directly to gralloc output?
+    if (req->frameIn->mFourcc == V4L2_PIX_FMT_YUYV) {
+        ATRACE_BEGIN("YUYVtoI420");
+        int alignment = 16;
+        int stride = (req->frameIn->mWidth * 2 + alignment - 1) & ~(alignment - 1);
+        int res = libyuv::YUY2ToI420(
+            inData, stride, static_cast<uint8_t*>(mYu12FrameLayout.y), mYu12FrameLayout.yStride,
+            static_cast<uint8_t*>(mYu12FrameLayout.cb), mYu12FrameLayout.cStride,
+            static_cast<uint8_t*>(mYu12FrameLayout.cr), mYu12FrameLayout.cStride,
+            mYu12Frame->mWidth, mYu12Frame->mHeight);
+        ATRACE_END();
+        if (res != 0) {
+            // For some webcam, the first few V4L2 frames might be malformed...
+            ALOGE("%s: Convert V4L2 frame to YU12 failed! res %d", __FUNCTION__, res);
+            lk.unlock();
+            Status st = parent->processCaptureRequestError(req);
+            if (st != Status::OK) {
+                return onDeviceError("%s: failed to process capture request error!", __FUNCTION__);
+            }
+            signalRequestDone();
+            return true;
+        }
+    } else if (req->frameIn->mFourcc == V4L2_PIX_FMT_UYVY) {
+        ATRACE_BEGIN("UYVYtoI420");
+        // if (count%29 == 1) {
+        //     ALOGI("UYVYtoI420 with datasize: %d %d", (int32_t)inDataSize, count);
+        //     save_image(inData, inDataSize);
+        // }
+        // count ++;
+        int alignment = 16;
+        int stride = (req->frameIn->mWidth * 2 + alignment - 1) & ~(alignment - 1);
+        int res = libyuv::UYVYToI420(
+            inData, stride,
+            static_cast<uint8_t*>(mYu12FrameLayout.y), mYu12FrameLayout.yStride,
+            static_cast<uint8_t*>(mYu12FrameLayout.cb), mYu12FrameLayout.cStride,
+            static_cast<uint8_t*>(mYu12FrameLayout.cr), mYu12FrameLayout.cStride,
+            mYu12Frame->mWidth, mYu12Frame->mHeight);
+        ATRACE_END();
+
+        if (res != 0) {
+            // For some webcam, the first few V4L2 frames might be malformed...
+            ALOGE("%s: Convert V4L2 frame to YU12 failed! res %d", __FUNCTION__, res);
+            lk.unlock();
+            Status st = parent->processCaptureRequestError(req);
+            if (st != Status::OK) {
+                return onDeviceError("%s: failed to process capture request error!", __FUNCTION__);
+            }
+            signalRequestDone();
+            return true;
+        }
+    }
+
+    ATRACE_BEGIN("Wait for BufferRequest done");
+    res = waitForBufferRequestDone(&req->buffers);
+    ATRACE_END();
+
+    // ALOGI("%s %d: flusing inflight requests", __FUNCTION__, __LINE__);
+    if (res != 0) {
+        ALOGE("%s: wait for BufferRequest done failed! res %d", __FUNCTION__, res);
+        lk.unlock();
+        return onDeviceError("%s: failed to process buffer request error!", __FUNCTION__);
+    }
+
+    ALOGV("%s processing new request", __FUNCTION__);
+    const int kSyncWaitTimeoutMs = 500;
+    for (auto& halBuf : req->buffers) {
+        if (*(halBuf.bufPtr) == nullptr) {
+            ALOGW("%s: buffer for stream %d missing", __FUNCTION__, halBuf.streamId);
+            halBuf.fenceTimeout = true;
+        } else if (halBuf.acquireFence >= 0) {
+            int ret = sync_wait(halBuf.acquireFence, kSyncWaitTimeoutMs);
+            if (ret) {
+                halBuf.fenceTimeout = true;
+            } else {
+                ::close(halBuf.acquireFence);
+                halBuf.acquireFence = -1;
+            }
+        }
+
+        if (halBuf.fenceTimeout) {
+            continue;
+        }
+
+        // Gralloc lockYCbCr the buffer
+        switch (halBuf.format) {
+            case PixelFormat::BLOB: {
+                int ret = createJpegLocked(halBuf, req->setting);
+
+                if(ret != 0) {
+                    lk.unlock();
+                    return onDeviceError("%s: createJpegLocked failed with %d",
+                          __FUNCTION__, ret);
+                }
+            } break;
+            case PixelFormat::Y16: {
+                void* outLayout = sHandleImporter.lock(*(halBuf.bufPtr), halBuf.usage, inDataSize);
+
+                std::memcpy(outLayout, inData, inDataSize);
+
+                int relFence = sHandleImporter.unlock(*(halBuf.bufPtr));
+                if (relFence >= 0) {
+                    halBuf.acquireFence = relFence;
+                }
+            } break;
+            case PixelFormat::YCBCR_420_888:
+            case PixelFormat::YV12: {
+                IMapper::Rect outRect {0, 0,
+                        static_cast<int32_t>(halBuf.width),
+                        static_cast<int32_t>(halBuf.height)};
+                YCbCrLayout outLayout = sHandleImporter.lockYCbCr(
+                        *(halBuf.bufPtr), halBuf.usage, outRect);
+                ALOGV("%s: outLayout y %p cb %p cr %p y_str %d c_str %d c_step %d",
+                        __FUNCTION__, outLayout.y, outLayout.cb, outLayout.cr,
+                        outLayout.yStride, outLayout.cStride, outLayout.chromaStep);
+
+                // Convert to output buffer size/format
+                uint32_t outputFourcc = getFourCcFromLayout(outLayout);
+                ALOGV("%s: converting to format %c%c%c%c", __FUNCTION__,
+                        outputFourcc & 0xFF,
+                        (outputFourcc >> 8) & 0xFF,
+                        (outputFourcc >> 16) & 0xFF,
+                        (outputFourcc >> 24) & 0xFF);
+
+                YCbCrLayout cropAndScaled;
+                ATRACE_BEGIN("cropAndScaleLocked");
+                int ret = cropAndScaleLocked(
+                        mYu12Frame,
+                        Size { halBuf.width, halBuf.height },
+                        &cropAndScaled);
+                ATRACE_END();
+                if (ret != 0) {
+                    lk.unlock();
+                    return onDeviceError("%s: crop and scale failed!", __FUNCTION__);
+                }
+
+                Size sz {halBuf.width, halBuf.height};
+                ATRACE_BEGIN("formatConvert");
+                ret = formatConvert(cropAndScaled, outLayout, sz, outputFourcc);
+                ATRACE_END();
+                if (ret != 0) {
+                    lk.unlock();
+                    return onDeviceError("%s: format coversion failed!", __FUNCTION__);
+                }
+                int relFence = sHandleImporter.unlock(*(halBuf.bufPtr));
+                if (relFence >= 0) {
+                    halBuf.acquireFence = relFence;
+                }
+            } break;
+            default:
+                lk.unlock();
+                return onDeviceError("%s: unknown output format %x", __FUNCTION__, halBuf.format);
+        }
+    } // for each buffer
+    mScaledYu12Frames.clear();
+
+    // Don't hold the lock while calling back to parent
+    lk.unlock();
+    Status st = parent->processCaptureResult(req);
+    if (st != Status::OK) {
+        return onDeviceError("%s: failed to process capture result!", __FUNCTION__);
+    }
+    signalRequestDone();
+    return true;
+}
+
+Status VirtualCameraDeviceSession::OutputThread::allocateIntermediateBuffers(
+        const Size& v4lSize, const Size& thumbSize,
+        const hidl_vec<Stream>& streams,
+        uint32_t blobBufferSize) {
+    std::lock_guard<std::mutex> lk(mBufferLock);
+    if (mScaledYu12Frames.size() != 0) {
+        ALOGE("%s: intermediate buffer pool has %zu inflight buffers! (expect 0)",
+                __FUNCTION__, mScaledYu12Frames.size());
+        return Status::INTERNAL_ERROR;
+    }
+
+    // Allocating intermediate YU12 frame
+    if (mYu12Frame == nullptr || mYu12Frame->mWidth != v4lSize.width ||
+            mYu12Frame->mHeight != v4lSize.height) {
+        mYu12Frame.clear();
+        mYu12Frame = new AllocatedFrame(v4lSize.width, v4lSize.height);
+        int ret = mYu12Frame->allocate(&mYu12FrameLayout);
+        if (ret != 0) {
+            ALOGE("%s: allocating YU12 frame failed!", __FUNCTION__);
+            return Status::INTERNAL_ERROR;
+        }
+    }
+
+    // Allocating intermediate YU12 thumbnail frame
+    if (mYu12ThumbFrame == nullptr ||
+        mYu12ThumbFrame->mWidth != thumbSize.width ||
+        mYu12ThumbFrame->mHeight != thumbSize.height) {
+        mYu12ThumbFrame.clear();
+        mYu12ThumbFrame = new AllocatedFrame(thumbSize.width, thumbSize.height);
+        int ret = mYu12ThumbFrame->allocate(&mYu12ThumbFrameLayout);
+        if (ret != 0) {
+            ALOGE("%s: allocating YU12 thumb frame failed!", __FUNCTION__);
+            return Status::INTERNAL_ERROR;
+        }
+    }
+
+    // Allocating scaled buffers
+    for (const auto& stream : streams) {
+        Size sz = {stream.width, stream.height};
+        if (sz == v4lSize) {
+            continue; // Don't need an intermediate buffer same size as v4lBuffer
+        }
+        if (mIntermediateBuffers.count(sz) == 0) {
+            // Create new intermediate buffer
+            sp<AllocatedFrame> buf = new AllocatedFrame(stream.width, stream.height);
+            int ret = buf->allocate();
+            if (ret != 0) {
+                ALOGE("%s: allocating intermediate YU12 frame %dx%d failed!",
+                            __FUNCTION__, stream.width, stream.height);
+                return Status::INTERNAL_ERROR;
+            }
+            mIntermediateBuffers[sz] = buf;
+        }
+    }
+
+    // Remove unconfigured buffers
+    auto it = mIntermediateBuffers.begin();
+    while (it != mIntermediateBuffers.end()) {
+        bool configured = false;
+        auto sz = it->first;
+        for (const auto& stream : streams) {
+            if (stream.width == sz.width && stream.height == sz.height) {
+                configured = true;
+                break;
+            }
+        }
+        if (configured) {
+            it++;
+        } else {
+            it = mIntermediateBuffers.erase(it);
+        }
+    }
+
+    mBlobBufferSize = blobBufferSize;
+    return Status::OK;
+}
+
+void VirtualCameraDeviceSession::OutputThread::clearIntermediateBuffers() {
+    std::lock_guard<std::mutex> lk(mBufferLock);
+    mYu12Frame.clear();
+    mYu12ThumbFrame.clear();
+    mIntermediateBuffers.clear();
+    mBlobBufferSize = 0;
+}
+
+Status VirtualCameraDeviceSession::OutputThread::submitRequest(
+        const std::shared_ptr<HalRequest>& req) {
+    std::unique_lock<std::mutex> lk(mRequestListLock);
+    mRequestList.push_back(req);
+    lk.unlock();
+    mRequestCond.notify_one();
+    return Status::OK;
+}
+
+void VirtualCameraDeviceSession::OutputThread::flush() {
+    ATRACE_CALL();
+    auto parent = mParent.promote();
+    if (parent == nullptr) {
+       ALOGE("%s: session has been disconnected!", __FUNCTION__);
+       return;
+    }
+
+    std::unique_lock<std::mutex> lk(mRequestListLock);
+    std::list<std::shared_ptr<HalRequest>> reqs = std::move(mRequestList);
+    mRequestList.clear();
+    if (mProcessingRequest) {
+        std::chrono::seconds timeout = std::chrono::seconds(kFlushWaitTimeoutSec);
+        auto st = mRequestDoneCond.wait_for(lk, timeout);
+        if (st == std::cv_status::timeout) {
+            ALOGE("%s: wait for inflight request finish timeout!", __FUNCTION__);
+        }
+    }
+
+    ALOGV("%s: flusing inflight requests", __FUNCTION__);
+    lk.unlock();
+    for (const auto& req : reqs) {
+        parent->processCaptureRequestError(req);
+    }
+}
+
+std::list<std::shared_ptr<HalRequest>>
+VirtualCameraDeviceSession::OutputThread::switchToOffline() {
+    ATRACE_CALL();
+    std::list<std::shared_ptr<HalRequest>> emptyList;
+    auto parent = mParent.promote();
+    if (parent == nullptr) {
+       ALOGE("%s: session has been disconnected!", __FUNCTION__);
+       return emptyList;
+    }
+
+    std::unique_lock<std::mutex> lk(mRequestListLock);
+    std::list<std::shared_ptr<HalRequest>> reqs = std::move(mRequestList);
+    mRequestList.clear();
+    if (mProcessingRequest) {
+        std::chrono::seconds timeout = std::chrono::seconds(kFlushWaitTimeoutSec);
+        auto st = mRequestDoneCond.wait_for(lk, timeout);
+        if (st == std::cv_status::timeout) {
+            ALOGE("%s: wait for inflight request finish timeout!", __FUNCTION__);
+        }
+    }
+    lk.unlock();
+    clearIntermediateBuffers();
+    ALOGV("%s: returning %zu request for offline processing", __FUNCTION__, reqs.size());
+    return reqs;
+}
+
+void VirtualCameraDeviceSession::OutputThread::waitForNextRequest(
+        std::shared_ptr<HalRequest>* out) {
+    ATRACE_CALL();
+    if (out == nullptr) {
+        ALOGE("%s: out is null", __FUNCTION__);
+        return;
+    }
+
+    std::unique_lock<std::mutex> lk(mRequestListLock);
+    int waitTimes = 0;
+    while (mRequestList.empty()) {
+        if (exitPending()) {
+            return;
+        }
+        std::chrono::milliseconds timeout = std::chrono::milliseconds(kReqWaitTimeoutMs);
+        auto st = mRequestCond.wait_for(lk, timeout);
+        if (st == std::cv_status::timeout) {
+            waitTimes++;
+            if (waitTimes == kReqWaitTimesMax) {
+                // no new request, return
+                return;
+            }
+        }
+    }
+    *out = mRequestList.front();
+    mRequestList.pop_front();
+    mProcessingRequest = true;
+    mProcessingFrameNumer = (*out)->frameNumber;
+}
+
+void VirtualCameraDeviceSession::OutputThread::signalRequestDone() {
+    std::unique_lock<std::mutex> lk(mRequestListLock);
+    mProcessingRequest = false;
+    mProcessingFrameNumer = 0;
+    lk.unlock();
+    mRequestDoneCond.notify_one();
+}
+
+void VirtualCameraDeviceSession::OutputThread::dump(int fd) {
+    std::lock_guard<std::mutex> lk(mRequestListLock);
+    if (mProcessingRequest) {
+        dprintf(fd, "OutputThread processing frame %d\n", mProcessingFrameNumer);
+    } else {
+        dprintf(fd, "OutputThread not processing any frames\n");
+    }
+    dprintf(fd, "OutputThread request list contains frame: ");
+    for (const auto& req : mRequestList) {
+        dprintf(fd, "%d, ", req->frameNumber);
+    }
+    dprintf(fd, "\n");
+}
+
+void VirtualCameraDeviceSession::cleanupBuffersLocked(int id) {
+    for (auto& pair : mCirculatingBuffers.at(id)) {
+        sHandleImporter.freeBuffer(pair.second);
+    }
+    mCirculatingBuffers[id].clear();
+    mCirculatingBuffers.erase(id);
+}
+
+void VirtualCameraDeviceSession::updateBufferCaches(const hidl_vec<BufferCache>& cachesToRemove) {
+    Mutex::Autolock _l(mCbsLock);
+    for (auto& cache : cachesToRemove) {
+        auto cbsIt = mCirculatingBuffers.find(cache.streamId);
+        if (cbsIt == mCirculatingBuffers.end()) {
+            // The stream could have been removed
+            continue;
+        }
+        CirculatingBuffers& cbs = cbsIt->second;
+        auto it = cbs.find(cache.bufferId);
+        if (it != cbs.end()) {
+            sHandleImporter.freeBuffer(it->second);
+            cbs.erase(it);
+        } else {
+            ALOGE("%s: stream %d buffer %" PRIu64 " is not cached",
+                    __FUNCTION__, cache.streamId, cache.bufferId);
+        }
+    }
+}
+
+bool VirtualCameraDeviceSession::isSupported(const Stream& stream,
+        const std::vector<SupportedV4L2Format>& supportedFormats,
+        const ExternalCameraConfig& devCfg) {
+    int32_t ds = static_cast<int32_t>(stream.dataSpace);
+    PixelFormat fmt = stream.format;
+    uint32_t width = stream.width;
+    uint32_t height = stream.height;
+    // TODO: check usage flags
+
+    if (stream.streamType != StreamType::OUTPUT) {
+        ALOGE("%s: does not support non-output stream type", __FUNCTION__);
+        return false;
+    }
+
+    if (stream.rotation != StreamRotation::ROTATION_0) {
+        ALOGE("%s: does not support stream rotation", __FUNCTION__);
+        return false;
+    }
+
+    switch (fmt) {
+        case PixelFormat::BLOB:
+            if (ds != static_cast<int32_t>(Dataspace::V0_JFIF)) {
+                ALOGI("%s: BLOB format does not support dataSpace %x", __FUNCTION__, ds);
+                return false;
+            }
+            break;
+        case PixelFormat::IMPLEMENTATION_DEFINED:
+        case PixelFormat::YCBCR_420_888:
+        case PixelFormat::YV12:
+            // TODO: check what dataspace we can support here.
+            // intentional no-ops.
+            break;
+        case PixelFormat::Y16:
+            if (!devCfg.depthEnabled) {
+                ALOGI("%s: Depth is not Enabled", __FUNCTION__);
+                return false;
+            }
+            if (!(ds & Dataspace::DEPTH)) {
+                ALOGI("%s: Y16 supports only dataSpace DEPTH", __FUNCTION__);
+                return false;
+            }
+            break;
+        default:
+            ALOGI("%s: does not support format %x", __FUNCTION__, fmt);
+            return false;
+    }
+
+    // Assume we can convert any V4L2 format to any of supported output format for now, i.e,
+    // ignoring v4l2Fmt.fourcc for now. Might need more subtle check if we support more v4l format
+    // in the futrue.
+    for (const auto& v4l2Fmt : supportedFormats) {
+        if (width == v4l2Fmt.width && height == v4l2Fmt.height) {
+            return true;
+        }
+    }
+    ALOGI("%s: resolution %dx%d is not supported", __FUNCTION__, width, height);
+    return false;
+}
+
+int VirtualCameraDeviceSession::v4l2StreamOffLocked() {
+    return OK;
+}
+
+int VirtualCameraDeviceSession::setV4l2FpsLocked(double fps) {
+    // // VIDIOC_G_PARM/VIDIOC_S_PARM: set fps
+    // v4l2_streamparm streamparm = { .type = V4L2_BUF_TYPE_VIDEO_CAPTURE };
+    // // The following line checks that the driver knows about framerate get/set.
+    // mV4l2StreamingFps=30.0;
+    // int ret = TEMP_FAILURE_RETRY(ioctl(mV4l2Fd.get(), VIDIOC_G_PARM, &streamparm));
+    // if (ret != 0) {
+    //     if (errno == -EINVAL) {
+    //         ALOGW("%s: device does not support VIDIOC_G_PARM", __FUNCTION__);
+    //     }
+    //     return -errno;
+    // }
+    // // Now check if the device is able to accept a capture framerate set.
+    // if (!(streamparm.parm.capture.capability & V4L2_CAP_TIMEPERFRAME)) {
+    //     ALOGW("%s: device does not support V4L2_CAP_TIMEPERFRAME", __FUNCTION__);
+    //     return -EINVAL;
+    // }
+
+    // // fps is float, approximate by a fraction.
+    // const int kFrameRatePrecision = 10000;
+    // streamparm.parm.capture.timeperframe.numerator = kFrameRatePrecision;
+    // streamparm.parm.capture.timeperframe.denominator =
+    //     (fps * kFrameRatePrecision);
+
+    // if (TEMP_FAILURE_RETRY(ioctl(mV4l2Fd.get(), VIDIOC_S_PARM, &streamparm)) < 0) {
+    //     ALOGE("%s: failed to set framerate to %f: %s", __FUNCTION__, fps, strerror(errno));
+    //     return -1;
+    // }
+
+    // double retFps = streamparm.parm.capture.timeperframe.denominator /
+    //         static_cast<double>(streamparm.parm.capture.timeperframe.numerator);
+
+    // if (std::fabs(fps - retFps) > 1.0) {
+    //     ALOGE("%s: expect fps %f, got %f instead", __FUNCTION__, fps, retFps);
+    //     return -1;
+    // }
+    mV4l2StreamingFps = fps;
+    return 0;
+}
+
+int VirtualCameraDeviceSession::configureV4l2StreamLocked(
+        const SupportedV4L2Format& v4l2Fmt, double requestFps) {
+    ATRACE_CALL();
+    // int ret = v4l2StreamOffLocked();
+    // if (ret != OK) {
+    //     ALOGE("%s: stop v4l2 streaming failed: ret %d", __FUNCTION__, ret);
+    //     return ret;
+    // }
+
+    // VIDIOC_S_FMT w/h/fmt
+    v4l2_format fmt;
+    fmt.fmt.pix.width = v4l2Fmt.width;
+    fmt.fmt.pix.height = v4l2Fmt.height;
+    fmt.fmt.pix.pixelformat = v4l2Fmt.fourcc;
+    fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+
+    mV4L2BufferCount = REQUEST_BUFFER_COUNT; //should get from QueryBuf
+    sp<VirtualCameraDevice> virtDevice = mVirtManager->getVirtCamByID(mCameraId);
+    if(virtDevice->configureStream() != 0) { 
+        ALOGE("%s: failed to congfiure ", __FUNCTION__);
+        return -errno;
+    }
+
+    if(virtDevice->streamOn() != 0) { 
+        ALOGE("%s: failed to stream on ", __FUNCTION__);
+        return -errno;
+    }
+    if (mFrameBuffer == nullptr)
+        mFrameBuffer = new FrameBuffer();
+    mFrameBuffer->mFourcc = V4L2_PIX_FMT_UYVY;
+    // mFrameBuffer->mFourcc = V4L2_PIX_FMT_YUYV;
+    // mFrameBuffer->mDataSize = mFrameBuffer->mWidth * mFrameBuffer->mHeight * 2 + mFrameBuffer->mWidth * 2;
+     mFrameBuffer->mDataSize = mFrameBuffer->mWidth * mFrameBuffer->mHeight * 2;
+    ALOGI("%s: alloc buffer size %d", __FUNCTION__, mFrameBuffer->mDataSize);
+
+    virtDevice->enqueueFrame(mFrameBuffer);
+    
+    ALOGI("%s: start V4L2 streaming %dx%d@%f",
+                __FUNCTION__, v4l2Fmt.width, v4l2Fmt.height, requestFps);
+    mV4l2StreamingFmt = v4l2Fmt;
+    mV4l2Streaming = true;
+    return OK;
+}
+
+sp<V4L2Frame> VirtualCameraDeviceSession::dequeueV4l2FrameLocked(/*out*/nsecs_t* shutterTs) {
+    ATRACE_CALL();
+    sp<V4L2Frame> ret = nullptr;
+
+    // ALOGI("%s %d", __FUNCTION__, __LINE__);
+    if (shutterTs == nullptr) {
+        ALOGE("%s: shutterTs must not be null!", __FUNCTION__);
+        return ret;
+    }
+
+    {
+        std::unique_lock<std::mutex> lk(mV4l2BufferLock);
+        if (mNumDequeuedV4l2Buffers == mV4L2BufferCount) {
+            int waitRet = waitForV4L2BufferReturnLocked(lk);
+            if (waitRet != 0) {
+                return ret;
+            }
+        }
+    }
+
+    //Wait and get the buffer.
+    if (mFrameBuffer == nullptr) {
+        ALOGE("%s: session mFrameBuffer == nullptr", __FUNCTION__);
+        return nullptr;
+    }
+
+    sp<VirtualCameraDevice> virtDevice = mVirtManager->getVirtCamByID(mCameraId);
+    virtDevice->dequeueFrame(mFrameBuffer);
+    mFrameBuffer->mFourcc = V4L2_PIX_FMT_UYVY;
+    // mFrameBuffer->mFourcc = V4L2_PIX_FMT_YUYV;
+    ret = new V4L2Frame(1920, 1080, mFrameBuffer->mFourcc, 0, 0, mFrameBuffer->mDataSize, 0);
+    ret->setMapData(mFrameBuffer->mData);
+
+    *shutterTs = systemTime(SYSTEM_TIME_MONOTONIC);
+    {
+        std::lock_guard<std::mutex> lk(mV4l2BufferLock);
+        mNumDequeuedV4l2Buffers++;
+    }
+
+    return ret;
+}
+
+void VirtualCameraDeviceSession::enqueueV4l2Frame() {
+// void VirtualCameraDeviceSession::enqueueV4l2Frame(const sp<V4L2Frame>& frame) {
+    ATRACE_CALL();
+    ATRACE_BEGIN("VIDIOC_QBUF");
+
+    if (mFrameBuffer == nullptr)
+        mFrameBuffer = new FrameBuffer();
+    mFrameBuffer->mFourcc = V4L2_PIX_FMT_UYVY;
+    // mFrameBuffer->mFourcc = V4L2_PIX_FMT_YUYV;
+    // mFrameBuffer->mDataSize = mFrameBuffer->mWidth * mFrameBuffer->mHeight * 2 + mFrameBuffer->mWidth * 2;
+    mFrameBuffer->mDataSize = mFrameBuffer->mWidth * mFrameBuffer->mHeight * 2;
+    // ALOGI("%s: alloc buffer size %d", __FUNCTION__, mFrameBuffer->mDataSize);
+
+    sp<VirtualCameraDevice> virtDevice = mVirtManager->getVirtCamByID(mCameraId);
+    if (virtDevice == nullptr) {
+        ALOGE("%s: cannot fetch virtual device %s.", __FUNCTION__, mCameraId.c_str());
+        return;
+    }
+
+    virtDevice->enqueueFrame(mFrameBuffer);
+    {
+        std::lock_guard<std::mutex> lk(mV4l2BufferLock);
+        mNumDequeuedV4l2Buffers--;
+    }
+    mV4L2BufferReturned.notify_one();
+    // ALOGI("%s: mNumDequeuedV4l2Buffers = %d done.", __FUNCTION__, (int)mNumDequeuedV4l2Buffers);
+}
+
+// Status VirtualCameraDeviceSession::isStreamCombinationSupported(
+//         const V3_2::StreamConfiguration& config,
+//         const std::vector<SupportedV4L2Format>& supportedFormats,
+//         const ExternalCameraConfig& devCfg) {
+//     if (config.operationMode != StreamConfigurationMode::NORMAL_MODE) {
+//         ALOGE("%s: unsupported operation mode: %d", __FUNCTION__, config.operationMode);
+//         return Status::ILLEGAL_ARGUMENT;
+//     }
+
+//     if (config.streams.size() == 0) {
+//         ALOGE("%s: cannot configure zero stream", __FUNCTION__);
+//         return Status::ILLEGAL_ARGUMENT;
+//     }
+
+//     int numProcessedStream = 0;
+//     int numStallStream = 0;
+//     for (const auto& stream : config.streams) {
+//         // Check if the format/width/height combo is supported
+//         if (!isSupported(stream, supportedFormats, devCfg)) {
+//             return Status::ILLEGAL_ARGUMENT;
+//         }
+//         if (stream.format == PixelFormat::BLOB) {
+//             numStallStream++;
+//         } else {
+//             numProcessedStream++;
+//         }
+//     }
+
+//     if (numProcessedStream > kMaxProcessedStream) {
+//         ALOGE("%s: too many processed streams (expect <= %d, got %d)", __FUNCTION__,
+//                 kMaxProcessedStream, numProcessedStream);
+//         return Status::ILLEGAL_ARGUMENT;
+//     }
+
+//     if (numStallStream > kMaxStallStream) {
+//         ALOGE("%s: too many stall streams (expect <= %d, got %d)", __FUNCTION__,
+//                 kMaxStallStream, numStallStream);
+//         return Status::ILLEGAL_ARGUMENT;
+//     }
+
+//     return Status::OK;
+// }
+
+Status VirtualCameraDeviceSession::configureStreams(
+        const V3_2::StreamConfiguration& config,
+        V3_3::HalStreamConfiguration* out,
+        uint32_t blobBufferSize) {
+    ATRACE_CALL();
+
+    // Status status = isStreamCombinationSupported(config, mSupportedFormats, mCfg);
+    // if (status != Status::OK) {
+    //     return status;
+    // }
+
+    Status status = initStatus();
+    if (status != Status::OK) {
+        return status;
+    }
+
+
+    {
+        std::lock_guard<std::mutex> lk(mInflightFramesLock);
+        if (!mInflightFrames.empty()) {
+            ALOGE("%s: trying to configureStreams while there are still %zu inflight frames!",
+                    __FUNCTION__, mInflightFrames.size());
+            return Status::INTERNAL_ERROR;
+        }
+    }
+
+    Mutex::Autolock _l(mLock);
+    {
+        Mutex::Autolock _l(mCbsLock);
+        // Add new streams
+        for (const auto& stream : config.streams) {
+            if (mStreamMap.count(stream.id) == 0) {
+                mStreamMap[stream.id] = stream;
+                mCirculatingBuffers.emplace(stream.id, CirculatingBuffers{});
+            }
+        }
+
+        // Cleanup removed streams
+        for(auto it = mStreamMap.begin(); it != mStreamMap.end();) {
+            int id = it->first;
+            bool found = false;
+            for (const auto& stream : config.streams) {
+                if (id == stream.id) {
+                    found = true;
+                    break;
+                }
+            }
+            if (!found) {
+                // Unmap all buffers of deleted stream
+                cleanupBuffersLocked(id);
+                it = mStreamMap.erase(it);
+            } else {
+                ++it;
+            }
+        }
+    }
+
+    // Now select a V4L2 format to produce all output streams
+    float desiredAr = (mCroppingType == VERTICAL) ? kMaxAspectRatio : kMinAspectRatio;
+    uint32_t maxDim = 0;
+    for (const auto& stream : config.streams) {
+        float aspectRatio = ASPECT_RATIO(stream);
+        ALOGI("%s: request stream %dx%d", __FUNCTION__, stream.width, stream.height);
+        if ((mCroppingType == VERTICAL && aspectRatio < desiredAr) ||
+                (mCroppingType == HORIZONTAL && aspectRatio > desiredAr)) {
+            desiredAr = aspectRatio;
+        }
+
+        // The dimension that's not cropped
+        uint32_t dim = (mCroppingType == VERTICAL) ? stream.width : stream.height;
+        if (dim > maxDim) {
+            maxDim = dim;
+        }
+    }
+    // Find the smallest format that matches the desired aspect ratio and is wide/high enough
+    SupportedV4L2Format v4l2Fmt {.width = 1920, .height = 1080};
+    for (const auto& fmt : mSupportedFormats) {
+        uint32_t dim = (mCroppingType == VERTICAL) ? fmt.width : fmt.height;
+        if (dim >= maxDim) {
+            float aspectRatio = ASPECT_RATIO(fmt);
+            if (isAspectRatioClose(aspectRatio, desiredAr)) {
+                v4l2Fmt = fmt;
+                // since mSupportedFormats is sorted by width then height, the first matching fmt
+                // will be the smallest one with matching aspect ratio
+                break;
+            }
+        }
+    }
+    if (v4l2Fmt.width == 0) {
+        // Cannot find exact good aspect ratio candidate, try to find a close one
+        for (const auto& fmt : mSupportedFormats) {
+            uint32_t dim = (mCroppingType == VERTICAL) ? fmt.width : fmt.height;
+            if (dim >= maxDim) {
+                float aspectRatio = ASPECT_RATIO(fmt);
+                if ((mCroppingType == VERTICAL && aspectRatio < desiredAr) ||
+                        (mCroppingType == HORIZONTAL && aspectRatio > desiredAr)) {
+                    v4l2Fmt = fmt;
+                    break;
+                }
+            }
+        }
+    }
+
+    if (v4l2Fmt.width == 0) {
+        ALOGE("%s: unable to find a resolution matching (%s at least %d, aspect ratio %f)"
+                , __FUNCTION__, (mCroppingType == VERTICAL) ? "width" : "height",
+                maxDim, desiredAr);
+        return Status::ILLEGAL_ARGUMENT;
+    }
+
+    if (configureV4l2StreamLocked(v4l2Fmt) != 0) {
+        ALOGE("V4L configuration failed!, format:%c%c%c%c, w %d, h %d",
+            v4l2Fmt.fourcc & 0xFF,
+            (v4l2Fmt.fourcc >> 8) & 0xFF,
+            (v4l2Fmt.fourcc >> 16) & 0xFF,
+            (v4l2Fmt.fourcc >> 24) & 0xFF,
+            v4l2Fmt.width, v4l2Fmt.height);
+        return Status::INTERNAL_ERROR;
+    }
+
+    Size v4lSize = {v4l2Fmt.width, v4l2Fmt.height};
+    Size thumbSize { 0, 0 };
+    camera_metadata_ro_entry entry =
+        mCameraCharacteristics.find(ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES);
+    for(uint32_t i = 0; i < entry.count; i += 2) {
+        Size sz { static_cast<uint32_t>(entry.data.i32[i]),
+                  static_cast<uint32_t>(entry.data.i32[i+1]) };
+        if(sz.width * sz.height > thumbSize.width * thumbSize.height) {
+            thumbSize = sz;
+        }
+    }
+
+    if (thumbSize.width * thumbSize.height == 0) {
+        ALOGE("%s: non-zero thumbnail size not available", __FUNCTION__);
+        return Status::INTERNAL_ERROR;
+    }
+
+    mBlobBufferSize = blobBufferSize;
+    status = mOutputThread->allocateIntermediateBuffers(v4lSize,
+                mMaxThumbResolution, config.streams, blobBufferSize);
+    if (status != Status::OK) {
+        ALOGE("%s: allocating intermediate buffers failed!", __FUNCTION__);
+        return status;
+    }
+
+    out->streams.resize(config.streams.size());
+    for (size_t i = 0; i < config.streams.size(); i++) {
+        out->streams[i].overrideDataSpace = config.streams[i].dataSpace;
+        out->streams[i].v3_2.id = config.streams[i].id;
+        // TODO: double check should we add those CAMERA flags
+        mStreamMap[config.streams[i].id].usage =
+                out->streams[i].v3_2.producerUsage = config.streams[i].usage |
+                BufferUsage::CPU_WRITE_OFTEN |
+                BufferUsage::CAMERA_OUTPUT;
+        out->streams[i].v3_2.consumerUsage = 0;
+        out->streams[i].v3_2.maxBuffers  = mV4L2BufferCount;
+
+        switch (config.streams[i].format) {
+            case PixelFormat::BLOB:
+            case PixelFormat::YCBCR_420_888:
+            case PixelFormat::YV12: // Used by SurfaceTexture
+            case PixelFormat::Y16:
+                // No override
+                out->streams[i].v3_2.overrideFormat = config.streams[i].format;
+                break;
+            case PixelFormat::IMPLEMENTATION_DEFINED:
+                // Override based on VIDEO or not
+                out->streams[i].v3_2.overrideFormat =
+                        (config.streams[i].usage & BufferUsage::VIDEO_ENCODER) ?
+                        PixelFormat::YCBCR_420_888 : PixelFormat::YV12;
+                // Save overridden formt in mStreamMap
+                mStreamMap[config.streams[i].id].format = out->streams[i].v3_2.overrideFormat;
+                break;
+            default:
+                ALOGE("%s: unsupported format 0x%x", __FUNCTION__, config.streams[i].format);
+                return Status::ILLEGAL_ARGUMENT;
+        }
+    }
+
+    mFirstRequest = true;
+    return Status::OK;
+}
+
+bool VirtualCameraDeviceSession::isClosed() {
+    Mutex::Autolock _l(mLock);
+    return mClosed;
+}
+
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof(a[0]))
+#define UPDATE(md, tag, data, size)               \
+do {                                              \
+    if ((md).update((tag), (data), (size))) {     \
+        ALOGE("Update " #tag " failed!");         \
+        return BAD_VALUE;                         \
+    }                                             \
+} while (0)
+
+status_t VirtualCameraDeviceSession::initDefaultRequests() {
+    ::android::hardware::camera::common::V1_0::helper::CameraMetadata md;
+
+    const uint8_t aberrationMode = ANDROID_COLOR_CORRECTION_ABERRATION_MODE_OFF;
+    UPDATE(md, ANDROID_COLOR_CORRECTION_ABERRATION_MODE, &aberrationMode, 1);
+
+    const int32_t exposureCompensation = 0;
+    UPDATE(md, ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION, &exposureCompensation, 1);
+
+    const uint8_t videoStabilizationMode = ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF;
+    UPDATE(md, ANDROID_CONTROL_VIDEO_STABILIZATION_MODE, &videoStabilizationMode, 1);
+
+    const uint8_t awbMode = ANDROID_CONTROL_AWB_MODE_AUTO;
+    UPDATE(md, ANDROID_CONTROL_AWB_MODE, &awbMode, 1);
+
+    const uint8_t aeMode = ANDROID_CONTROL_AE_MODE_ON;
+    UPDATE(md, ANDROID_CONTROL_AE_MODE, &aeMode, 1);
+
+    const uint8_t aePrecaptureTrigger = ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_IDLE;
+    UPDATE(md, ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER, &aePrecaptureTrigger, 1);
+
+    const uint8_t afMode = ANDROID_CONTROL_AF_MODE_AUTO;
+    UPDATE(md, ANDROID_CONTROL_AF_MODE, &afMode, 1);
+
+    const uint8_t afTrigger = ANDROID_CONTROL_AF_TRIGGER_IDLE;
+    UPDATE(md, ANDROID_CONTROL_AF_TRIGGER, &afTrigger, 1);
+
+    const uint8_t sceneMode = ANDROID_CONTROL_SCENE_MODE_DISABLED;
+    UPDATE(md, ANDROID_CONTROL_SCENE_MODE, &sceneMode, 1);
+
+    const uint8_t effectMode = ANDROID_CONTROL_EFFECT_MODE_OFF;
+    UPDATE(md, ANDROID_CONTROL_EFFECT_MODE, &effectMode, 1);
+
+    const uint8_t flashMode = ANDROID_FLASH_MODE_OFF;
+    UPDATE(md, ANDROID_FLASH_MODE, &flashMode, 1);
+
+    const int32_t thumbnailSize[] = {240, 180};
+    UPDATE(md, ANDROID_JPEG_THUMBNAIL_SIZE, thumbnailSize, 2);
+
+    const uint8_t jpegQuality = 90;
+    UPDATE(md, ANDROID_JPEG_QUALITY, &jpegQuality, 1);
+    UPDATE(md, ANDROID_JPEG_THUMBNAIL_QUALITY, &jpegQuality, 1);
+
+    const int32_t jpegOrientation = 0;
+    UPDATE(md, ANDROID_JPEG_ORIENTATION, &jpegOrientation, 1);
+
+    const uint8_t oisMode = ANDROID_LENS_OPTICAL_STABILIZATION_MODE_OFF;
+    UPDATE(md, ANDROID_LENS_OPTICAL_STABILIZATION_MODE, &oisMode, 1);
+
+    const uint8_t nrMode = ANDROID_NOISE_REDUCTION_MODE_OFF;
+    UPDATE(md, ANDROID_NOISE_REDUCTION_MODE, &nrMode, 1);
+
+    const int32_t testPatternModes = ANDROID_SENSOR_TEST_PATTERN_MODE_OFF;
+    UPDATE(md, ANDROID_SENSOR_TEST_PATTERN_MODE, &testPatternModes, 1);
+
+    const uint8_t fdMode = ANDROID_STATISTICS_FACE_DETECT_MODE_OFF;
+    UPDATE(md, ANDROID_STATISTICS_FACE_DETECT_MODE, &fdMode, 1);
+
+    const uint8_t hotpixelMode = ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE_OFF;
+    UPDATE(md, ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE, &hotpixelMode, 1);
+
+    bool support30Fps = false;
+    int32_t maxFps = std::numeric_limits<int32_t>::min();
+    for (const auto& supportedFormat : mSupportedFormats) {
+        for (const auto& fr : supportedFormat.frameRates) {
+            int32_t framerateInt = static_cast<int32_t>(fr.getDouble());
+            ALOGI("%s maxFps=%d, framerateInt=%d", __FUNCTION__, maxFps, framerateInt);
+            if (maxFps < framerateInt) {
+                maxFps = framerateInt;
+            }
+            if (framerateInt == 30) {
+                support30Fps = true;
+                break;
+            }
+        }
+        if (support30Fps) {
+            break;
+        }
+    }
+    // int32_t defaultFramerate = support30Fps ? 30 : maxFps;
+    int32_t defaultFramerate = 30;
+    int32_t defaultFpsRange[] = {defaultFramerate / 2, defaultFramerate};
+    UPDATE(md, ANDROID_CONTROL_AE_TARGET_FPS_RANGE, defaultFpsRange, ARRAY_SIZE(defaultFpsRange));
+
+    uint8_t antibandingMode = ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO;
+    UPDATE(md, ANDROID_CONTROL_AE_ANTIBANDING_MODE, &antibandingMode, 1);
+
+    const uint8_t controlMode = ANDROID_CONTROL_MODE_AUTO;
+    UPDATE(md, ANDROID_CONTROL_MODE, &controlMode, 1);
+
+    auto requestTemplates = hidl_enum_range<RequestTemplate>();
+    for (RequestTemplate type : requestTemplates) {
+        ::android::hardware::camera::common::V1_0::helper::CameraMetadata mdCopy = md;
+        uint8_t intent = ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW;
+        switch (type) {
+            case RequestTemplate::PREVIEW:
+                intent = ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW;
+                break;
+            case RequestTemplate::STILL_CAPTURE:
+                intent = ANDROID_CONTROL_CAPTURE_INTENT_STILL_CAPTURE;
+                break;
+            case RequestTemplate::VIDEO_RECORD:
+                intent = ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_RECORD;
+                break;
+            case RequestTemplate::VIDEO_SNAPSHOT:
+                intent = ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT;
+                break;
+            default:
+                ALOGV("%s: unsupported RequestTemplate type %d", __FUNCTION__, type);
+                continue;
+        }
+        UPDATE(mdCopy, ANDROID_CONTROL_CAPTURE_INTENT, &intent, 1);
+
+        camera_metadata_t* rawMd = mdCopy.release();
+        CameraMetadata hidlMd;
+        hidlMd.setToExternal(
+                (uint8_t*) rawMd, get_camera_metadata_size(rawMd));
+        mDefaultRequests[type] = hidlMd;
+        free_camera_metadata(rawMd);
+    }
+
+    return OK;
+}
+
+status_t VirtualCameraDeviceSession::fillCaptureResult(
+        common::V1_0::helper::CameraMetadata &md, nsecs_t timestamp) {
+    bool afTrigger = false;
+    {
+        std::lock_guard<std::mutex> lk(mAfTriggerLock);
+        afTrigger = mAfTrigger;
+        if (md.exists(ANDROID_CONTROL_AF_TRIGGER)) {
+            camera_metadata_entry entry = md.find(ANDROID_CONTROL_AF_TRIGGER);
+            if (entry.data.u8[0] == ANDROID_CONTROL_AF_TRIGGER_START) {
+                mAfTrigger = afTrigger = true;
+            } else if (entry.data.u8[0] == ANDROID_CONTROL_AF_TRIGGER_CANCEL) {
+                mAfTrigger = afTrigger = false;
+            }
+        }
+    }
+
+    // For USB camera, the USB camera handles everything and we don't have control
+    // over AF. We only simply fake the AF metadata based on the request
+    // received here.
+    uint8_t afState;
+    if (afTrigger) {
+        afState = ANDROID_CONTROL_AF_STATE_FOCUSED_LOCKED;
+    } else {
+        afState = ANDROID_CONTROL_AF_STATE_INACTIVE;
+    }
+    UPDATE(md, ANDROID_CONTROL_AF_STATE, &afState, 1);
+
+    camera_metadata_ro_entry activeArraySize =
+            mCameraCharacteristics.find(ANDROID_SENSOR_INFO_ACTIVE_ARRAY_SIZE);
+
+    return fillCaptureResultCommon(md, timestamp, activeArraySize);
+}
+
+#undef ARRAY_SIZE
+#undef UPDATE
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
diff --git a/camera/device/3.4/default/Virtual/VirtualCameraManager.cpp b/camera/device/3.4/default/Virtual/VirtualCameraManager.cpp
new file mode 100644
index 000000000..93a190461
--- /dev/null
+++ b/camera/device/3.4/default/Virtual/VirtualCameraManager.cpp
@@ -0,0 +1,128 @@
+#include "VirtualCameraManager.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+VirtualCameraManager *VirtualCameraManager::mInstance = nullptr;
+int VirtualCameraManager::mRefcount = 0;
+
+int VirtualCameraManager::initialize()
+{
+    if (mInitialized == true) {
+        ALOGI("%s: VirtualCameraManager has already been initialized.", __FUNCTION__);
+        return 0;
+    }
+
+    for (int i = 0; i < MAX_VIRTUAL_CAMERA_COUNT; i++) {
+        std::string vid = std::to_string(i+VIRTUAL_CAMERA_ID_OFFSET);
+        ALOGD("%s: create virtual device with cameraId %s", __FUNCTION__, vid.c_str());
+        sp<VirtualCameraDevice> pdev = new VirtualCameraDevice(vid);
+        if (pdev == nullptr) {
+            ALOGE("%s: Memory error: Cannot create a device object.", __FUNCTION__);
+            return -1;
+        }
+        mVirtualDevices[vid] = pdev;
+    }
+    mInitialized = true;
+    return mVirtualDevices.size();
+}
+
+int VirtualCameraManager::getVirtCamIDs(std::vector<std::string>& ids)
+{
+    Mutex::Autolock _l(mLock);
+    for (const auto& pair: mVirtualDevices) {
+        if (pair.second->getStatus() != INVALID )
+        ids.push_back(pair.first);
+    }
+
+    return ids.size();
+}
+
+sp<VirtualCameraDevice> VirtualCameraManager::getVirtCamByID(const std::string& virtualDeviceId)
+{
+    Mutex::Autolock _l(mLock);
+    auto iter = mVirtualDevices.find(virtualDeviceId);
+    if (iter == mVirtualDevices.end()) {
+        ALOGE("%s: cannot find the virtual device by id %s", __FUNCTION__, virtualDeviceId.c_str());
+        return nullptr;
+    }
+
+    return mVirtualDevices[virtualDeviceId];
+}
+
+sp<VirtualCameraDevice> VirtualCameraManager::getFirstVirtCam()
+{
+    sp<VirtualCameraDevice> ret = nullptr;
+    Mutex::Autolock _l(mLock);
+    std::map<std::string, sp<VirtualCameraDevice>>::iterator iter = mVirtualDevices.begin();
+    if (iter != mVirtualDevices.end()) {
+        ret = iter->second;
+    }
+    return ret;
+}
+
+sp<VirtualCameraDevice> VirtualCameraManager::allocVirtCam()
+{
+    sp<VirtualCameraDevice> dev = nullptr;
+    Mutex::Autolock _l(mLock);
+    for (const auto& pair : mVirtualDevices) {
+        if (pair.second->getStatus() == INVALID) {
+            dev = pair.second;
+            dev->setStatus(FREE);
+            break;
+        }
+    }
+    return dev;
+}
+
+int VirtualCameraManager::freeVirtCam(sp<VirtualCameraDevice> dev)
+{
+    Mutex::Autolock _l(mLock);
+    auto iter = mVirtualDevices.find(dev->getCameraId());
+    if (iter == mVirtualDevices.end()) {
+        ALOGE("%s: cannot find the virtual device by id %s", __FUNCTION__, dev->getCameraId().c_str());
+        return -1;
+    }
+
+    dev->setStatus(FREE);
+    dev->releaseV4L2CameraDevice();
+
+    return 0;
+}
+
+int VirtualCameraManager::createVirtualLoopback(const std::string& id)
+{
+    mVirtualLoopback = new VirtualCameraDevice(id);
+    if (mVirtualLoopback == nullptr) {
+        ALOGE("%s: failed to create virtual camera for loopback.", __FUNCTION__);
+        return -1;
+    }
+    return 0;
+}
+
+sp<VirtualCameraDevice> VirtualCameraManager::getVirtualLoopback()
+{
+    return mVirtualLoopback;
+}
+
+void VirtualCameraManager::dumpAllVirtualCameras() {
+    Mutex::Autolock _l(mLock);
+    ALOGI("%s dumps: refcount=%d, initialized=%d", __FUNCTION__, mRefcount, (int)mInitialized);
+    ALOGI("Virtual devices:");
+    for (auto iter : mVirtualDevices) {
+        ALOGI("CameraId = %s", iter.first.c_str());
+    }
+
+    return;
+}
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
diff --git a/camera/device/3.4/default/include/ext_device_v3_4_impl/ExternalCameraUtils.h b/camera/device/3.4/default/include/ext_device_v3_4_impl/ExternalCameraUtils.h
index b354406a5..d0a976c64 100644
--- a/camera/device/3.4/default/include/ext_device_v3_4_impl/ExternalCameraUtils.h
+++ b/camera/device/3.4/default/include/ext_device_v3_4_impl/ExternalCameraUtils.h
@@ -65,6 +65,7 @@ struct SizeHasher {
 };
 
 struct ExternalCameraConfig {
+    ExternalCameraConfig();
     static const char* kDefaultCfgPath;
     static ExternalCameraConfig loadFromCfg(const char* cfgPath = kDefaultCfgPath);
 
@@ -103,7 +104,6 @@ struct ExternalCameraConfig {
     int32_t orientation;
 
 private:
-    ExternalCameraConfig();
     static bool updateFpsList(tinyxml2::XMLElement* fpsList, std::vector<FpsLimitation>& fpsLimits);
 };
 
@@ -152,6 +152,7 @@ public:
     const int mBufferIndex; // for later enqueue
     int map(uint8_t** data, size_t* dataSize);
     int unmap();
+    int setMapData(uint8_t* data);
 private:
     std::mutex mLock;
     const int mFd; // used for mmap but doesn't claim ownership
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/CaptureManager.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/CaptureManager.h
new file mode 100644
index 000000000..32aa05fb9
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/CaptureManager.h
@@ -0,0 +1,123 @@
+#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_CAPTUREMANAGER_H
+#define ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_CAPTUREMANAGER_H
+
+#include <map>
+#include <vector>
+#include <string>
+
+#include "VirtualCameraDevice.h"
+#include "VirtualCameraManager.h"
+#include "V4L2CameraDevice.h"
+#include "LoopbackListener.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+using ::android::hardware::camera::common::V1_0::Status;
+using ::android::hardware::camera::common::V1_0::CameraDeviceStatus;
+
+using ::android::Mutex;
+using ::android::sp;
+
+struct DeviceMapper {
+    sp<V4L2CameraDevice> mV4L2Device;
+    std::map<std::string, sp<VirtualCameraDevice>> mVirtualDevices;
+};
+
+/*
+ * CaptureManager binds virtual cameras and v4l2 camera in initialization.
+ * No other ops 
+ */
+class CaptureManager : public virtual RefBase {
+public:
+    static CaptureManager *getInstance() {
+        if (mInstance == nullptr) {
+            mInstance = new CaptureManager();
+            mRefcount = 1;
+            mVirtManager = VirtualCameraManager::getInstance();
+            if (mVirtManager == nullptr) {
+                ALOGE("%s Fatal error: failed to alloc virtual manager.", __FUNCTION__);
+                delete mInstance;
+                return nullptr;
+            }
+        }
+        mRefcount++;
+        return mInstance;
+    }
+
+    virtual ~CaptureManager() {
+        Mutex::Autolock _l(mLock);
+        if (mRefcount == 1) {
+            delete mVirtManager;
+            mVirtManager = nullptr;
+            delete mInstance;
+            mInstance = nullptr;
+        }
+        mRefcount --;
+    }
+
+    int initialize();
+    
+    //For provider to fetch interface.
+    sp<VirtualCameraDevice> getFirstVirtualDevice() {
+        return mVirtManager->getFirstVirtCam();
+    }
+    
+    int getAllV4L2CameraIds(std::vector<std::string>& ids);
+    int getAllVirtualCameraIds(std::vector<std::string>& ids);
+
+    int getVirtualLoopbackId(std::string& id);
+
+    std::unordered_map<std::string, CameraDeviceStatus> mCameraStatusMap; // camera id -> status
+    // Get v4l2cameradevice by v4l2 cameraId
+    sp<V4L2CameraDevice> getV4L2Camera(const std::string& id);
+    // Get v4l2cameradevice by virutal cameraId
+    sp<V4L2CameraDevice> getV4L2CameraByVirtID(const std::string& id);
+    // HAL should call this interface to alloc virtual camera which bind to the physical camera.
+    sp<VirtualCameraDevice> getVirtualCamera(const std::string& vid);
+
+    // get virtual camera
+    // sp<VirtualCameraDevice> getVirtualCamera(const std::string& id);
+    // int setupVirtualLoopback(const std::string& virtcamId, sp<V4L2CameraDevice> v4l2Dev);
+
+    // Interfaces for virtual camera calling.
+    int openRequest(const std::string& vcameraId);
+    int closeRequest(const std::string& vcameraId);
+    int configureRequest(const std::string& vcameraId);
+    int streamonRequest(const std::string& vcameraId);
+    int streamoffRequest(const std::string& vcameraId);
+    int enqueueRequest(const std::string& vcameraId, sp<FrameBuffer> buf);
+    int dequeueRequest(sp<FrameBuffer> buf);
+    void printMyself();
+
+private:
+    CaptureManager() {
+        mRefcount = 0;
+        mInitialized = false;
+        mInstance = nullptr;
+        mVirtManager = nullptr;
+        mLicCamAgent = nullptr;
+    }
+
+    Mutex mLock;
+    static CaptureManager *mInstance;
+    static VirtualCameraManager *mVirtManager;
+    LicCamAgent *mLicCamAgent;
+    std::map<std::string, DeviceMapper> mMappers;
+    DeviceMapper mVirtualLoopMapper;
+    static int mRefcount;
+    bool mInitialized;
+}; //class CaptureManager
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
+
+#endif //ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_CAPTUREMANAGER_H
\ No newline at end of file
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/IVICameraUtils.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/IVICameraUtils.h
new file mode 100644
index 000000000..822988a2c
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/IVICameraUtils.h
@@ -0,0 +1,21 @@
+#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_IVICAMUTILS_H
+#define ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_IVICAMUTILS_H
+
+#include <android/hardware/camera/common/1.0/types.h>
+#include <android/hardware/camera/device/3.2/types.h>
+#include <android/hardware/graphics/common/1.0/types.h>
+#include <android/hardware/graphics/mapper/2.0/IMapper.h>
+#include <inttypes.h>
+#include <mutex>
+#include <unordered_map>
+#include <unordered_set>
+#include <vector>
+#include "tinyxml2.h"  // XML parsing
+#include "utils/LightRefBase.h"
+#include "utils/Timers.h"
+#include <CameraMetadata.h>
+#include <HandleImporter.h>
+
+#include "../ext_device_v3_4_impl/ExternalCameraUtils.h"
+
+#endif
\ No newline at end of file
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/LoopbackListener.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/LoopbackListener.h
new file mode 100644
index 000000000..caaf999fb
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/LoopbackListener.h
@@ -0,0 +1,181 @@
+#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_LOOPBACKLISTENER_H
+#define ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_LOOPBACKLISTENER_H
+
+#include <string>
+
+#include "utils/RefBase.h"
+#include "utils/Mutex.h"
+#include "utils/Thread.h"
+
+#include "NetlinkUtil.h"
+#include "VirtualCameraDevice.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+using ::android::sp;
+using ::android::Mutex;
+using ::android::Thread;
+
+// const std::string kSysVideo4Linux = "/sys/class/video4linux/";
+
+struct LoopbackDevice {
+public:
+    std::string mDeviceName;
+    std::string mCardName;
+    std::string mDriver;
+    int mRefcount;
+    bool mStreaming;
+    int mFd;
+
+    LoopbackDevice() {
+        mDeviceName = "";
+        mCardName = "";
+        mDriver = "";
+        mRefcount = 0;
+        mStreaming = false;
+        mFd = -1;
+    }
+
+    virtual ~LoopbackDevice() {
+        if (mFd > 0) {
+            close(mFd);
+        }
+        mRefcount = 0;
+        mFd = -1;
+    }
+    static bool isLoopbackDevice(const std::string& node);
+
+    int openLoopback(const std::string& node);
+    int closeLoopback();
+    int configureLoopback(int width, int height, uint32_t pixelFormat);
+    int writeStream(uint8_t* data, int32_t dataSize);
+};
+
+typedef enum {
+    DEV_BUSY = -100,
+    DEV_ERR,
+    DEV_IGN,
+
+    DEV_OPEN_SUCC = 0,
+    DEV_CLOSE_SUCC,
+} DeviceStatus;
+
+class LoopbackListener : public android::RefBase {
+public:
+    static LoopbackListener *getInstance() {
+        if (mInstance == nullptr) {
+            mInstance = new LoopbackListener();
+            mRefcount = 1;
+        }
+        mRefcount++;
+        return mInstance;
+    }
+
+    ~LoopbackListener() {
+        mRefcount--;
+        ALOGI("%s: delete LoopbackListener", __FUNCTION__);
+        if (mRefcount == 0) {
+            mLoopbackDevice.closeLoopback();
+            delete mInstance;
+            mInstance = nullptr;
+        }
+    }
+
+    // int initialize(const std::string& id, const std::string& loopbackPath);
+    int initialize(sp<VirtualCameraDevice> vcam, const std::string& loopbackPath);
+
+    //Request from v4l2loopback; response to v4l2loopback.
+    DeviceStatus handleRequest(const std::string &request, std::string &response);
+protected:
+    class StreamThread : public android::Thread {
+    public:
+        sp<LoopbackListener> mParent;
+        StreamThread(sp<LoopbackListener> l) {
+            mParent = l;
+            mStopRequest = false;
+            mStarted = false;
+        }
+        virtual ~StreamThread() {}
+        bool threadLoop();
+        int stop();
+
+        //This method is called in listener to wait for streamer starts to
+        //write image into loopback device.
+        int notifyStartComplete();
+        int waitStartComplete();
+
+        //Stop the thread gracefully.
+        std::mutex mStopMutex;
+        std::condition_variable mStopCondition;
+        bool mStopRequest;
+        //Start the streaming sync.
+        std::mutex mStartMutex;
+        std::condition_variable mStartCondition;
+        bool mStarted;
+    };
+
+private:
+    int checkLoopbackDevice(const std::string& node);
+
+    LoopbackListener() {
+        mRefcount = 0;
+        mInitialized = false;
+        mInstance = nullptr;
+    }
+
+    static LoopbackListener *mInstance;
+    static int mRefcount;
+    bool mInitialized;
+
+    //Bind to one dedicate virtual camera.
+    sp<VirtualCameraDevice> mVirtualCameraDevice;
+    LoopbackDevice mLoopbackDevice;
+    std::string mLoopbackPath;
+    sp<StreamThread> mStreamer;
+};
+
+class LicCamAgent : public android::RefBase {
+public:
+    LicCamAgent() {
+        mListener = nullptr;
+    }
+    virtual ~LicCamAgent() {
+        mListener = nullptr;
+        mNetlink.closeNetlink();
+    }
+
+    int initialize(sp<VirtualCameraDevice> vcam, const std::string& loopbackPath);
+
+    class AgentThread: public android::Thread{
+    public:
+        sp<LicCamAgent> mParent;
+        AgentThread(sp<LicCamAgent> agent) {
+            mParent = agent;
+        }
+        virtual ~AgentThread() {}
+        bool threadLoop();
+        int stop();
+    private:
+        std::mutex mStopMutex;
+        std::condition_variable mStopCondition;
+        bool mStopRequest;
+    };
+private:
+    NetlinkUtil mNetlink;
+    sp<LoopbackListener> mListener;
+    sp<AgentThread> mAgent;
+};
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
+
+#endif //ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_LOOPBACKLISTENER_H
\ No newline at end of file
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/MediaControl.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/MediaControl.h
new file mode 100644
index 000000000..1b7955665
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/MediaControl.h
@@ -0,0 +1,249 @@
+/*
+ * Copyright (C) 2015-2021 Intel Corporation.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <errno.h>
+#include <fcntl.h>
+#include <linux/media.h>
+#include "v4l2-subdev.h"
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <sys/ioctl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+
+#include <string>
+#include <vector>
+#include <mutex>
+#include <map>
+#include <utils/Log.h>
+#include "NodeInfo.h"
+
+#define VIDEO_PLANES 1
+#define BUFFER_COUNT 3
+#define WIDTH 1920
+#define HEIGHT 1080
+
+struct MediaEntity;
+struct MediaPad;
+struct MediaLink;
+
+#define MEDIA_CTL_DEV_NAME "/dev/media"
+#define MEDIA_DRIVER_NAME "intel-ipu"
+#define MEDIA_DEVICE_MAX_NUM 256
+
+enum {
+    FC_FORMAT = 0,
+    FC_SELECTION = 1,
+};
+
+enum ResolutionType {
+    RESOLUTION_MAX = 0,
+    RESOLUTION_COMPOSE,
+    RESOLUTION_CROP,
+    RESOLUTION_TARGET,
+
+};
+
+struct McFormat {
+    int entity;
+    int pad;
+    int stream;
+    int formatType;
+    int selCmd;
+    int top;
+    int left;
+    int width;
+    int height;
+    enum ResolutionType type;
+    std::string entityName;
+    unsigned int pixelCode;
+};
+
+struct McOutput {
+    int port;
+    unsigned int v4l2Format;
+    int width;
+    int height;
+    McOutput() {
+        port = -1;
+        v4l2Format = 0;
+        width = 0;
+        height = 0;
+    }
+};
+
+struct McCtl {
+    int entity;
+    int ctlCmd;
+    int ctlValue;
+    std::string ctlName;
+    std::string entityName;
+    McCtl() {
+        entity = 0;
+        ctlCmd = 0;
+        ctlValue = 0;
+    }
+};
+
+struct McLink {
+    int srcEntity;
+    int srcPad;
+    int sinkEntity;
+    int sinkPad;
+    bool enable;
+    std::string srcEntityName;
+    std::string sinkEntityName;
+};
+
+struct McRoute {
+    int entity;
+    uint32_t sinkPad;
+    uint32_t sinkStream;
+    uint32_t srcPad;
+    uint32_t srcStream;
+    uint32_t flag;
+    std::string entityName;
+    McRoute() {
+        entity = 0;
+        sinkPad = 0;
+        srcPad = 0;
+        sinkStream = 0;
+        srcStream = 0;
+        flag = 0;
+        entityName.clear();
+    }
+};
+
+struct McVideoNode {
+    std::string name;
+    VideoNodeType videoNodeType;
+    McVideoNode() { videoNodeType = VIDEO_GENERIC; }
+};
+
+struct MediaCtlConf {
+    std::vector<McCtl> ctls;
+    std::vector<McLink> links;
+    std::vector<McRoute> routes;
+    std::vector<McFormat> formats;
+    std::vector<McOutput> outputs;
+    std::vector<McVideoNode> videoNodes;
+    int mcId;
+    int outputWidth;
+    int outputHeight;
+    int format;
+    /*
+     * The outputWidth or outputHeight is 0 if there isn't this setting
+     * in MediaCtlConf. It means the isys output size is dynamic, and
+     * we don't use stream size to select MC.
+     */
+    MediaCtlConf() {
+        mcId = -1;
+        outputWidth = 0;
+        outputHeight = 0;
+        format = -1;
+    }
+};
+
+/**
+ * \class MediaController
+ *
+ * This class is used for discovering and configuring the internal topology
+ * of a media device. Devices are modelled as an oriented graph of building
+ * blocks called media entities. The media entities are connected to each other
+ * through pads.
+ *
+ * Each media entity corresponds to a V4L2 subdevice. This class is also used
+ * for configuring the V4L2 subdevices.
+ */
+
+class MediaControl {
+ public:
+    /**
+     * \brief Get the singleton instance of MediaControl
+     */
+    static MediaControl* getInstance();
+
+    /**
+     * \brief Release the singleton instance of MediaControl.
+     */
+    static void releaseInstance();
+
+    /**
+     * \brief Enum entities and link, and reset all links
+     *
+     * \return 0 if succeed, other value indicates failed
+     */
+    int initEntities();
+
+    /**
+     * \brief Free all entities and links memory
+     */
+    void clearEntities();
+
+    /**
+     * \brief Get the entity by name
+     *
+     * \return entity id if succeed or -1 if error
+     */
+    int getEntityIdByName(const char* name);
+
+    int resetAllLinks();
+    // VIRTUAL_CHANNEL_S
+    int resetAllRoutes();
+    // VIRTUAL_CHANNEL_E
+    int createLink();
+
+ private:
+    MediaControl& operator=(const MediaControl&);
+    MediaControl(const char* devName);
+    ~MediaControl();
+
+    static MediaControl* getMediaControlInstance();
+    int openDevice();
+    void closeDevice(int fd);
+    void getDeviceName(const char* entityName, std::string& deviceNodeName, bool isSubDev);
+    int SetRouting(int fd, v4l2_subdev_route* routes, uint32_t numRoutes);
+    int GetRouting(int fd, v4l2_subdev_route* routes, uint32_t* numRoutes);
+
+    // enum MediaControl info.
+    int enumInfo();
+    int enumLinks(int fd);
+    int enumEntities(int fd);
+
+    // get entity info.
+    int getDevnameFromSysfs(MediaEntity* entity);
+    MediaEntity* getEntityById(uint32_t id);
+    MediaEntity* getEntityByName(const char* name);
+
+    // set up entity link.
+
+    MediaLink* entityAddLink(MediaEntity* entity);
+    int setupLink(uint32_t srcEntity, uint32_t srcPad, uint32_t sinkEntity, uint32_t sinkPad,
+                  bool enable);
+    int setupLink(MediaPad* source, MediaPad* sink, uint32_t flags);
+
+    int SetFormat(int fd, const struct v4l2_subdev_format& format);
+    int setSelection(int cameraId, const McFormat* format, int targetWidth, int targetHeight);
+
+    std::string mDevName;
+    std::vector<MediaEntity> mEntities;
+
+    static MediaControl* sInstance;
+    static std::mutex sLock;
+};
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/NetlinkUtil.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/NetlinkUtil.h
new file mode 100644
index 000000000..70ca37989
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/NetlinkUtil.h
@@ -0,0 +1,56 @@
+#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_NETLINKUTIL_H
+#define ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_NETLINKUTIL_H
+
+#include <string>
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+#define NETLINK_GRP 22
+#define NETLINK_BUFFER_SIZE 1024
+
+class NetlinkUtil {
+public:
+    NetlinkUtil() {
+        mSock = -1;
+    }
+    ~NetlinkUtil() {}
+    int openNetlink();
+    int closeNetlink();
+    int receiveRequest(std::string& request);
+    int sendResponse(const std::string& response);
+private:
+    int mSock;
+};
+
+class NetlinkRequest {
+public:
+    std::string mRequest;
+    //loopback cardName and deviceName
+    std::string mCardName;
+    // std::string mDeviceName;
+    //Ignore loopback listener output accessing.
+    std::string mProcessName;
+    int mProcessId;
+
+    NetlinkRequest() {}
+    ~NetlinkRequest() {}
+
+    int parse(const std::string &request);
+
+private:
+    int split(const std::string &request, char token, std::vector<std::string> &segments);
+};
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
+
+#endif //ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_NETLINKUTIL_H
\ No newline at end of file
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/NodeInfo.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/NodeInfo.h
new file mode 100644
index 000000000..8e8401266
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/NodeInfo.h
@@ -0,0 +1,51 @@
+/*
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+
+enum VideoNodeType {
+    // video node device
+    VIDEO_GENERIC,
+    VIDEO_GENERIC_MEDIUM_EXPO,
+    VIDEO_GENERIC_SHORT_EXPO,
+    // CSI_META_S
+    VIDEO_CSI_META,
+    // CSI_META_E
+
+    // sensor subdevice
+    VIDEO_PIXEL_ARRAY,
+    VIDEO_PIXEL_BINNER,
+    VIDEO_PIXEL_SCALER,
+
+    // ISP subdevice
+    VIDEO_ISYS_RECEIVER,
+    VIDEO_ISYS_RECEIVER_BACKEND,
+};
+
+struct VideoNodeInfo {
+    VideoNodeType type;
+    const char* fullName;
+    const char* shortName;
+};
+
+enum EncodeBufferType {
+    ENCODE_ISA_CONFIG = 0,
+    ENCODE_STATS = 1,
+};
+
+extern const VideoNodeInfo gVideoNodeInfos[];
+extern const char* GetNodeName(VideoNodeType nodeType);
+extern VideoNodeType GetNodeType(const char* nodeName);
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/SysCall.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/SysCall.h
new file mode 100644
index 000000000..116a635fa
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/SysCall.h
@@ -0,0 +1,81 @@
+/*
+ * Copyright (C) 2015-2021 Intel Corporation.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+
+#include <errno.h>
+#include <fcntl.h>
+#include <linux/media.h>
+#include <linux/v4l2-subdev.h>
+#include <linux/videodev2.h>
+#include <poll.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <mutex>
+
+class SysCall {
+ protected:
+    SysCall();
+    virtual ~SysCall();
+
+ public:
+    virtual int open(const char* pathname, int flags);
+    virtual int close(int fd);
+    virtual void* mmap(void* addr, size_t len, int prot, int flag, int filedes, off_t off);
+    virtual int munmap(void* addr, size_t len);
+
+    virtual int ioctl(int fd, int request, struct media_device_info* arg);
+    virtual int ioctl(int fd, int request, struct media_link_desc* arg);
+    virtual int ioctl(int fd, int request, struct media_links_enum* arg);
+    virtual int ioctl(int fd, int request, struct media_links_desc* arg);
+    virtual int ioctl(int fd, int request, struct media_entity_desc* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_capability* arg);
+    virtual int ioctl(int fd, int request, v4l2_fmtdesc* arg);
+    virtual int ioctl(int fd, int request, enum v4l2_buf_type* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_format* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_requestbuffers* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_buffers* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_buffer* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_subdev_format* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_subdev_stream* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_streamon_info* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_ext_controls* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_control* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_queryctrl* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_subdev_selection* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_subdev_routing* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_querymenu* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_event_subscription* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_event* arg);
+    virtual int ioctl(int fd, int request, struct v4l2_exportbuffer* arg);
+
+    virtual int poll(struct pollfd* pfd, nfds_t nfds, int timeout);
+
+    static SysCall* getInstance();
+    static void updateInstance(SysCall* newSysCall);
+
+ private:
+    int ioctl(int fd, int request, void* arg);
+
+    SysCall& operator=(const SysCall&);  // Don't call me
+
+    static bool sIsInitialized;
+    static SysCall* sInstance;
+    static std::mutex sLock;
+};
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/V4L2CameraDevice.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/V4L2CameraDevice.h
new file mode 100644
index 000000000..5344fe655
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/V4L2CameraDevice.h
@@ -0,0 +1,164 @@
+#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_V4L2CAMERADEVICE_H
+#define ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_V4L2CAMERADEVICE_H
+
+#include <map>
+
+#include "utils/RefBase.h"
+#include "utils/Mutex.h"
+#include "utils/Thread.h"
+#include <sys/mman.h>
+#include <linux/videodev2.h>
+#include <inttypes.h>
+#include "android-base/macros.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+using ::android::sp;
+using namespace ::android::hardware::camera::device;
+using ::android::Mutex;
+using ::android::Thread;
+
+#define RING_BUFFER_SIZE 2
+#define REQUEST_BUFFER_COUNT 2
+
+struct FrameBuffer : public android::RefBase {
+public:
+    FrameBuffer() : mWidth(1920), mHeight(1080), mFourcc(0) {}
+    FrameBuffer(uint32_t width, uint32_t height, uint32_t fourcc);
+    uint32_t mWidth;
+    uint32_t mHeight;
+    uint32_t mFourcc;
+    uint8_t *mData;
+    uint32_t mDataSize;
+    // // getData might involve map/allocation
+    // virtual int getData(uint8_t** outData, size_t* dataSize) = 0;
+    std::mutex mReadyMutex;
+    std::condition_variable mReadyCondition;
+    bool mReady; //Ready forread.
+};
+
+class V4L2CameraDevice : public virtual RefBase {
+public:
+    V4L2CameraDevice(const std::string& mDevicePath);
+    virtual ~V4L2CameraDevice();
+
+    // Interfaces for virtual camera calling.
+    // int openRequest(const std::string& vcameraId);
+    // int closeRequest(const std::string& vcameraId);
+    // int configureRequest(const std::string& vcameraId);
+    // int streamonRequest(const std::string& vcameraId);
+    // int streamoffRequest(const std::string& vcameraId);
+    int registerFrameBuffer(const std::string& vcameraId, sp<FrameBuffer> buf) {
+        Mutex::Autolock _l(mLock);
+        mVirtualBuffers[vcameraId] = buf;
+        return 0;
+    }
+
+    bool isValidCaptureDevice() {
+        // Mutex::Autolock _l(mLock);
+        return (mBufferType == V4L2_BUF_TYPE_VIDEO_OUTPUT) ? false : true;
+    }
+
+    v4l2_buf_type getBufferType() {
+        // Mutex::Autolock _l(mLock);
+        return mBufferType;
+    }
+
+    int getConfiguration(v4l2_format& fmt) {
+        // Mutex::Autolock _l(mLock);
+        fmt = mFormat;
+        // fmt.fmt.pix.width = mFormat.width;
+        // fmt.fmt.pix.height = mFormat.height;
+        // fmt.fmt.pix.pixelformat = mFormat.fourcc;
+        // fmt.type = mBufferType;
+        return 0;
+    }
+
+    std::string& getCameraId() {
+        // Mutex::Autolock _l(mLock);
+        return mCameraId;
+    }
+
+    int getRefcount() {
+        // Mutex::Autolock _l(mLock);
+        return mRefcount;
+    }
+
+    int getFd() {
+        return mFd;
+    }
+
+    //Methods for really handles the physical camera.
+    int openDev();
+    int closeDev();
+    //configure the device by default: uyvy 1080p@30fps
+    int configureDev();
+    int configureDev(const v4l2_format& v4l2Fmt);
+    int streamOnDev();
+    int streamOffDev();
+    int dequeueFrame();
+    int enqueueFrame(int idx);
+
+protected:
+    bool isValidVirtualCamera(const std::string& vcameraId) {
+        // Mutex::Autolock _l(mLock);
+        auto it = mVirtualBuffers.find(vcameraId);
+        return (it == mVirtualBuffers.end()) ? false : true;
+        return true;
+    }
+
+    class StreamThread : public android::Thread {
+    public:
+        sp<V4L2CameraDevice> mParent;
+        StreamThread(sp<V4L2CameraDevice> p) {
+            mParent = p;
+        }
+        virtual ~StreamThread() {}
+
+        bool threadLoop();
+        int stop();
+
+        void reset() {
+            mStopRequest = false;
+        }
+
+    private:
+        //Stop the thread gracefully.
+        std::mutex mStopMutex;
+        std::condition_variable mStopCondition;
+        bool mStopRequest;
+    };
+
+private:
+    V4L2CameraDevice() {}
+    V4L2CameraDevice(const V4L2CameraDevice&) {}
+
+    Mutex mLock;
+    std::string mDevicePath;
+    std::string mCameraId;
+    int mFd;
+    v4l2_format mFormat;
+    FrameBuffer mRingBuffer[RING_BUFFER_SIZE];
+
+    v4l2_buf_type mBufferType;
+    uint32_t mRefcount;
+    bool mStreaming;
+
+    //each allocated virtual camera should register their mFrameBuffer here.
+    std::map<std::string, sp<FrameBuffer>> mVirtualBuffers;
+
+    sp<StreamThread> mPollingThread;
+}; //class V4L2CameraDevice
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
+#endif //#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_V4L2CAMERADEVICE_H
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraDevice.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraDevice.h
new file mode 100644
index 000000000..350998720
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraDevice.h
@@ -0,0 +1,291 @@
+
+#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTCAMERADEVICE_H
+#define ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTCAMERADEVICE_H
+
+#include "utils/Mutex.h"
+#include "CameraMetadata.h"
+#include "IVICameraUtils.h"
+#include "V4L2CameraDevice.h"
+#include "VirtualCameraDeviceSession.h"
+#include <android/hardware/camera/device/3.2/ICameraDevice.h>
+#include <hidl/Status.h>
+#include <hidl/MQDescriptor.h>
+
+#include <vector>
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+using namespace ::android::hardware::camera::device;
+using ::android::hardware::camera::device::V3_2::ICameraDevice;
+using ::android::hardware::camera::device::V3_2::ICameraDeviceCallback;
+using ::android::hardware::camera::common::V1_0::CameraResourceCost;
+using ::android::hardware::camera::common::V1_0::TorchMode;
+using ::android::hardware::camera::common::V1_0::Status;
+
+// using ::android::hardware::camera::IVICamera::common::ExternalCameraConfig;
+// using ::android::hardware::camera::IVICamera::common::Size;
+using ::android::hardware::camera::external::common::ExternalCameraConfig;
+using ::android::hardware::camera::external::common::Size;
+
+using ::android::hardware::Return;
+using ::android::hardware::Void;
+using ::android::hardware::hidl_vec;
+using ::android::hardware::hidl_string;
+using ::android::sp;
+
+class CaptureManager;
+
+typedef enum {
+    INVALID = -1,
+    FREE = 0,
+    USED,
+} VirtualCameraStatus;
+
+struct VirtualCameraDevice : public virtual RefBase {
+    // Called by ivi camera provider HAL.
+    // Provider HAL must ensure the uniqueness of CameraDevice object per cameraId, or there could
+    // be multiple CameraDevice trying to access the same physical camera.  Also, provider will have
+    // to keep track of all CameraDevice objects in order to notify CameraDevice when the underlying
+    // camera is detached.
+    //VirtualCameraDevice(const std::string& cameraId, const ExternalCameraConfig& cfg);
+    //Neo: CameraId is assigned by VirtualCameraManager
+    VirtualCameraDevice(const std::string& cameraId);
+    virtual ~VirtualCameraDevice();
+
+    // Retrieve the HIDL interface, split into its own class to avoid inheritance issues when
+    // dealing with minor version revs and simultaneous implementation and interface inheritance
+    virtual sp<ICameraDevice> getInterface() {
+        return new TrampolineDeviceInterface_3_4(this);
+    }
+
+    // Caller must use this method to check if CameraDevice connector failed
+    bool isInitFailed();
+    bool isInitFailedLocked();
+
+    /* Methods from ::android::hardware::camera::device::V3_2::ICameraDevice follow. */
+    // The following method can be called without opening the actual camera device
+    Return<void> getResourceCost(ICameraDevice::getResourceCost_cb _hidl_cb);
+
+    Return<void> getCameraCharacteristics(
+            ICameraDevice::getCameraCharacteristics_cb _hidl_cb);
+
+    //Not applicable.
+    Return<Status> setTorchMode(TorchMode) {
+         return Status::OPERATION_NOT_SUPPORTED;
+    }
+
+    // Open the device HAL and also return a default capture session
+    Return<void> open(const sp<ICameraDeviceCallback>&, ICameraDevice::open_cb);
+    int open();
+    virtual int close();
+    virtual int configureStream();
+    virtual int streamOff();
+    virtual int streamOn();
+    int dequeueFrame(sp<FrameBuffer> frame);
+    int enqueueFrame(sp<FrameBuffer> frame);
+
+    // Forward the dump call to the opened session, or do nothing
+    Return<void> dumpState(const ::android::hardware::hidl_handle&);
+    /* End of Methods from ::android::hardware::camera::device::V3_2::ICameraDevice */
+
+    void setCameraId(const std::string& id) {
+        mCameraId = id;
+    }
+
+    std::string& getCameraId() {
+        return mCameraId;
+    }
+
+    sp<FrameBuffer> getFrameBuffer() {
+        return mFrameBuffer;
+    }
+
+    void setStatus(VirtualCameraStatus status) {
+        mDeviceStatus = status;
+    }
+
+    VirtualCameraStatus getStatus() {
+        return mDeviceStatus;
+    }
+
+    // void bindV4L2CameraDevice(wp<V4L2CameraDevice> v4l2Device) {
+    //     mV4L2CameraDevice = v4l2Device;
+    // }
+
+    void releaseV4L2CameraDevice() {
+        mCaptureManager = nullptr;
+    }
+
+    CaptureManager* getCaptureManager() {
+        return mCaptureManager;
+    }
+protected:
+    // Overridden by child implementations for returning different versions of
+    // VirtualCameraDeviceSession
+    // Neo: remove cfg/croppingType and cfg if not necessary with the fixed data.
+    virtual sp<VirtualCameraDeviceSession> createSession(
+            const sp<ICameraDeviceCallback>&,
+            // const ExternalCameraConfig& cfg,
+            const std::vector<SupportedV4L2Format>& sortedFormats,
+            const CroppingType& croppingType,
+            const common::V1_0::helper::CameraMetadata& chars,
+            const std::string& cameraId);
+
+    // Init supported w/h/format/fps in mSupportedFormats.
+    // Do not need to own a fd, if required, pass the physical camera node fd to it.
+    void initSupportedFormatsLocked(int fd);
+
+    // Calls into virtual member function. Do not use it in constructor
+    status_t initCameraCharacteristics();
+    // Init available capabilities keys
+    virtual status_t initAvailableCapabilities(
+            ::android::hardware::camera::common::V1_0::helper::CameraMetadata*);
+    // Init non-device dependent keys
+    virtual status_t initDefaultCharsKeys(
+            ::android::hardware::camera::common::V1_0::helper::CameraMetadata*);
+    // Init camera control chars keys. Caller still owns fd
+    status_t initCameraControlsCharsKeys(
+            ::android::hardware::camera::common::V1_0::helper::CameraMetadata*);
+    // Init camera output configuration related keys.  Caller still owns fd
+    status_t initOutputCharsKeys(
+            ::android::hardware::camera::common::V1_0::helper::CameraMetadata*);
+
+    // Helper function for initOutputCharskeys
+    template <size_t SIZE>
+    status_t initOutputCharsKeysByFormat(
+            ::android::hardware::camera::common::V1_0::helper::CameraMetadata*,
+            uint32_t fourcc, const std::array<int, SIZE>& formats,
+            int scaler_stream_config_tag,
+            int stream_configuration, int min_frame_duration, int stall_duration);
+
+    bool calculateMinFps(::android::hardware::camera::common::V1_0::helper::CameraMetadata*);
+
+     static void getFrameRateList(int fd, double fpsUpperBound, SupportedV4L2Format* format);
+
+     static void updateFpsBounds(int fd, CroppingType cropType,
+             const std::vector<ExternalCameraConfig::FpsLimitation>& fpsLimits,
+             SupportedV4L2Format format,
+             std::vector<SupportedV4L2Format>& outFmts);
+
+    // Get candidate supported formats list of input cropping type.
+     static std::vector<SupportedV4L2Format> getCandidateSupportedFormatsLocked(
+             int fd, CroppingType cropType,
+             const std::vector<ExternalCameraConfig::FpsLimitation>& fpsLimits,
+             const std::vector<ExternalCameraConfig::FpsLimitation>& depthFpsLimits,
+             const Size& minStreamSize,
+             bool depthEnabled);
+    // Trim supported format list by the cropping type. Also sort output formats by width/height
+     static void trimSupportedFormats(CroppingType cropType,
+             /*inout*/std::vector<SupportedV4L2Format>* pFmts);
+
+    Mutex mLock;
+    bool mInitialized = false;
+    bool mInitFailed = false;
+    std::string mCameraId;
+    sp<FrameBuffer> mFrameBuffer;
+    
+    // Neo: Use the external camera config in the first stage.
+    ExternalCameraConfig mCfg;
+    // Neo: Only one fixed supporting formats in this vector, 1080p YUYV
+    std::vector<SupportedV4L2Format> mSupportedFormats;
+    // Neo: No need to implement cropping, remove it hope no defects.
+    CroppingType mCroppingType;
+
+    wp<VirtualCameraDeviceSession> mSession = nullptr;
+    CaptureManager* mCaptureManager = nullptr;
+
+    VirtualCameraStatus mDeviceStatus;
+
+protected:
+    ::android::hardware::camera::common::V1_0::helper::CameraMetadata mCameraCharacteristics;
+
+    const std::vector<int32_t> AVAILABLE_CHARACTERISTICS_KEYS_3_4 = {
+        ANDROID_COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES,
+        ANDROID_CONTROL_AE_AVAILABLE_ANTIBANDING_MODES,
+        ANDROID_CONTROL_AE_AVAILABLE_MODES,
+        ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES,
+        ANDROID_CONTROL_AE_COMPENSATION_RANGE,
+        ANDROID_CONTROL_AE_COMPENSATION_STEP,
+        ANDROID_CONTROL_AE_LOCK_AVAILABLE,
+        ANDROID_CONTROL_AF_AVAILABLE_MODES,
+        ANDROID_CONTROL_AVAILABLE_EFFECTS,
+        ANDROID_CONTROL_AVAILABLE_MODES,
+        ANDROID_CONTROL_AVAILABLE_SCENE_MODES,
+        ANDROID_CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES,
+        ANDROID_CONTROL_AWB_AVAILABLE_MODES,
+        ANDROID_CONTROL_AWB_LOCK_AVAILABLE,
+        ANDROID_CONTROL_MAX_REGIONS,
+        ANDROID_FLASH_INFO_AVAILABLE,
+        ANDROID_INFO_SUPPORTED_HARDWARE_LEVEL,
+        ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES,
+        ANDROID_LENS_FACING,
+        ANDROID_LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION,
+        ANDROID_LENS_INFO_FOCUS_DISTANCE_CALIBRATION,
+        ANDROID_NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES,
+        ANDROID_REQUEST_AVAILABLE_CAPABILITIES,
+        ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS,
+        ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS,
+        ANDROID_REQUEST_PARTIAL_RESULT_COUNT,
+        ANDROID_REQUEST_PIPELINE_MAX_DEPTH,
+        ANDROID_SCALER_AVAILABLE_MAX_DIGITAL_ZOOM,
+        ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+        ANDROID_SCALER_CROPPING_TYPE,
+        ANDROID_SENSOR_INFO_ACTIVE_ARRAY_SIZE,
+        ANDROID_SENSOR_INFO_MAX_FRAME_DURATION,
+        ANDROID_SENSOR_INFO_PIXEL_ARRAY_SIZE,
+        ANDROID_SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE,
+        ANDROID_SENSOR_INFO_TIMESTAMP_SOURCE,
+        ANDROID_SENSOR_ORIENTATION,
+        ANDROID_SHADING_AVAILABLE_MODES,
+        ANDROID_STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES,
+        ANDROID_STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES,
+        ANDROID_STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES,
+        ANDROID_STATISTICS_INFO_MAX_FACE_COUNT,
+        ANDROID_SYNC_MAX_LATENCY};
+
+private:
+    struct TrampolineDeviceInterface_3_4 : public ICameraDevice {
+        TrampolineDeviceInterface_3_4(sp<VirtualCameraDevice> parent) :
+            mParent(parent) {}
+
+        virtual Return<void> getResourceCost(V3_2::ICameraDevice::getResourceCost_cb _hidl_cb)
+                override {
+            return mParent->getResourceCost(_hidl_cb);
+        }
+
+        virtual Return<void> getCameraCharacteristics(
+                V3_2::ICameraDevice::getCameraCharacteristics_cb _hidl_cb) override {
+            return mParent->getCameraCharacteristics(_hidl_cb);
+        }
+
+        virtual Return<Status> setTorchMode(TorchMode mode) override {
+            return mParent->setTorchMode(mode);
+        }
+
+        virtual Return<void> open(const sp<V3_2::ICameraDeviceCallback>& callback,
+                V3_2::ICameraDevice::open_cb _hidl_cb) override {
+            return mParent->open(callback, _hidl_cb);
+        }
+
+        virtual Return<void> dumpState(const hidl_handle& fd) override {
+            return mParent->dumpState(fd);
+        }
+
+    private:
+        sp<VirtualCameraDevice> mParent;
+    };
+};
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
+
+#endif  // ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTCAMERADEVICE_H
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraDeviceSession.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraDeviceSession.h
new file mode 100644
index 000000000..84757c1c4
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraDeviceSession.h
@@ -0,0 +1,441 @@
+#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTUALCAMERADEVICESESSION_H
+#define ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTUALCAMERADEVICESESSION_H
+
+#include <android/hardware/camera/device/3.2/ICameraDevice.h>
+#include <android/hardware/camera/device/3.4/ICameraDeviceSession.h>
+#include <fmq/MessageQueue.h>
+#include <hidl/MQDescriptor.h>
+#include <hidl/Status.h>
+#include <include/convert.h>
+#include <chrono>
+#include <condition_variable>
+#include <list>
+#include <unordered_map>
+#include <unordered_set>
+#include "CameraMetadata.h"
+#include "HandleImporter.h"
+#include "Exif.h"
+#include "utils/KeyedVector.h"
+#include "utils/Mutex.h"
+#include "utils/Thread.h"
+#include "android-base/unique_fd.h"
+#include "IVICameraUtils.h"
+#include "V4L2CameraDevice.h"
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+using namespace ::android::hardware::camera::device;
+
+using ::android::hardware::camera::device::V3_2::BufferCache;
+using ::android::hardware::camera::device::V3_2::BufferStatus;
+using ::android::hardware::camera::device::V3_2::CameraMetadata;
+using ::android::hardware::camera::device::V3_2::CaptureRequest;
+using ::android::hardware::camera::device::V3_2::CaptureResult;
+using ::android::hardware::camera::device::V3_2::ErrorCode;
+using ::android::hardware::camera::device::V3_2::ICameraDeviceCallback;
+using ::android::hardware::camera::device::V3_2::MsgType;
+using ::android::hardware::camera::device::V3_2::NotifyMsg;
+using ::android::hardware::camera::device::V3_2::RequestTemplate;
+using ::android::hardware::camera::device::V3_2::Stream;
+using ::android::hardware::camera::device::V3_4::StreamConfiguration;
+using ::android::hardware::camera::device::V3_2::StreamConfigurationMode;
+using ::android::hardware::camera::device::V3_2::StreamRotation;
+using ::android::hardware::camera::device::V3_2::StreamType;
+using ::android::hardware::camera::device::V3_2::DataspaceFlags;
+using ::android::hardware::camera::device::V3_2::CameraBlob;
+using ::android::hardware::camera::device::V3_2::CameraBlobId;
+using ::android::hardware::camera::device::V3_4::HalStreamConfiguration;
+using ::android::hardware::camera::device::V3_4::ICameraDeviceSession;
+using ::android::hardware::camera::common::V1_0::Status;
+using ::android::hardware::camera::common::V1_0::helper::HandleImporter;
+using ::android::hardware::camera::common::V1_0::helper::ExifUtils;
+
+//Need to replace IVICamera
+using ::android::hardware::camera::external::common::ExternalCameraConfig;
+using ::android::hardware::camera::external::common::Size;
+using ::android::hardware::camera::external::common::SizeHasher;
+
+using ::android::hardware::graphics::common::V1_0::BufferUsage;
+using ::android::hardware::graphics::common::V1_0::Dataspace;
+using ::android::hardware::graphics::common::V1_0::PixelFormat;
+using ::android::hardware::kSynchronizedReadWrite;
+using ::android::hardware::MessageQueue;
+using ::android::hardware::MQDescriptorSync;
+using ::android::hardware::Return;
+using ::android::hardware::Void;
+using ::android::hardware::hidl_vec;
+using ::android::hardware::hidl_string;
+using ::android::sp;
+using ::android::Mutex;
+using ::android::base::unique_fd;
+
+class VirtualCameraManager;
+
+struct VirtualCameraDeviceSession : public virtual RefBase,
+        public virtual OutputThreadInterface {
+    VirtualCameraDeviceSession(const sp<ICameraDeviceCallback>&,
+            const std::vector<SupportedV4L2Format>& sortedFormats,
+            const CroppingType& croppingType,
+            const common::V1_0::helper::CameraMetadata& chars,
+            const std::string& cameraId);
+    virtual ~VirtualCameraDeviceSession();
+    // Call by CameraDevice to dump active device states
+    void dumpState(const native_handle_t*);
+    // Caller must use this method to check if CameraDeviceSession ctor failed
+    bool isInitFailed();
+    bool isClosed();
+
+    virtual sp<ICameraDeviceSession> getInterface() {
+        return new TrampolineSessionInterface_3_4(this);
+    }
+
+    static const int kMaxProcessedStream = 2;
+    static const int kMaxStallStream = 1;
+    static const uint32_t kMaxBytesPerPixel = 2;
+
+    class OutputThread : public android::Thread {
+    public:
+        OutputThread(wp<OutputThreadInterface> parent, CroppingType,
+                const common::V1_0::helper::CameraMetadata&);
+        virtual ~OutputThread();
+
+        Status allocateIntermediateBuffers(
+                const Size& v4lSize, const Size& thumbSize,
+                const hidl_vec<Stream>& streams,
+                uint32_t blobBufferSize);
+        Status submitRequest(const std::shared_ptr<HalRequest>&);
+        void flush();
+        void dump(int fd);
+        virtual bool threadLoop() override;
+        void setExifMakeModel(const std::string& make, const std::string& model);
+
+        // The remaining request list is returned for offline processing
+        std::list<std::shared_ptr<HalRequest>> switchToOffline();
+    protected:
+        // Methods to request output buffer in parallel
+        // No-op for device@3.4. Implemented in device@3.5
+        virtual int requestBufferStart(const std::vector<HalStreamBuffer>&) { return 0; }
+        virtual int waitForBufferRequestDone(
+                /*out*/std::vector<HalStreamBuffer>*) { return 0; }
+
+        static const int kFlushWaitTimeoutSec = 3; // 3 sec
+        static const int kReqWaitTimeoutMs = 33;   // 33ms
+        static const int kReqWaitTimesMax = 90;    // 33ms * 90 ~= 3 sec
+
+        void waitForNextRequest(std::shared_ptr<HalRequest>* out);
+        void signalRequestDone();
+
+        int cropAndScaleLocked(
+                sp<AllocatedFrame>& in, const Size& outSize,
+                YCbCrLayout* out);
+
+        int cropAndScaleThumbLocked(
+                sp<AllocatedFrame>& in, const Size& outSize,
+                YCbCrLayout* out);
+
+        int createJpegLocked(HalStreamBuffer &halBuf,
+                const common::V1_0::helper::CameraMetadata& settings);
+
+        void clearIntermediateBuffers();
+
+        const wp<OutputThreadInterface> mParent;
+        const CroppingType mCroppingType;
+        const common::V1_0::helper::CameraMetadata mCameraCharacteristics;
+
+        mutable std::mutex mRequestListLock;      // Protect acccess to mRequestList,
+                                                  // mProcessingRequest and mProcessingFrameNumer
+        std::condition_variable mRequestCond;     // signaled when a new request is submitted
+        std::condition_variable mRequestDoneCond; // signaled when a request is done processing
+        std::list<std::shared_ptr<HalRequest>> mRequestList;
+        bool mProcessingRequest = false;
+        uint32_t mProcessingFrameNumer = 0;
+
+        // V4L2 frameIn
+        // (MJPG decode)-> mYu12Frame
+        // (Scale)-> mScaledYu12Frames
+        // (Format convert) -> output gralloc frames
+        mutable std::mutex mBufferLock; // Protect access to intermediate buffers
+        sp<AllocatedFrame> mYu12Frame;
+        sp<AllocatedFrame> mYu12ThumbFrame;
+        std::unordered_map<Size, sp<AllocatedFrame>, SizeHasher> mIntermediateBuffers;
+        std::unordered_map<Size, sp<AllocatedFrame>, SizeHasher> mScaledYu12Frames;
+        YCbCrLayout mYu12FrameLayout;
+        YCbCrLayout mYu12ThumbFrameLayout;
+        uint32_t mBlobBufferSize = 0; // 0 -> HAL derive buffer size, else: use given size
+
+        std::string mExifMake;
+        std::string mExifModel;
+    };
+protected:
+
+    // Methods from ::android::hardware::camera::device::V3_2::ICameraDeviceSession follow
+
+    Return<void> constructDefaultRequestSettings(
+            RequestTemplate,
+            ICameraDeviceSession::constructDefaultRequestSettings_cb _hidl_cb);
+
+    Return<void> configureStreams(
+            const V3_2::StreamConfiguration&,
+            ICameraDeviceSession::configureStreams_cb);
+
+    Return<void> getCaptureRequestMetadataQueue(
+        ICameraDeviceSession::getCaptureRequestMetadataQueue_cb);
+
+    Return<void> getCaptureResultMetadataQueue(
+        ICameraDeviceSession::getCaptureResultMetadataQueue_cb);
+
+    Return<void> processCaptureRequest(
+            const hidl_vec<CaptureRequest>&,
+            const hidl_vec<BufferCache>&,
+            ICameraDeviceSession::processCaptureRequest_cb);
+
+    Return<Status> flush();
+    Return<void> close(bool callerIsDtor = false);
+
+    Return<void> configureStreams_3_3(
+            const V3_2::StreamConfiguration&,
+            ICameraDeviceSession::configureStreams_3_3_cb);
+
+    Return<void> configureStreams_3_4(
+            const V3_4::StreamConfiguration& requestedConfiguration,
+            ICameraDeviceSession::configureStreams_3_4_cb _hidl_cb);
+
+    Return<void> processCaptureRequest_3_4(
+            const hidl_vec<V3_4::CaptureRequest>& requests,
+            const hidl_vec<V3_2::BufferCache>& cachesToRemove,
+            ICameraDeviceSession::processCaptureRequest_3_4_cb _hidl_cb);
+
+protected:
+    // Methods from OutputThreadInterface
+    virtual Status importBuffer(int32_t streamId,
+            uint64_t bufId, buffer_handle_t buf,
+            /*out*/buffer_handle_t** outBufPtr,
+            bool allowEmptyBuf) override;
+
+    virtual Status processCaptureResult(std::shared_ptr<HalRequest>&) override;
+
+    virtual Status processCaptureRequestError(const std::shared_ptr<HalRequest>&,
+        /*out*/std::vector<NotifyMsg>* msgs = nullptr,
+        /*out*/std::vector<CaptureResult>* results = nullptr) override;
+
+    virtual ssize_t getJpegBufferSize(uint32_t width, uint32_t height) const override;
+
+    virtual void notifyError(uint32_t frameNumber, int32_t streamId, ErrorCode ec) override;
+    // End of OutputThreadInterface methods
+
+    Status constructDefaultRequestSettingsRaw(RequestTemplate type,
+            V3_2::CameraMetadata *outMetadata);
+
+    bool initialize();
+    // To init/close different version of output thread
+    virtual void initOutputThread();
+    virtual void closeOutputThread();
+    void closeOutputThreadImpl();
+
+    Status initStatus() const;
+    status_t initDefaultRequests();
+    status_t fillCaptureResult(common::V1_0::helper::CameraMetadata& md, nsecs_t timestamp);
+
+    Status configureStreams(const V3_2::StreamConfiguration&,
+            V3_3::HalStreamConfiguration* out,
+            // Only filled by configureStreams_3_4, and only one blob stream supported
+            uint32_t blobBufferSize = 0);
+    int configureV4l2StreamLocked(const SupportedV4L2Format& fmt, double fps = 0.0);
+
+    int v4l2StreamOffLocked();
+    int setV4l2FpsLocked(double fps);
+
+    sp<V4L2Frame> dequeueV4l2FrameLocked(/*out*/nsecs_t* shutterTs); // Called with mLock hold
+    //void enqueueV4l2Frame(const sp<V4L2Frame>&);
+    void enqueueV4l2Frame();
+
+    // Check if input Stream is one of supported stream setting on this device
+    static bool isSupported(const Stream& stream,
+            const std::vector<SupportedV4L2Format>& supportedFormats,
+            const ExternalCameraConfig& cfg);
+
+    // Validate and import request's output buffers and acquire fence
+    virtual Status importRequestLocked(
+            const CaptureRequest& request,
+            hidl_vec<buffer_handle_t*>& allBufPtrs,
+            hidl_vec<int>& allFences);
+
+    Status importRequestLockedImpl(
+            const CaptureRequest& request,
+            hidl_vec<buffer_handle_t*>& allBufPtrs,
+            hidl_vec<int>& allFences,
+            // Optional argument for ICameraDeviceSession@3.5 impl
+            bool allowEmptyBuf = false);
+
+    Status importBufferLocked(int32_t streamId,
+            uint64_t bufId, buffer_handle_t buf,
+            /*out*/buffer_handle_t** outBufPtr,
+            bool allowEmptyBuf);
+
+    static void cleanupInflightFences(
+            hidl_vec<int>& allFences, size_t numFences);
+    void cleanupBuffersLocked(int id);
+    void updateBufferCaches(const hidl_vec<BufferCache>& cachesToRemove);
+
+    Status processOneCaptureRequest(const CaptureRequest& request);
+
+    void notifyShutter(uint32_t frameNumber, nsecs_t shutterTs);
+    void invokeProcessCaptureResultCallback(
+            hidl_vec<CaptureResult> &results, bool tryWriteFmq);
+
+    Size getMaxJpegResolution() const;
+    Size getMaxThumbResolution() const;
+
+    int waitForV4L2BufferReturnLocked(std::unique_lock<std::mutex>& lk);
+
+    // Protect (most of) HIDL interface methods from synchronized-entering
+    mutable Mutex mInterfaceLock;
+
+    mutable Mutex mLock; // Protect all private members except otherwise noted
+    const sp<ICameraDeviceCallback> mCallback;
+    VirtualCameraManager* mVirtManager = nullptr;
+//     const ExternalCameraConfig& mCfg;
+    const common::V1_0::helper::CameraMetadata mCameraCharacteristics;
+    const std::vector<SupportedV4L2Format> mSupportedFormats;
+    const CroppingType mCroppingType;
+    const std::string mCameraId;
+//     unique_fd mV4l2Fd;
+
+    // device is closed either
+    //    - closed by user
+    //    - init failed
+    //    - camera disconnected
+    bool mClosed = false;
+    bool mInitialized = false;
+    bool mInitFail = false;
+    bool mFirstRequest = false;
+    common::V1_0::helper::CameraMetadata mLatestReqSetting;
+
+    bool mV4l2Streaming = false;
+    SupportedV4L2Format mV4l2StreamingFmt;
+    double mV4l2StreamingFps = 0.0;
+    size_t mV4L2BufferCount = 0;
+
+    sp<FrameBuffer> mFrameBuffer;
+
+    static const int kBufferWaitTimeoutSec = 3; // TODO: handle long exposure (or not allowing)
+    std::mutex mV4l2BufferLock; // protect the buffer count and condition below
+    std::condition_variable mV4L2BufferReturned;
+    size_t mNumDequeuedV4l2Buffers = 0;
+    uint32_t mMaxV4L2BufferSize = 0;
+
+    // Not protected by mLock (but might be used when mLock is locked)
+    sp<OutputThread> mOutputThread;
+
+    // Stream ID -> Camera3Stream cache
+    std::unordered_map<int, Stream> mStreamMap;
+
+    std::mutex mInflightFramesLock; // protect mInflightFrames
+    std::unordered_set<uint32_t>  mInflightFrames;
+
+    // Stream ID -> circulating buffers map
+    std::map<int, CirculatingBuffers> mCirculatingBuffers;
+    // Protect mCirculatingBuffers, must not lock mLock after acquiring this lock
+    mutable Mutex mCbsLock;
+
+    std::mutex mAfTriggerLock; // protect mAfTrigger
+    bool mAfTrigger = false;
+
+    uint32_t mBlobBufferSize = 0;
+
+    static HandleImporter sHandleImporter;
+
+    /* Beginning of members not changed after initialize() */
+    using RequestMetadataQueue = MessageQueue<uint8_t, kSynchronizedReadWrite>;
+    std::unique_ptr<RequestMetadataQueue> mRequestMetadataQueue;
+    using ResultMetadataQueue = MessageQueue<uint8_t, kSynchronizedReadWrite>;
+    std::shared_ptr<ResultMetadataQueue> mResultMetadataQueue;
+
+    // Protect against invokeProcessCaptureResultCallback()
+    Mutex mProcessCaptureResultLock;
+
+    std::unordered_map<RequestTemplate, CameraMetadata> mDefaultRequests;
+
+    const Size mMaxThumbResolution;
+    const Size mMaxJpegResolution;
+
+    std::string mExifMake;
+    std::string mExifModel;
+
+private:
+
+    struct TrampolineSessionInterface_3_4 : public ICameraDeviceSession {
+        TrampolineSessionInterface_3_4(sp<VirtualCameraDeviceSession> parent) :
+                mParent(parent) {}
+
+        virtual Return<void> constructDefaultRequestSettings(
+                RequestTemplate type,
+                V3_3::ICameraDeviceSession::constructDefaultRequestSettings_cb _hidl_cb) override {
+            return mParent->constructDefaultRequestSettings(type, _hidl_cb);
+        }
+
+        virtual Return<void> configureStreams(
+                const V3_2::StreamConfiguration& requestedConfiguration,
+                V3_3::ICameraDeviceSession::configureStreams_cb _hidl_cb) override {
+            return mParent->configureStreams(requestedConfiguration, _hidl_cb);
+        }
+
+        virtual Return<void> processCaptureRequest(const hidl_vec<V3_2::CaptureRequest>& requests,
+                const hidl_vec<V3_2::BufferCache>& cachesToRemove,
+                V3_3::ICameraDeviceSession::processCaptureRequest_cb _hidl_cb) override {
+            return mParent->processCaptureRequest(requests, cachesToRemove, _hidl_cb);
+        }
+
+        virtual Return<void> getCaptureRequestMetadataQueue(
+                V3_3::ICameraDeviceSession::getCaptureRequestMetadataQueue_cb _hidl_cb) override  {
+            return mParent->getCaptureRequestMetadataQueue(_hidl_cb);
+        }
+
+        virtual Return<void> getCaptureResultMetadataQueue(
+                V3_3::ICameraDeviceSession::getCaptureResultMetadataQueue_cb _hidl_cb) override  {
+            return mParent->getCaptureResultMetadataQueue(_hidl_cb);
+        }
+
+        virtual Return<Status> flush() override {
+            return mParent->flush();
+        }
+
+        virtual Return<void> close() override {
+            return mParent->close();
+        }
+
+        virtual Return<void> configureStreams_3_3(
+                const V3_2::StreamConfiguration& requestedConfiguration,
+                configureStreams_3_3_cb _hidl_cb) override {
+            return mParent->configureStreams_3_3(requestedConfiguration, _hidl_cb);
+        }
+
+        virtual Return<void> configureStreams_3_4(
+                const V3_4::StreamConfiguration& requestedConfiguration,
+                configureStreams_3_4_cb _hidl_cb) override {
+            return mParent->configureStreams_3_4(requestedConfiguration, _hidl_cb);
+        }
+
+        virtual Return<void> processCaptureRequest_3_4(const hidl_vec<V3_4::CaptureRequest>& requests,
+                const hidl_vec<V3_2::BufferCache>& cachesToRemove,
+                ICameraDeviceSession::processCaptureRequest_3_4_cb _hidl_cb) override {
+            return mParent->processCaptureRequest_3_4(requests, cachesToRemove, _hidl_cb);
+        }
+
+    private:
+        sp<VirtualCameraDeviceSession> mParent;
+    };
+};
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
+
+#endif  // ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTUALCAMERADEVICESESSION_H
\ No newline at end of file
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraManager.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraManager.h
new file mode 100644
index 000000000..9c3291d21
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/VirtualCameraManager.h
@@ -0,0 +1,93 @@
+#ifndef ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTUALCAMERAMANAGER_H
+#define ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTUALCAMERAMANAGER_H
+
+#include <map>
+#include <vector>
+#include <string>
+
+#include "VirtualCameraDevice.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace device {
+namespace V3_4 {
+namespace implementation {
+
+using ::android::hardware::camera::common::V1_0::Status;
+using ::android::Mutex;
+
+#define MAX_VIRTUAL_CAMERA_COUNT 8
+#define VIRTUAL_CAMERA_ID_OFFSET 10
+
+const std::string kLoopbackOffset = "50";
+
+class VirtualCameraManager : public virtual RefBase {
+public:
+    static VirtualCameraManager* getInstance() {
+        if (mInstance == nullptr) {
+            mInstance = new VirtualCameraManager();
+        }
+        mRefcount++;
+        return mInstance;
+    }
+
+    virtual ~VirtualCameraManager() {
+        Mutex::Autolock _l(mLock);
+        if (mRefcount == 1) {
+            delete mInstance;
+            mInstance = nullptr;
+        }
+        mRefcount --;
+    }
+
+    int initialize();
+    bool isInitialized() {
+        return mInitialized;
+    }
+
+    int createVirtualLoopback(const std::string& id);
+    sp<VirtualCameraDevice> getVirtualLoopback();
+
+    int getVirtCamIDs(std::vector<std::string>& ids);
+    sp<VirtualCameraDevice> getFirstVirtCam();
+
+    // Set virtualDevice as used.
+    // return -1 if all virtual devices used up.
+    sp<VirtualCameraDevice> getVirtCamByID(const std::string& virtualDeviceId);
+    // int getVirtDevByV4L2DevID(const std::string& v4l2DeviceId, VirtualCameraDevice& dev);
+
+    //Only access by CaptureManager for initialize/deinitialize
+    sp<VirtualCameraDevice> allocVirtCam();
+    int freeVirtCam(sp<VirtualCameraDevice> dev);
+
+    // To reset all virtual camera devices if errhandling required.
+    int resetAll() {
+        return 0;
+    }
+
+    void dumpAllVirtualCameras();
+
+private:
+    VirtualCameraManager() {
+        mRefcount = 0;
+        mInitialized = false;
+    }
+
+    Mutex mLock;
+    static VirtualCameraManager *mInstance;
+    static int mRefcount;
+    bool mInitialized;
+
+    std::map<std::string, sp<VirtualCameraDevice>> mVirtualDevices;
+    sp<VirtualCameraDevice> mVirtualLoopback;
+}; //class VirtualCameraManager
+
+}  // namespace implementation
+}  // namespace V3_4
+}  // namespace device
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
+
+#endif //ANDROID_HARDWARE_CAMERA_DEVICE_V3_4_VIRTUALCAMERAMANAGER_H
\ No newline at end of file
diff --git a/camera/device/3.4/default/include/ivi_device_v3_4_impl/v4l2-subdev.h b/camera/device/3.4/default/include/ivi_device_v3_4_impl/v4l2-subdev.h
new file mode 100644
index 000000000..94a89b636
--- /dev/null
+++ b/camera/device/3.4/default/include/ivi_device_v3_4_impl/v4l2-subdev.h
@@ -0,0 +1,171 @@
+/****************************************************************************
+ ****************************************************************************
+ ***
+ ***   This header was automatically generated from a Linux kernel header
+ ***   of the same name, to make information necessary for userspace to
+ ***   call into the kernel available to libc.  It contains only constants,
+ ***   structures, and macros generated from the original header, and thus,
+ ***   contains no copyrightable information.
+ ***
+ ***   To edit the content of this header, modify the corresponding
+ ***   source file (e.g. under external/kernel-headers/original/) then
+ ***   run bionic/libc/kernel/tools/update_all.py
+ ***
+ ***   Any manual change here will be lost the next time this script will
+ ***   be run. You've been warned!
+ ***
+ ****************************************************************************
+ ****************************************************************************/
+#ifndef __LINUX_V4L2_SUBDEV_H
+#define __LINUX_V4L2_SUBDEV_H
+#include <linux/ioctl.h>
+#include <linux/types.h>
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+#include <linux/v4l2-common.h>
+#include <linux/v4l2-mediabus.h>
+enum v4l2_subdev_format_whence {
+  V4L2_SUBDEV_FORMAT_TRY = 0,
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  V4L2_SUBDEV_FORMAT_ACTIVE = 1,
+};
+struct v4l2_subdev_format {
+  __u32 which;
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  __u32 pad;
+  struct v4l2_mbus_framefmt format;
+   __u32 stream;
+  __u32 reserved[7];
+};
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+struct v4l2_subdev_crop {
+  __u32 which;
+  __u32 pad;
+  struct v4l2_rect rect;
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  __u32 reserved[8];
+};
+struct v4l2_subdev_mbus_code_enum {
+  __u32 pad;
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  __u32 index;
+  __u32 code;
+  __u32 which;
+  __u32 reserved[8];
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+};
+struct v4l2_subdev_frame_size_enum {
+  __u32 index;
+  __u32 pad;
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  __u32 code;
+  __u32 min_width;
+  __u32 max_width;
+  __u32 min_height;
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  __u32 max_height;
+  __u32 which;
+  __u32 reserved[8];
+};
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+struct v4l2_subdev_frame_interval {
+  __u32 pad;
+  struct v4l2_fract interval;
+  __u32 reserved[9];
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+};
+struct v4l2_subdev_frame_interval_enum {
+  __u32 index;
+  __u32 pad;
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  __u32 code;
+  __u32 width;
+  __u32 height;
+  struct v4l2_fract interval;
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  __u32 which;
+  __u32 reserved[8];
+};
+struct v4l2_subdev_selection {
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  __u32 which;
+  __u32 pad;
+  __u32 target;
+  __u32 flags;
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+  struct v4l2_rect r;
+  __u32 reserved[8];
+};
+#define v4l2_subdev_edid v4l2_edid
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+#define VIDIOC_SUBDEV_G_FMT _IOWR('V', 4, struct v4l2_subdev_format)
+#define VIDIOC_SUBDEV_S_FMT _IOWR('V', 5, struct v4l2_subdev_format)
+#define VIDIOC_SUBDEV_G_FRAME_INTERVAL _IOWR('V', 21, struct v4l2_subdev_frame_interval)
+#define VIDIOC_SUBDEV_S_FRAME_INTERVAL _IOWR('V', 22, struct v4l2_subdev_frame_interval)
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+#define VIDIOC_SUBDEV_ENUM_MBUS_CODE _IOWR('V', 2, struct v4l2_subdev_mbus_code_enum)
+#define VIDIOC_SUBDEV_ENUM_FRAME_SIZE _IOWR('V', 74, struct v4l2_subdev_frame_size_enum)
+#define VIDIOC_SUBDEV_ENUM_FRAME_INTERVAL _IOWR('V', 75, struct v4l2_subdev_frame_interval_enum)
+#define VIDIOC_SUBDEV_G_CROP _IOWR('V', 59, struct v4l2_subdev_crop)
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+#define VIDIOC_SUBDEV_S_CROP _IOWR('V', 60, struct v4l2_subdev_crop)
+#define VIDIOC_SUBDEV_G_SELECTION _IOWR('V', 61, struct v4l2_subdev_selection)
+#define VIDIOC_SUBDEV_S_SELECTION _IOWR('V', 62, struct v4l2_subdev_selection)
+#define VIDIOC_SUBDEV_G_STD _IOR('V', 23, v4l2_std_id)
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+#define VIDIOC_SUBDEV_S_STD _IOW('V', 24, v4l2_std_id)
+#define VIDIOC_SUBDEV_ENUMSTD _IOWR('V', 25, struct v4l2_standard)
+#define VIDIOC_SUBDEV_G_EDID _IOWR('V', 40, struct v4l2_edid)
+#define VIDIOC_SUBDEV_S_EDID _IOWR('V', 41, struct v4l2_edid)
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+#define VIDIOC_SUBDEV_QUERYSTD _IOR('V', 63, v4l2_std_id)
+#define VIDIOC_SUBDEV_S_DV_TIMINGS _IOWR('V', 87, struct v4l2_dv_timings)
+#define VIDIOC_SUBDEV_G_DV_TIMINGS _IOWR('V', 88, struct v4l2_dv_timings)
+#define VIDIOC_SUBDEV_ENUM_DV_TIMINGS _IOWR('V', 98, struct v4l2_enum_dv_timings)
+/* WARNING: DO NOT EDIT, AUTO-GENERATED CODE - SEE TOP FOR INSTRUCTIONS */
+#define VIDIOC_SUBDEV_QUERY_DV_TIMINGS _IOR('V', 99, struct v4l2_dv_timings)
+#define VIDIOC_SUBDEV_DV_TIMINGS_CAP _IOWR('V', 100, struct v4l2_dv_timings_cap)
+#define VIDIOC_SUBDEV_S_ROUTING _IOWR('V', 39, struct v4l2_subdev_routing)
+#define VIDIOC_SUBDEV_G_ROUTING _IOWR('V', 38, struct v4l2_subdev_routing)
+#define V4L2_SUBDEV_ROUTE_FL_ACTIVE (1 << 0)
+#define V4L2_SUBDEV_ROUTE_FL_IMMUTABLE (1 << 1)
+#define V4L2_SUBDEV_ROUTE_FL_SOURCE (1 << 2)
+/**
+ * struct v4l2_subdev_route - A signal route inside a subdev
+ * @sink_pad: the sink pad
+ * @sink_stream: the sink stream
+ * @source_pad: the source pad
+ * @source_stream: the source stream
+ * @flags: route flags:
+ *
+ * V4L2_SUBDEV_ROUTE_FL_ACTIVE: Is the stream in use or not? An
+ * active stream will start when streaming is enabled on a video
+ * node. Set by the user.
+ *
+ * V4L2_SUBDEV_ROUTE_FL_SOURCE: Is the sub-device the source of a
+ * stream? In this case the sink information is unused (and
+ * zero). Set by the driver.
+ *
+ * V4L2_SUBDEV_ROUTE_FL_IMMUTABLE: Is the stream immutable, i.e.
+ * can it be activated and inactivated? Set by the driver.
+ */
+struct v4l2_subdev_route {
+ __u32 sink_pad;
+ __u32 sink_stream;
+ __u32 source_pad;
+ __u32 source_stream;
+ __u32 flags;
+ __u32 reserved[5];
+};
+
+/**
+ * struct v4l2_subdev_routing - Routing information
+ * @routes: the routes array
+ * @num_routes: the total number of routes in the routes array
+ */
+struct v4l2_subdev_routing {
+ struct v4l2_subdev_route *routes;
+ __u32 num_routes;
+ __u32 reserved[5];
+};
+
+#endif
diff --git a/camera/provider/2.4/default/Android.bp b/camera/provider/2.4/default/Android.bp
index bccd6cb53..e5dbcb06d 100644
--- a/camera/provider/2.4/default/Android.bp
+++ b/camera/provider/2.4/default/Android.bp
@@ -90,6 +90,53 @@ cc_library_shared {
     export_include_dirs: ["."],
 }
 
+
+cc_library_shared {
+    name: "android.hardware.camera.provider@2.4-ivi",
+    proprietary: true,
+    srcs: [
+        "IVICameraProviderImpl_2_4.cpp",
+        ],
+    shared_libs: [
+        "android.hardware.camera.common@1.0",
+        "android.hardware.camera.device@1.0",
+        "android.hardware.camera.device@3.2",
+        "android.hardware.camera.device@3.3",
+        "android.hardware.camera.device@3.4",
+        "android.hardware.camera.device@3.5",
+        "android.hardware.camera.device@3.6",
+        "android.hardware.camera.provider@2.4",
+        "android.hardware.graphics.mapper@2.0",
+        "android.hardware.graphics.mapper@3.0",
+        "android.hardware.graphics.mapper@4.0",
+        "android.hidl.allocator@1.0",
+        "android.hidl.memory@1.0",
+        "camera.device@3.3-impl",
+        "camera.device@3.4-ivi-impl",
+
+        "camera.device@3.4-impl",
+        "camera.device@3.5-external-impl",
+        "camera.device@3.5-impl",
+        "camera.device@3.6-external-impl",
+        "libcamera_metadata",
+        "libcutils",
+        "libhardware",
+        "libhidlbase",
+        "liblog",
+        "libtinyxml2",
+        "libutils",
+    ],
+    static_libs: [
+        "android.hardware.camera.common@1.0-helper",
+    ],
+    header_libs: [
+        "camera.device@3.4-ivi-impl_headers",
+        "camera.device@3.5-external-impl_headers",
+        "camera.device@3.6-external-impl_headers",
+    ],
+    export_include_dirs: ["."],
+}
+
 cc_library_shared {
     name: "android.hardware.camera.provider@2.4-impl",
     defaults: ["hidl_defaults"],
@@ -105,6 +152,7 @@ cc_library_shared {
         "android.hardware.camera.device@3.5",
         "android.hardware.camera.provider@2.4",
         "android.hardware.camera.provider@2.4-external",
+        "android.hardware.camera.provider@2.4-ivi",
         "android.hardware.camera.provider@2.4-legacy",
         "android.hardware.graphics.mapper@2.0",
         "android.hardware.graphics.mapper@3.0",
@@ -127,6 +175,7 @@ cc_library_shared {
         "libutils",
     ],
     header_libs: [
+        "camera.device@3.4-ivi-impl_headers",
         "camera.device@3.4-external-impl_headers",
         "camera.device@3.4-impl_headers",
         "camera.device@3.5-external-impl_headers",
@@ -237,3 +286,42 @@ cc_binary {
         "camera.device@3.5-impl_headers",
     ],
 }
+
+cc_binary {
+    name: "android.hardware.camera.provider@2.4-ivi-service",
+    defaults: ["hidl_defaults"],
+    proprietary: true,
+    relative_install_path: "hw",
+    srcs: ["ivi-service.cpp"],
+    compile_multilib: "32",
+    init_rc: ["android.hardware.camera.provider@2.4-ivi-service.rc"],
+    shared_libs: [
+        "android.hardware.camera.common@1.0",
+        "android.hardware.camera.device@1.0",
+        "android.hardware.camera.device@3.2",
+        "android.hardware.camera.device@3.3",
+        "android.hardware.camera.device@3.4",
+        "android.hardware.camera.provider@2.4-external",
+        "android.hardware.camera.device@3.5",
+        "android.hardware.camera.provider@2.4",
+        "android.hardware.graphics.mapper@2.0",
+        "android.hardware.graphics.mapper@3.0",
+        "android.hardware.graphics.mapper@4.0",
+
+        "libcamera_metadata",
+        "libbinder",
+        "libhidlbase",
+        "liblog",
+        "libtinyxml2",
+        "libutils",
+    ],
+    static_libs: [
+        "android.hardware.camera.common@1.0-helper",
+    ],
+    header_libs: [
+        "camera.device@3.4-ivi-impl_headers",
+        "camera.device@3.4-impl_headers",
+        "camera.device@3.5-external-impl_headers",
+        "camera.device@3.5-impl_headers",
+    ],
+}
diff --git a/camera/provider/2.4/default/CameraProvider_2_4.cpp b/camera/provider/2.4/default/CameraProvider_2_4.cpp
index 15fc702aa..2a4531240 100644
--- a/camera/provider/2.4/default/CameraProvider_2_4.cpp
+++ b/camera/provider/2.4/default/CameraProvider_2_4.cpp
@@ -17,9 +17,11 @@
 #include "CameraProvider_2_4.h"
 #include "LegacyCameraProviderImpl_2_4.h"
 #include "ExternalCameraProviderImpl_2_4.h"
+#include "IVICameraProviderImpl_2_4.h"
 
 const char *kLegacyProviderName = "legacy/0";
 const char *kExternalProviderName = "external/0";
+const char *kIVIProviderName = "ivi/0";
 
 namespace android {
 namespace hardware {
@@ -54,6 +56,9 @@ ICameraProvider* HIDL_FETCH_ICameraProvider(const char* name) {
         provider = getProviderImpl<LegacyCameraProviderImpl_2_4>();
     } else if (strcmp(name, kExternalProviderName) == 0) {
         provider = getProviderImpl<ExternalCameraProviderImpl_2_4>();
+    } else if (strcmp(name, kIVIProviderName) == 0) {
+        ALOGE("IVICameraProviderImpl_2_4 \n");
+        provider = getProviderImpl<IVICameraProviderImpl_2_4>();
     } else {
         ALOGE("%s: unknown instance name: %s", __FUNCTION__, name);
     }
diff --git a/camera/provider/2.4/default/IVICameraProviderImpl_2_4.cpp b/camera/provider/2.4/default/IVICameraProviderImpl_2_4.cpp
new file mode 100644
index 000000000..26f942d5d
--- /dev/null
+++ b/camera/provider/2.4/default/IVICameraProviderImpl_2_4.cpp
@@ -0,0 +1,378 @@
+/*
+ * Copyright (C) 2018 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "CamPrvdr@2.4-ivi"
+#define LOG_NDEBUG 0
+#include <log/log.h>
+
+#include <regex>
+#include <sys/inotify.h>
+#include <errno.h>
+#include <unistd.h>
+#include <linux/videodev2.h>
+#include <cutils/properties.h>
+#include "IVICameraProviderImpl_2_4.h"
+
+#include "CaptureManager.h"
+#include "VirtualCameraManager.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace provider {
+namespace V2_4 {
+namespace implementation {
+
+template struct CameraProvider<IVICameraProviderImpl_2_4>;
+
+namespace {
+// "device@<version>/external/<id>"
+const std::regex kDeviceNameRE("device@([0-9]+\\.[0-9]+)/ivi/(.+)");
+const int kMaxDevicePathLen = 256;
+const char* kDevicePath = "/dev/";
+constexpr char kPrefix[] = "video";
+constexpr int kPrefixLen = sizeof(kPrefix) - 1;
+constexpr int kDevicePrefixLen = sizeof(kDevicePath) + kPrefixLen + 1;
+
+bool matchDeviceName(int cameraIdOffset,
+                     const hidl_string& deviceName, std::string* deviceVersion,
+                     std::string* cameraDevicePath) {
+    std::string deviceNameStd(deviceName.c_str());
+    std::smatch sm;
+    if (std::regex_match(deviceNameStd, sm, kDeviceNameRE)) {
+        if (deviceVersion != nullptr) {
+            *deviceVersion = sm[1];
+        }
+        if (cameraDevicePath != nullptr) {
+            *cameraDevicePath = "/dev/video" + std::to_string(std::stoi(sm[2]) - cameraIdOffset);
+        }
+        return true;
+    }
+    return false;
+}
+
+} // anonymous namespace
+
+IVICameraProviderImpl_2_4::IVICameraProviderImpl_2_4() :
+        mCfg(ExternalCameraConfig::loadFromCfg()),
+        mHotPlugThread(this) {
+		//no hot plug support for IVI camera
+    mHotPlugThread.run("IVICamHotPlug", PRIORITY_BACKGROUND);
+
+    mPreferredHal3MinorVersion =
+        property_get_int32("ro.vendor.camera.external.hal3TrebleMinorVersion", 4);
+    ALOGE("IVI Preferred HAL 3 minor version is %d", mPreferredHal3MinorVersion);
+    switch(mPreferredHal3MinorVersion) {
+        case 4:
+        case 5:
+        case 6:
+            // OK
+            break;
+        default:
+            ALOGW("Unknown minor camera device HAL version %d in property "
+                    "'camera.external.hal3TrebleMinorVersion', defaulting to 4",
+                    mPreferredHal3MinorVersion);
+            mPreferredHal3MinorVersion = 4;
+    }
+
+    mCaptureManager = CaptureManager::getInstance();
+    if (mCaptureManager != nullptr) {
+        ALOGE("Initialize the capture manager.");
+        mCaptureManager->initialize();
+    }
+}
+
+IVICameraProviderImpl_2_4::~IVICameraProviderImpl_2_4() {
+    mHotPlugThread.requestExit();
+    mCaptureManager = nullptr;
+}
+
+
+Return<Status> IVICameraProviderImpl_2_4::setCallback(
+        const sp<ICameraProviderCallback>& callback) {
+    {
+
+        Mutex::Autolock _l(mLock);
+        mCallbacks = callback;
+    }
+    if (mCallbacks == nullptr) {
+        return Status::OK;
+    }
+    // Send a callback for all devices to initialize
+    {
+        for (const auto& pair : mCaptureManager->mCameraStatusMap) {
+            mCallbacks->cameraDeviceStatusChange(pair.first, pair.second);
+        }
+    }
+
+    return Status::OK;
+}
+
+Return<void> IVICameraProviderImpl_2_4::getVendorTags(
+        ICameraProvider::getVendorTags_cb _hidl_cb) {
+    // No vendor tag support for USB camera
+    hidl_vec<VendorTagSection> zeroSections;
+    _hidl_cb(Status::OK, zeroSections);
+    return Void();
+}
+
+Return<void> IVICameraProviderImpl_2_4::getCameraIdList(
+        ICameraProvider::getCameraIdList_cb _hidl_cb) {
+    // External camera HAL always report 0 camera, and extra cameras
+    // are just reported via cameraDeviceStatusChange callbacks
+    hidl_vec<hidl_string> hidlDeviceNameList;
+    _hidl_cb(Status::OK, hidlDeviceNameList);
+    return Void();
+}
+
+Return<void> IVICameraProviderImpl_2_4::isSetTorchModeSupported(
+        ICameraProvider::isSetTorchModeSupported_cb _hidl_cb) {
+    // setTorchMode API is supported, though right now no external camera device
+    // has a flash unit.
+    _hidl_cb (Status::OK, true);
+    return Void();
+}
+
+Return<void> IVICameraProviderImpl_2_4::getCameraDeviceInterface_V1_x(
+        const hidl_string&,
+        ICameraProvider::getCameraDeviceInterface_V1_x_cb _hidl_cb) {
+    // External Camera HAL does not support HAL1
+    _hidl_cb(Status::OPERATION_NOT_SUPPORTED, nullptr);
+    return Void();
+}
+
+Return<void> IVICameraProviderImpl_2_4::getCameraDeviceInterface_V3_x(
+        const hidl_string& cameraDeviceName,
+        ICameraProvider::getCameraDeviceInterface_V3_x_cb _hidl_cb) {
+
+    std::string cameraDevicePath, deviceVersion;
+    bool match = matchDeviceName(mCfg.cameraIdOffset, cameraDeviceName,
+                                 &deviceVersion, &cameraDevicePath);
+    if (!match) {
+        _hidl_cb(Status::ILLEGAL_ARGUMENT, nullptr);
+        return Void();
+    }
+
+    if (mCaptureManager->mCameraStatusMap.count(cameraDeviceName) == 0 ||
+            mCaptureManager->mCameraStatusMap[cameraDeviceName] != CameraDeviceStatus::PRESENT) {
+        _hidl_cb(Status::ILLEGAL_ARGUMENT, nullptr);
+        return Void();
+    }
+
+
+    sp<device::V3_4::implementation::VirtualCameraDevice> deviceImpl = mCaptureManager->getFirstVirtualDevice();
+
+    if (deviceImpl == nullptr || deviceImpl->isInitFailed()) {
+        ALOGE("%s: camera device %s init failed!", __FUNCTION__, cameraDevicePath.c_str());
+        _hidl_cb(Status::INTERNAL_ERROR, nullptr);
+        return Void();
+    }
+
+    IF_ALOGV() {
+        deviceImpl->getInterface()->interfaceChain([](
+            ::android::hardware::hidl_vec<::android::hardware::hidl_string> interfaceChain) {
+                ALOGV("Device interface chain:");
+                for (auto iface : interfaceChain) {
+                    ALOGV("  %s", iface.c_str());
+                }
+            });
+    }
+
+    _hidl_cb (Status::OK, deviceImpl->getInterface());
+
+    return Void();
+}
+
+void IVICameraProviderImpl_2_4::addExternalCamera(const char* devName) {
+    ALOGI("ExtCam: adding %s to External Camera HAL!", devName);
+    Mutex::Autolock _l(mLock);
+    std::string deviceName;
+    std::string cameraId = std::to_string(mCfg.cameraIdOffset +
+                                          std::atoi(devName + kDevicePrefixLen));
+    if (mPreferredHal3MinorVersion == 6) {
+        deviceName = std::string("device@3.6/external/") + cameraId;
+    } else if (mPreferredHal3MinorVersion == 5) {
+        deviceName = std::string("device@3.5/external/") + cameraId;
+    } else {
+        deviceName = std::string("device@3.4/external/") + cameraId;
+    }
+    mCameraStatusMap[deviceName] = CameraDeviceStatus::PRESENT;
+    if (mCallbacks != nullptr) {
+        mCallbacks->cameraDeviceStatusChange(deviceName, CameraDeviceStatus::PRESENT);
+    }
+}
+
+void IVICameraProviderImpl_2_4::deviceAdded(const char* devName) {
+    //int status = 0;
+#if 0
+    // sometimes device nodes not enumated hence it fails retry before confirm
+    for (int i = 0; i < 3; i++) {
+        if (status == 1)
+            break;
+        base::unique_fd fd(::open(devName, O_RDWR));
+        if (fd.get() < 0) {
+            ALOGE("%s open v4l2 device %s failed:%s and iteration %d", __FUNCTION__, devName, strerror(errno), i);
+            usleep(200000);
+            continue;
+        }
+        status = 1;
+        struct v4l2_capability capability;
+        int ret = ioctl(fd.get(), VIDIOC_QUERYCAP, &capability);
+        if (ret < 0) {
+            ALOGE("%s v4l2 QUERYCAP %s failed", __FUNCTION__, devName);
+            return;
+        }
+
+        if (!(capability.device_caps & V4L2_CAP_VIDEO_CAPTURE)
+            && !(capability.device_caps & V4L2_CAP_VIDEO_CAPTURE_MPLANE)
+            && !(capability.device_caps & V4L2_CAP_STREAMING)) {
+            ALOGW("%s device %s does not support VIDEO_CAPTURE or V4L2_CAP_VIDEO_CAPTURE_MPLANE", __FUNCTION__, devName);
+            return;
+        }
+    }
+    // See if we can initialize ExternalCameraDevice correctly
+    sp<device::V3_4::implementation::ExternalCameraDevice> deviceImpl =
+            new device::V3_4::implementation::ExternalCameraDevice(devName, mCfg);
+    if (deviceImpl == nullptr || deviceImpl->isInitFailed()) {
+        ALOGW("%s: Attempt to init camera device %s failed!", __FUNCTION__, devName);
+        return;
+    }
+    deviceImpl.clear();
+
+    addExternalCamera(devName);
+#endif
+    ALOGI("%s", devName);
+    return;
+}
+
+void IVICameraProviderImpl_2_4::deviceRemoved(const char* devName) {
+    Mutex::Autolock _l(mLock);
+    std::string deviceName;
+    std::string cameraId = std::to_string(mCfg.cameraIdOffset +
+                                          std::atoi(devName + kDevicePrefixLen));
+    if (mPreferredHal3MinorVersion == 6) {
+        deviceName = std::string("device@3.6/external/") + cameraId;
+    } else if (mPreferredHal3MinorVersion == 5) {
+        deviceName = std::string("device@3.5/external/") + cameraId;
+    } else {
+        deviceName = std::string("device@3.4/external/") + cameraId;
+    }
+    if (mCameraStatusMap.find(deviceName) != mCameraStatusMap.end()) {
+        mCameraStatusMap.erase(deviceName);
+        if (mCallbacks != nullptr) {
+            mCallbacks->cameraDeviceStatusChange(deviceName, CameraDeviceStatus::NOT_PRESENT);
+        }
+    } else {
+        ALOGE("%s: cannot find camera device %s", __FUNCTION__, devName);
+    }
+}
+
+IVICameraProviderImpl_2_4::HotplugThread::HotplugThread(
+        IVICameraProviderImpl_2_4* parent) :
+        Thread(/*canCallJava*/false),
+        mParent(parent),
+        mInternalDevices(parent->mCfg.mInternalDevices) {}
+
+IVICameraProviderImpl_2_4::HotplugThread::~HotplugThread() {}
+
+bool IVICameraProviderImpl_2_4::HotplugThread::threadLoop() {
+    // Find existing /dev/video* devices
+    DIR* devdir = opendir(kDevicePath);
+    if(devdir == 0) {
+        ALOGE("%s: cannot open %s! Exiting threadloop", __FUNCTION__, kDevicePath);
+        return false;
+    }
+#if 0
+    ALOGI("MediaControl setting in threadLoop.");
+    MediaControl* mc = MediaControl::getInstance();
+    if (mc != nullptr) {
+        ALOGI("MediaControl setting: initEntities.");
+        mc->initEntities();
+        mc->resetAllRoutes();
+        mc->createLink();
+    }
+
+    struct dirent* de;
+    while ((de = readdir(devdir)) != 0) {
+        // Find external v4l devices that's existing before we start watching and add them
+        if (!strncmp(kPrefix, de->d_name, kPrefixLen)) {
+            // TODO: This might reject some valid devices. Ex: internal is 33 and a device named 3
+            //       is added.
+            std::string deviceId(de->d_name + kPrefixLen);
+            if (mInternalDevices.count(deviceId) == 0) {
+                ALOGV("Non-internal v4l device %s found", de->d_name);
+                char v4l2DevicePath[kMaxDevicePathLen];
+                snprintf(v4l2DevicePath, kMaxDevicePathLen,
+                        "%s%s", kDevicePath, de->d_name);
+                mParent->deviceAdded(v4l2DevicePath);
+            }
+        }
+    }
+    closedir(devdir);
+#endif
+    // Watch new video devices
+    mINotifyFD = inotify_init();
+    if (mINotifyFD < 0) {
+        ALOGE("%s: inotify init failed! Exiting threadloop", __FUNCTION__);
+        return true;
+    }
+
+    mWd = inotify_add_watch(mINotifyFD, kDevicePath, IN_CREATE | IN_DELETE);
+    if (mWd < 0) {
+        ALOGE("%s: inotify add watch failed! Exiting threadloop", __FUNCTION__);
+        return true;
+    }
+
+    ALOGI("%s start monitoring new V4L2 devices", __FUNCTION__);
+
+    bool done = false;
+    char eventBuf[512];
+    while (!done) {
+        int offset = 0;
+        int ret = read(mINotifyFD, eventBuf, sizeof(eventBuf));
+        if (ret >= (int)sizeof(struct inotify_event)) {
+            while (offset < ret) {
+                struct inotify_event* event = (struct inotify_event*)&eventBuf[offset];
+                if (event->wd == mWd) {
+                    if (!strncmp(kPrefix, event->name, kPrefixLen)) {
+                        std::string deviceId(event->name + kPrefixLen);
+                        if (mInternalDevices.count(deviceId) == 0) {
+                            char v4l2DevicePath[kMaxDevicePathLen];
+                            snprintf(v4l2DevicePath, kMaxDevicePathLen,
+                                    "%s%s", kDevicePath, event->name);
+                            if (event->mask & IN_CREATE) {
+                                mParent->deviceAdded(v4l2DevicePath);
+                            }
+                            if (event->mask & IN_DELETE) {
+                                mParent->deviceRemoved(v4l2DevicePath);
+                            }
+                        }
+                    }
+                }
+                offset += sizeof(struct inotify_event) + event->len;
+            }
+        }
+    }
+
+    return true;
+}
+
+}  // namespace implementation
+}  // namespace V2_4
+}  // namespace provider
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
diff --git a/camera/provider/2.4/default/IVICameraProviderImpl_2_4.h b/camera/provider/2.4/default/IVICameraProviderImpl_2_4.h
new file mode 100644
index 000000000..1cd0d37f3
--- /dev/null
+++ b/camera/provider/2.4/default/IVICameraProviderImpl_2_4.h
@@ -0,0 +1,122 @@
+/*
+ * Copyright (C) 2018 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef ANDROID_HARDWARE_CAMERA_PROVIDER_V2_4_IVICAMERAPROVIDER_H
+#define ANDROID_HARDWARE_CAMERA_PROVIDER_V2_4_IVICAMERAPROVIDER_H
+
+#include <string>
+#include <unordered_map>
+#include <unordered_set>
+#include <utils/Mutex.h>
+#include <utils/Thread.h>
+#include <hidl/Status.h>
+#include <hidl/MQDescriptor.h>
+
+#include "IVICameraUtils.h"
+#include "VirtualCameraManager.h"
+#include "CaptureManager.h"
+#include "CameraProvider_2_4.h"
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace provider {
+namespace V2_4 {
+namespace implementation {
+
+using ::android::hardware::camera::common::V1_0::CameraDeviceStatus;
+using ::android::hardware::camera::common::V1_0::Status;
+using ::android::hardware::camera::common::V1_0::VendorTagSection;
+using ::android::hardware::camera::external::common::ExternalCameraConfig;
+using ::android::hardware::camera::device::V3_4::implementation::CaptureManager;
+using ::android::hardware::camera::provider::V2_4::ICameraProvider;
+using ::android::hardware::camera::provider::V2_4::ICameraProviderCallback;
+using ::android::hardware::Return;
+using ::android::hardware::Void;
+using ::android::hardware::hidl_vec;
+using ::android::hardware::hidl_string;
+using ::android::sp;
+using ::android::Mutex;
+
+/**
+ * The implementation of external webcam CameraProvider 2.4, separated
+ * from the HIDL interface layer to allow for implementation reuse by later
+ * provider versions.
+ *
+ * This camera provider supports standard UVC webcameras via the Linux V4L2
+ * UVC driver.
+ */
+struct IVICameraProviderImpl_2_4 {
+    IVICameraProviderImpl_2_4();
+    ~IVICameraProviderImpl_2_4();
+
+    // Caller must use this method to check if CameraProvider ctor failed
+    bool isInitFailed() { return false;}
+
+    // Methods from ::android::hardware::camera::provider::V2_4::ICameraProvider follow.
+    Return<Status> setCallback(const sp<ICameraProviderCallback>& callback);
+    Return<void> getVendorTags(ICameraProvider::getVendorTags_cb _hidl_cb);
+    Return<void> getCameraIdList(ICameraProvider::getCameraIdList_cb _hidl_cb);
+    Return<void> isSetTorchModeSupported(ICameraProvider::isSetTorchModeSupported_cb _hidl_cb);
+    Return<void> getCameraDeviceInterface_V1_x(
+            const hidl_string&,
+            ICameraProvider::getCameraDeviceInterface_V1_x_cb);
+    Return<void> getCameraDeviceInterface_V3_x(
+            const hidl_string&,
+            ICameraProvider::getCameraDeviceInterface_V3_x_cb);
+
+private:
+
+    void addExternalCamera(const char* devName);
+
+    void deviceAdded(const char* devName);
+
+    void deviceRemoved(const char* devName);
+
+    class HotplugThread : public android::Thread {
+    public:
+        HotplugThread(IVICameraProviderImpl_2_4* parent);
+        ~HotplugThread();
+
+        virtual bool threadLoop() override;
+
+    private:
+        IVICameraProviderImpl_2_4* mParent = nullptr;
+        const std::unordered_set<std::string> mInternalDevices;
+
+        int mINotifyFD = -1;
+        int mWd = -1;
+    };
+
+    Mutex mLock;
+    sp<ICameraProviderCallback> mCallbacks = nullptr;
+    std::unordered_map<std::string, CameraDeviceStatus> mCameraStatusMap; // camera id -> status
+    const ExternalCameraConfig mCfg;
+    sp<CaptureManager> mCaptureManager;
+    HotplugThread mHotPlugThread;
+    int mPreferredHal3MinorVersion;
+};
+
+
+
+}  // namespace implementation
+}  // namespace V2_4
+}  // namespace provider
+}  // namespace camera
+}  // namespace hardware
+}  // namespace android
+
+#endif  // ANDROID_HARDWARE_CAMERA_PROVIDER_V2_4_IVICAMERAPROVIDER_H
diff --git a/camera/provider/2.4/default/android.hardware.camera.provider@2.4-ivi-service.rc b/camera/provider/2.4/default/android.hardware.camera.provider@2.4-ivi-service.rc
new file mode 100644
index 000000000..d311f1d3c
--- /dev/null
+++ b/camera/provider/2.4/default/android.hardware.camera.provider@2.4-ivi-service.rc
@@ -0,0 +1,8 @@
+service vendor.camera-provider-2-4-ivi /vendor/bin/hw/android.hardware.camera.provider@2.4-ivi-service
+    interface android.hardware.camera.provider@2.4::ICameraProvider ivi/0
+    class hal
+    user cameraserver
+    group audio camera input drmrpc usb
+    ioprio rt 4
+    capabilities SYS_NICE
+    task_profiles CameraServiceCapacity MaxPerformance
diff --git a/camera/provider/2.4/default/ivi-service.cpp b/camera/provider/2.4/default/ivi-service.cpp
new file mode 100644
index 000000000..e7b8f722d
--- /dev/null
+++ b/camera/provider/2.4/default/ivi-service.cpp
@@ -0,0 +1,34 @@
+/*
+ * Copyright 2018 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "android.hardware.camera.provider@2.4-ivi-service"
+
+#include <android/hardware/camera/provider/2.4/ICameraProvider.h>
+#include <hidl/LegacySupport.h>
+
+#include <binder/ProcessState.h>
+
+using android::hardware::camera::provider::V2_4::ICameraProvider;
+using android::hardware::defaultPassthroughServiceImplementation;
+
+int main()
+{
+    ALOGE("IVI camera provider service is starting.");
+    // The camera HAL may communicate to other vendor components via
+    // /dev/vndbinder
+    android::ProcessState::initWithDriver("/dev/vndbinder");
+    return defaultPassthroughServiceImplementation<ICameraProvider>("ivi/0", /*maxThreads*/ 6);
+}
-- 
2.17.1

