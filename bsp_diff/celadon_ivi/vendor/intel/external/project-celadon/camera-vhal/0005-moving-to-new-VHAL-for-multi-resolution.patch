From ff5d3b88b381e385423a7fddf6abc164846df3cf Mon Sep 17 00:00:00 2001
From: gkdeepa <g.k.deepa@intel.com>
Date: Thu, 31 Mar 2022 11:45:29 +0530
Subject: [PATCH] moving to new VHAL for multi resolution

Tracked-On:
---
 Android.mk                                    |  31 +--
 Android.mk_bkp                                | 251 +++++++++++++++++
 .../camera-vhal/0004-cache-clone-handle.patch | 126 +++++++++
 include/CameraSocketCommand.h                 |  20 +-
 include/CameraSocketServerThread.h            |   1 +
 include/VirtualCameraFactory.h                |   1 +
 include/VirtualFakeCamera3.h                  |   4 +-
 include/fake-pipeline2/Sensor.h               |  36 +--
 src/CameraSocketServerThread.cpp              | 247 ++++++++--------
 src/Exif.cpp                                  |   3 +-
 src/VirtualBaseCamera.cpp                     |   2 +-
 src/VirtualCameraFactory.cpp                  |  32 ++-
 src/VirtualFakeCamera3.cpp                    | 263 ++++++++----------
 src/fake-pipeline2/Sensor.cpp                 | 133 ++++-----
 14 files changed, 732 insertions(+), 418 deletions(-)
 create mode 100644 Android.mk_bkp
 create mode 100644 bsp_diff/caas_cfc/vendor/intel/external/project-celadon/camera-vhal/0004-cache-clone-handle.patch

diff --git a/Android.mk b/Android.mk
index 3e14dca..27be12f 100644
--- a/Android.mk
+++ b/Android.mk
@@ -24,8 +24,8 @@ FFMPEG_PREBUILD := prebuilts/ffmpeg-4.2.2/android-x86_64
 FFMPEG_LIB_PATH := ${FFMPEG_PREBUILD}/lib
 
 include $(CLEAR_VARS)
-LOCAL_CHECK_ELF_FILES := false
 LOCAL_MODULE				:= libavcodec
+LOCAL_CHECK_ELF_FILES                   := false
 LOCAL_MULTILIB 				:= 64
 LOCAL_SRC_FILES 			:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
 LOCAL_PROPRIETARY_MODULE	:= true
@@ -34,8 +34,8 @@ LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
 include $(BUILD_PREBUILT)
 
 include $(CLEAR_VARS)
-LOCAL_CHECK_ELF_FILES := false
 LOCAL_MODULE				:= libswresample
+LOCAL_CHECK_ELF_FILES                   := false
 LOCAL_MULTILIB				:= 64
 LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
 LOCAL_PROPRIETARY_MODULE	:= true
@@ -45,7 +45,7 @@ include $(BUILD_PREBUILT)
 
 include $(CLEAR_VARS)
 LOCAL_MODULE				:= libavutil
-LOCAL_CHECK_ELF_FILES := false
+LOCAL_CHECK_ELF_FILES                   := false
 LOCAL_MULTILIB 				:= 64
 LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
 LOCAL_PROPRIETARY_MODULE	:= true
@@ -54,8 +54,8 @@ LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
 include $(BUILD_PREBUILT)
 
 include $(CLEAR_VARS)
-LOCAL_CHECK_ELF_FILES := false
 LOCAL_MODULE				:= libavdevice
+LOCAL_CHECK_ELF_FILES                   := false
 LOCAL_MULTILIB				:= 64
 LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
 LOCAL_PROPRIETARY_MODULE	:= true
@@ -64,8 +64,8 @@ LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
 include $(BUILD_PREBUILT)
 
 include $(CLEAR_VARS)
-LOCAL_CHECK_ELF_FILES := false
 LOCAL_MODULE				:= libavfilter
+LOCAL_CHECK_ELF_FILES                   := false
 LOCAL_MULTILIB				:= 64
 LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
 LOCAL_PROPRIETARY_MODULE	:= true
@@ -74,8 +74,8 @@ LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
 include $(BUILD_PREBUILT)
 
 include $(CLEAR_VARS)
-LOCAL_CHECK_ELF_FILES := false
 LOCAL_MODULE				:= libavformat
+LOCAL_CHECK_ELF_FILES                   := false
 LOCAL_MULTILIB				:= 64
 LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
 LOCAL_PROPRIETARY_MODULE	:= true
@@ -84,8 +84,8 @@ LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
 include $(BUILD_PREBUILT)
 
 include $(CLEAR_VARS)
-LOCAL_CHECK_ELF_FILES := false
 LOCAL_MODULE				:= libswscale
+LOCAL_CHECK_ELF_FILES                   := false
 LOCAL_MULTILIB				:= 64
 LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
 LOCAL_PROPRIETARY_MODULE	:= true
@@ -135,9 +135,6 @@ camera_vhal_c_includes := external/libjpeg-turbo \
 	$(LOCAL_PATH)/$(FFMPEG_PREBUILD)/include \
 	$(call include-path-for, camera)
 
-ifeq ($(TARGET_BOARD_PLATFORM), celadon)
-camera_vhal_c_includes  +=        $(INTEL_MINIGBM)/cros_gralloc
-endif
 camera_vhal_shared_libraries := \
     libexif \
     liblog \
@@ -145,7 +142,6 @@ camera_vhal_shared_libraries := \
     libcutils \
     libui \
     libdl \
-    libjpeg \
     libcamera_metadata \
     libhardware \
     libsync 
@@ -157,7 +153,7 @@ camera_vhal_shared_libraries +=     libavcodec    \
     libavformat   \
     libavutil     \
     libswresample \
-    libswscale 
+    libswscale
 endif
 
 camera_vhal_static_libraries := \
@@ -189,13 +185,6 @@ LOCAL_SRC_FILES 			:= ${camera_vhal_src}
 LOCAL_SHARED_LIBRARIES 		:= ${camera_vhal_shared_libraries}
 LOCAL_STATIC_LIBRARIES 		:= ${camera_vhal_static_libraries}
 
-LOCAL_EXPORT_C_INCLUDES := \
-	$(LOCAL_PATH)/include \
-	$(LOCAL_PATH)/$(FFMPEG_PREBUILD)/include
-
-# to support platfrom build system
-LOCAL_EXPORT_C_INCLUDE_DIRS := $(LOCAL_EXPORT_C_INCLUDES)
-
 include $(BUILD_SHARED_LIBRARY)
 
 #####################################################
@@ -221,8 +210,8 @@ jpeg_shared_libraries := \
 jpeg_c_includes := external/libjpeg-turbo \
                    external/libexif \
                    frameworks/native/include \
-                  $(LOCAL_PATH)/include \
-                  $(LOCAL_PATH)/include/jpeg-stub \
+	           $(LOCAL_PATH)/include \
+	           $(LOCAL_PATH)/include/jpeg-stub \
 
 jpeg_src := \
     src/jpeg-stub/Compressor.cpp \
diff --git a/Android.mk_bkp b/Android.mk_bkp
new file mode 100644
index 0000000..3e14dca
--- /dev/null
+++ b/Android.mk_bkp
@@ -0,0 +1,251 @@
+# Copyright (C) 2011 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#ifeq ($(TARGET_USE_CAMERA_VHAL), true)
+LOCAL_PATH := $(call my-dir)
+
+include $(CLEAR_VARS)
+
+ifneq ($(TARGET_BOARD_PLATFORM), celadon)
+####### Build FFmpeg modules from prebuilt libs #########
+
+FFMPEG_PREBUILD := prebuilts/ffmpeg-4.2.2/android-x86_64
+FFMPEG_LIB_PATH := ${FFMPEG_PREBUILD}/lib
+
+include $(CLEAR_VARS)
+LOCAL_CHECK_ELF_FILES := false
+LOCAL_MODULE				:= libavcodec
+LOCAL_MULTILIB 				:= 64
+LOCAL_SRC_FILES 			:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
+LOCAL_PROPRIETARY_MODULE	:= true
+LOCAL_MODULE_SUFFIX			:= .so
+LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
+include $(BUILD_PREBUILT)
+
+include $(CLEAR_VARS)
+LOCAL_CHECK_ELF_FILES := false
+LOCAL_MODULE				:= libswresample
+LOCAL_MULTILIB				:= 64
+LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
+LOCAL_PROPRIETARY_MODULE	:= true
+LOCAL_MODULE_SUFFIX			:= .so
+LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
+include $(BUILD_PREBUILT)
+
+include $(CLEAR_VARS)
+LOCAL_MODULE				:= libavutil
+LOCAL_CHECK_ELF_FILES := false
+LOCAL_MULTILIB 				:= 64
+LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
+LOCAL_PROPRIETARY_MODULE	:= true
+LOCAL_MODULE_SUFFIX			:= .so
+LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
+include $(BUILD_PREBUILT)
+
+include $(CLEAR_VARS)
+LOCAL_CHECK_ELF_FILES := false
+LOCAL_MODULE				:= libavdevice
+LOCAL_MULTILIB				:= 64
+LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
+LOCAL_PROPRIETARY_MODULE	:= true
+LOCAL_MODULE_SUFFIX			:= .so
+LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
+include $(BUILD_PREBUILT)
+
+include $(CLEAR_VARS)
+LOCAL_CHECK_ELF_FILES := false
+LOCAL_MODULE				:= libavfilter
+LOCAL_MULTILIB				:= 64
+LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
+LOCAL_PROPRIETARY_MODULE	:= true
+LOCAL_MODULE_SUFFIX			:= .so
+LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
+include $(BUILD_PREBUILT)
+
+include $(CLEAR_VARS)
+LOCAL_CHECK_ELF_FILES := false
+LOCAL_MODULE				:= libavformat
+LOCAL_MULTILIB				:= 64
+LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
+LOCAL_PROPRIETARY_MODULE	:= true
+LOCAL_MODULE_SUFFIX			:= .so
+LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
+include $(BUILD_PREBUILT)
+
+include $(CLEAR_VARS)
+LOCAL_CHECK_ELF_FILES := false
+LOCAL_MODULE				:= libswscale
+LOCAL_MULTILIB				:= 64
+LOCAL_SRC_FILES				:= $(FFMPEG_LIB_PATH)/$(LOCAL_MODULE).so
+LOCAL_PROPRIETARY_MODULE	:= true
+LOCAL_MODULE_SUFFIX			:= .so
+LOCAL_MODULE_CLASS			:= SHARED_LIBRARIES
+include $(BUILD_PREBUILT)
+##########################################################
+endif
+
+include $(CLEAR_VARS)
+
+##################### Build camera-vhal #######################
+
+ifeq ($(TARGET_BOARD_PLATFORM), celadon)
+LOCAL_MODULE		:= camera.$(TARGET_BOARD_PLATFORM)
+else
+LOCAL_MODULE		:= camera.$(TARGET_PRODUCT)
+endif
+
+LOCAL_MULTILIB 		:= 64
+LOCAL_VENDOR_MODULE := true
+
+camera_vhal_src := \
+	src/VirtualCameraHal.cpp \
+	src/VirtualCameraFactory.cpp \
+	src/VirtualBaseCamera.cpp \
+	src/Converters.cpp \
+	src/NV21JpegCompressor.cpp \
+	src/fake-pipeline2/Scene.cpp \
+	src/fake-pipeline2/Sensor.cpp \
+	src/fake-pipeline2/JpegCompressor.cpp \
+	src/VirtualCamera3.cpp \
+	src/VirtualFakeCamera3.cpp \
+	src/Exif.cpp \
+	src/Thumbnail.cpp \
+	src/CameraSocketServerThread.cpp \
+	src/CameraSocketCommand.cpp
+ifneq ($(TARGET_BOARD_PLATFORM), celadon)
+camera_vhal_src += src/CGCodec.cpp
+endif
+camera_vhal_c_includes := external/libjpeg-turbo \
+	external/libexif \
+	external/libyuv/files/include \
+	frameworks/native/include/media/hardware \
+	hardware/libhardware/modules/gralloc \
+	$(LOCAL_PATH)/include \
+	$(LOCAL_PATH)/$(FFMPEG_PREBUILD)/include \
+	$(call include-path-for, camera)
+
+ifeq ($(TARGET_BOARD_PLATFORM), celadon)
+camera_vhal_c_includes  +=        $(INTEL_MINIGBM)/cros_gralloc
+endif
+camera_vhal_shared_libraries := \
+    libexif \
+    liblog \
+    libutils \
+    libcutils \
+    libui \
+    libdl \
+    libjpeg \
+    libcamera_metadata \
+    libhardware \
+    libsync 
+
+ifneq ($(TARGET_BOARD_PLATFORM), celadon)
+camera_vhal_shared_libraries +=     libavcodec    \
+    libavdevice   \
+    libavfilter   \
+    libavformat   \
+    libavutil     \
+    libswresample \
+    libswscale 
+endif
+
+camera_vhal_static_libraries := \
+	android.hardware.camera.common@1.0-helper \
+	libyuv_static
+
+camera_vhal_module_relative_path := hw
+camera_vhal_cflags				 := -fno-short-enums -DREMOTE_HARDWARE
+camera_vhal_cflags				 += -Wno-unused-parameter -Wno-missing-field-initializers
+camera_vhal_clang_flags			 := -Wno-c++11-narrowing -Werror -Wno-unknown-pragmas
+
+ifeq ($(BOARD_USES_GRALLOC1), true)
+camera_vhal_cflags += -DUSE_GRALLOC1
+endif
+
+ifeq ($(TARGET_BOARD_PLATFORM), celadon)
+camera_vhal_cflags += -DGRALLOC_MAPPER4
+else
+camera_vhal_cflags += -DENABLE_FFMPEG
+endif
+
+LOCAL_MODULE_RELATIVE_PATH	:= ${camera_vhal_module_relative_path}
+LOCAL_CFLAGS				:= ${camera_vhal_cflags}
+LOCAL_CPPFLAGS 				+= -std=c++17
+LOCAL_CLANG_CFLAGS			+= ${camera_vhal_clang_flags}
+
+LOCAL_C_INCLUDES			+= ${camera_vhal_c_includes}
+LOCAL_SRC_FILES 			:= ${camera_vhal_src}
+LOCAL_SHARED_LIBRARIES 		:= ${camera_vhal_shared_libraries}
+LOCAL_STATIC_LIBRARIES 		:= ${camera_vhal_static_libraries}
+
+LOCAL_EXPORT_C_INCLUDES := \
+	$(LOCAL_PATH)/include \
+	$(LOCAL_PATH)/$(FFMPEG_PREBUILD)/include
+
+# to support platfrom build system
+LOCAL_EXPORT_C_INCLUDE_DIRS := $(LOCAL_EXPORT_C_INCLUDES)
+
+include $(BUILD_SHARED_LIBRARY)
+
+#####################################################
+
+include $(CLEAR_VARS)
+
+################ Build JPEG Library #################
+
+LOCAL_VENDOR_MODULE := true
+LOCAL_MULTILIB := 64
+
+jpeg_module_relative_path := hw
+jpeg_cflags := -fno-short-enums -DREMOTE_HARDWARE
+jpeg_cflags += -Wno-unused-parameter
+LOCAL_CPPFLAGS += -std=c++17
+jpeg_clang_flags += -Wno-c++11-narrowing
+jpeg_shared_libraries := \
+    libcutils \
+    libexif \
+    libjpeg \
+    liblog \
+
+jpeg_c_includes := external/libjpeg-turbo \
+                   external/libexif \
+                   frameworks/native/include \
+                  $(LOCAL_PATH)/include \
+                  $(LOCAL_PATH)/include/jpeg-stub \
+
+jpeg_src := \
+    src/jpeg-stub/Compressor.cpp \
+    src/jpeg-stub/JpegStub.cpp \
+
+
+LOCAL_MODULE_RELATIVE_PATH := ${jpeg_module_relative_path}
+LOCAL_CFLAGS += ${jpeg_cflags}
+LOCAL_CLANG_CFLAGS += ${jpeg_clangflags}
+
+
+LOCAL_SHARED_LIBRARIES := ${jpeg_shared_libraries}
+LOCAL_C_INCLUDES += ${jpeg_c_includes}
+LOCAL_SRC_FILES := ${jpeg_src}
+
+ifeq ($(TARGET_BOARD_PLATFORM), celadon)
+LOCAL_MODULE		:= camera.$(TARGET_BOARD_PLATFORM).jpeg
+else
+LOCAL_MODULE := camera.$(TARGET_PRODUCT).jpeg
+endif
+
+include $(BUILD_SHARED_LIBRARY)
+
+######################################################
+
+#endif # TARGET_USE_CAMERA_VHAL
diff --git a/bsp_diff/caas_cfc/vendor/intel/external/project-celadon/camera-vhal/0004-cache-clone-handle.patch b/bsp_diff/caas_cfc/vendor/intel/external/project-celadon/camera-vhal/0004-cache-clone-handle.patch
new file mode 100644
index 0000000..338e4cf
--- /dev/null
+++ b/bsp_diff/caas_cfc/vendor/intel/external/project-celadon/camera-vhal/0004-cache-clone-handle.patch
@@ -0,0 +1,126 @@
+From c87900c15767c77303fba807c979d51ff9304f02 Mon Sep 17 00:00:00 2001
+From: shivasku82 <shiva.kumara.rudrappa@intel.com>
+Date: Wed, 2 Mar 2022 13:01:57 +0530
+Subject: [PATCH] cache clone handle
+
+Signed-off-by: shivasku82 <shiva.kumara.rudrappa@intel.com>
+---
+ include/VirtualFakeCamera3.h |  2 +-
+ src/VirtualFakeCamera3.cpp   | 40 ++++++++++++++++++++++++++++++++----
+ 2 files changed, 37 insertions(+), 5 deletions(-)
+
+diff --git a/include/VirtualFakeCamera3.h b/include/VirtualFakeCamera3.h
+index c05c666..6ed4253 100644
+--- a/include/VirtualFakeCamera3.h
++++ b/include/VirtualFakeCamera3.h
+@@ -65,7 +65,7 @@ public:
+                        std::atomic<socket::CameraSessionState> &state);
+ #endif
+     virtual ~VirtualFakeCamera3();
+-
++buffer_handle_t GetBufferHandle(buffer_handle_t key);
+     /****************************************************************************
+ * VirtualCamera3 virtual overrides
+      ***************************************************************************/
+diff --git a/src/VirtualFakeCamera3.cpp b/src/VirtualFakeCamera3.cpp
+index df4ccc5..00ef92a 100644
+--- a/src/VirtualFakeCamera3.cpp
++++ b/src/VirtualFakeCamera3.cpp
+@@ -54,6 +54,10 @@ buffer_handle_t bufferHandle;
+ buffer_handle_t bufferHandle1;
+ buffer_handle_t bufferHandle2;
+ buffer_handle_t bufferHandle_3;
++struct bufferHandleMap {
++    buffer_handle_t bufferHandle;
++    buffer_handle_t key;
++}handleMap[20];
+ namespace android {
+ 
+ int32_t gSrcWidth;
+@@ -141,6 +145,21 @@ VirtualFakeCamera3::VirtualFakeCamera3(int cameraId, struct hw_module_t *module,
+     mJpegCompressor = NULL;
+ }
+ 
++buffer_handle_t VirtualFakeCamera3::GetBufferHandle(buffer_handle_t key) {
++    for(size_t i = 0; i < 20; i++) {
++        if(handleMap[i].key  ==  key) {
++            //ALOGE("Shiva return existing pointer added index %d, and key %p",(int)i, key);
++            return handleMap[i].bufferHandle;
++        }
++        if(handleMap[i].key == NULL) {
++            handleMap[i].key = key;
++            handleMap[i].bufferHandle = native_handle_clone((buffer_handle_t )key);
++            //ALOGE("Shiva Newly added index %d, and key %p",(int)i, key);
++            return handleMap[i].bufferHandle;
++        }
++    }
++    return NULL;
++}
+ VirtualFakeCamera3::~VirtualFakeCamera3() {
+     for (size_t i = 0; i < CAMERA3_TEMPLATE_COUNT; i++) {
+         if (mDefaultTemplates[i] != NULL) {
+@@ -177,6 +196,10 @@ status_t VirtualFakeCamera3::openCamera(hw_device_t **device) {
+     ALOGI(LOG_TAG "%s: E", __FUNCTION__);
+     Mutex::Autolock l(mLock);
+ 
++for(size_t i = 0; i < 20; i++)
++{
++    handleMap[i].key = NULL;
++}
+     return VirtualCamera3::openCamera(device);
+ }
+ 
+@@ -363,6 +386,11 @@ status_t VirtualFakeCamera3::closeCamera() {
+     // stream. Need to be removed later once handle startPublication properly in
+     // remote. If NO processCaptureRequest received between open and close then wait.
+ 
++for(size_t i = 0; i < 20; i++) {
++    if(   handleMap[i].key != NULL)
++        native_handle_close(handleMap[i].bufferHandle);
++    handleMap[i].key = NULL;
++}
+     if (!mprocessCaptureRequestFlag) {
+         ALOGV(LOG_TAG " %s: wait:..", __FUNCTION__);
+         std::this_thread::sleep_for(2500ms);
+@@ -1159,7 +1187,9 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
+             if (srcBuf.stream->format == HAL_PIXEL_FORMAT_YCbCr_420_888) {
+                 if (destBuf.format == HAL_PIXEL_FORMAT_YCbCr_420_888) {
+                     android_ycbcr ycbcr = android_ycbcr();
+-                    bufferHandle2 = native_handle_clone(*(destBuf.buffer));
++		    //ALOGE("Shiva its HAL_PIXEL_FORMAT_YCbCr_420_888 ");
++            //        bufferHandle2 = native_handle_clone(*(destBuf.buffer));
++            bufferHandle2 = GetBufferHandle(*(destBuf.buffer));
+ #ifdef GRALLOC_MAPPER4
+                     res = GrallocModule::getInstance().importBuffer(bufferHandle2, &bufferHandle1);
+                     //res = GrallocModule::getInstance().importBuffer(*(destBuf.buffer), &bufferHandle1);
+@@ -1186,7 +1216,9 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
+                 }
+             } else {
+ #ifdef GRALLOC_MAPPER4
+-                bufferHandle_3 = native_handle_clone(*(destBuf.buffer)); 
++
++           //     bufferHandle_3 = native_handle_clone(*(destBuf.buffer)); 
++            bufferHandle_3 = GetBufferHandle(*(destBuf.buffer));
+                 res = GrallocModule::getInstance().importBuffer(bufferHandle_3, &bufferHandle);
+                 //res = GrallocModule::getInstance().importBuffer(*(destBuf.buffer), &bufferHandle);
+                 if (res!= OK) {
+@@ -1234,14 +1266,14 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
+         if (srcBuf.stream->format == HAL_PIXEL_FORMAT_YCbCr_420_888)
+         {
+            GrallocModule::getInstance().unlock(bufferHandle2);
+-            native_handle_close(bufferHandle2);
++  //          native_handle_close(bufferHandle2);
+            //GrallocModule::getInstance().release_handle(bufferHandle1);
+            //GrallocModule::getInstance().unlock(bufferHandle1);
+         }
+         else
+         {
+            GrallocModule::getInstance().unlock(bufferHandle_3);
+-            native_handle_close(bufferHandle_3);
++    //        native_handle_close(bufferHandle_3);
+            //GrallocModule::getInstance().release_handle(bufferHandle);
+            // GrallocModule::getInstance().unlock(bufferHandle);
+         }
+-- 
+2.17.1
+
diff --git a/include/CameraSocketCommand.h b/include/CameraSocketCommand.h
index b80509b..50f9026 100644
--- a/include/CameraSocketCommand.h
+++ b/include/CameraSocketCommand.h
@@ -32,16 +32,9 @@ namespace android {
 
 namespace socket {
 
-enum class VideoCodecType { kH264 = 1, kH265 = 2,  kI420 = 3, kAll = 4 };
+enum class VideoCodecType { kH264 = 1, kH265 = 2,kI420 = 4, kAll = 3 };
 enum class FrameResolution { k480p = 1, k720p = 2, k1080p = 4, kAll = 7 };
 
-struct CameraFrameInfo {
-    VideoCodecType codec_type = VideoCodecType::kI420;
-    FrameResolution resolution = FrameResolution::k480p;
-    uint32_t reserved[4];
-};
-
-enum class CameraOperation { kOpen = 11, kClose = 12, kNone = 13 };
 enum class SensorOrientation {
     ORIENTATION_0 = 0,
     ORIENTATION_90 = 90,
@@ -123,21 +116,10 @@ typedef struct _camera_packet {
     camera_header_t header;
     uint8_t payload[0];
 } camera_packet_t;
-enum class CameraVHalVersion {
-    kV1 = 0,  // decode out of camera vhal
-    kV2 = 1,  // decode in camera vhal
-};
-// has default values.
-struct CameraConfig {
-    CameraVHalVersion version = CameraVHalVersion::kV2;
-    CameraOperation operation = CameraOperation::kNone;
-    CameraFrameInfo frame_info;
-};
 
 const char* camera_type_to_str(int type);
 const char* codec_type_to_str(uint32_t type);
 const char* resolution_to_str(uint32_t resolution);
-
 }  // namespace socket
 }  // namespace android
 
diff --git a/include/CameraSocketServerThread.h b/include/CameraSocketServerThread.h
index 54a3a61..ca5ab40 100644
--- a/include/CameraSocketServerThread.h
+++ b/include/CameraSocketServerThread.h
@@ -86,6 +86,7 @@ private:
     // Source: https://tools.ietf.org/html/rfc6184#page-13
     std::array<uint8_t, 200 * 1024> mSocketBuffer = {};
     size_t mSocketBufferSize = 0;
+
     struct ValidateClientCapability {
         bool validCodecType = false;
         bool validResolution = false;
diff --git a/include/VirtualCameraFactory.h b/include/VirtualCameraFactory.h
index 67087af..2c17066 100644
--- a/include/VirtualCameraFactory.h
+++ b/include/VirtualCameraFactory.h
@@ -31,6 +31,7 @@
 #endif
 
 #define MAX_NUMBER_OF_SUPPORTED_CAMERAS 2  // Max restricted to two, but can be extended.
+
 namespace android {
 
 class CameraSocketServerThread;
diff --git a/include/VirtualFakeCamera3.h b/include/VirtualFakeCamera3.h
index 18e4fd6..adf6da8 100644
--- a/include/VirtualFakeCamera3.h
+++ b/include/VirtualFakeCamera3.h
@@ -67,13 +67,13 @@ public:
     virtual ~VirtualFakeCamera3();
 
     /****************************************************************************
-* VirtualCamera3 virtual overrides
+     * VirtualCamera3 virtual overrides
      ***************************************************************************/
+
 public:
     virtual status_t Initialize();
 
     /****************************************************************************
-     
      * Camera module API and generic hardware device API implementation
      ***************************************************************************/
 
diff --git a/include/fake-pipeline2/Sensor.h b/include/fake-pipeline2/Sensor.h
index cd26a2a..a0db84e 100644
--- a/include/fake-pipeline2/Sensor.h
+++ b/include/fake-pipeline2/Sensor.h
@@ -91,9 +91,6 @@
 
 using namespace std::chrono_literals;
 
-#define FRAME_SIZE_240P 320 * 240 * 1.5
-#define FRAME_SIZE_480P 640 * 480 * 1.5
-
 namespace android {
 
 class Sensor : private Thread, public virtual RefBase {
@@ -242,7 +239,7 @@ private:
     void captureRGBA(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height);
     void captureRGB(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height);
     void captureNV12(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height);
-    void captureJPEG(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height);
+    void captureNV21(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height);
     void captureDepth(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height);
     void captureDepthCloud(uint8_t *img);
     void saveNV21(uint8_t *img, uint32_t size);
@@ -254,7 +251,8 @@ private:
 
     // Max supported resolution and size of client/source camera HW.
     // HAL supports max 1080p resolution.
-  
+    int mSrcWidth = 0;
+    int mSrcHeight = 0;
     uint32_t mSrcFrameSize = 0;
 
     /**
@@ -262,29 +260,23 @@ private:
      * Hence allocating buffers for max supported resolution, that is 1080p.
      */
 
-    static const size_t maxSupportedResWidth = 640;
-    static const size_t maxSupportedResHeight = 480;
+    static const size_t maxSupportedResWidth = 1920;
+    static const size_t maxSupportedResHeight = 1080;
     static const size_t bpp = 2;  // 12 bpp for NV12/NV21 and 4 bits extra for FHD operations.
     static const size_t buffSize = maxSupportedResWidth * maxSupportedResHeight * bpp;
 
-    // memories for preview usecases
-    uint32_t destPrevBufSize = FRAME_SIZE_480P;
-    std::array<uint8_t, 640 * 480 * 3 / 2> mDstTempPrevBuf = {};
-    std::array<uint8_t, 640 * 480 * 3 / 2> mDstPrevBuf = {};
+    // Allocate memories for resolution scaling operation in preview.
+    std::array<uint8_t, buffSize> mDstTempPrevBuf = {};
+    std::array<uint8_t, buffSize> mDstPrevBuf = {};
 
-    // memories for capture/record usecases
-    uint32_t mDstBufSize = FRAME_SIZE_480P;
-    std::array<uint8_t, 640 * 480 * 3 / 2> mDstTempBuf = {};
-    std::array<uint8_t, 640 * 480 * 3 / 2> mDstBuf = {};
+    // Allocate memories for resolution scaling operation in capture/record.
+    std::array<uint8_t, buffSize> mDstTempBuf = {};
+    std::array<uint8_t, buffSize> mDstBuf = {};
 
-    //memories for JPEG/BLOB capture usecases
-    uint32_t mDstJpegBufSize = FRAME_SIZE_480P;
-    std::array<uint8_t, 640 * 480 * 3 / 2> mDstJpegTempBuf = {};
-    std::array<uint8_t, 640 * 480 * 3 / 2> mDstJpegBuf = {};
+    // Allocate memories for resolution scaling operation in JPEG capture.
+    std::array<uint8_t, buffSize> mDstJpegTempBuf = {};
+    std::array<uint8_t, buffSize> mDstJpegBuf = {};
 
-    // vHAL buffer
-    int mSrcWidth = 640;
-    int mSrcHeight = 480;
 #ifdef ENABLE_FFMPEG
     std::shared_ptr<CGVideoDecoder> mDecoder = {};
 #endif
diff --git a/src/CameraSocketServerThread.cpp b/src/CameraSocketServerThread.cpp
index 70cd298..c719372 100644
--- a/src/CameraSocketServerThread.cpp
+++ b/src/CameraSocketServerThread.cpp
@@ -13,13 +13,13 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-//#define LOG_NDEBUG 0
+#define LOG_NDEBUG 0
 //#define LOG_NNDEBUG 0
-#define LOG_TAG "CameraSocketServerThread:"
+#define LOG_TAG "CameraSocketServerThread: "
 #include <log/log.h>
 
-#if defined(LOG_NNDEBUG) && LOG_NNDEBUG == 0
-#define ALOGVV ALOGV
+#ifdef LOG_NNDEBUG
+#define ALOGVV(...) ALOGV(__VA_ARGS__)
 #else
 #define ALOGVV(...) ((void)0)
 #endif
@@ -82,15 +82,8 @@ CameraSocketServerThread::CameraSocketServerThread(std::string suffix,
     char *k8s_env_value = getenv("K8S_ENV");
     mSocketPath = (k8s_env_value != NULL && !strcmp(k8s_env_value, "true")) ? "/conn/camera-socket"
                                                                             : sock_path.c_str();
-    mNumOfCamerasRequested = 2;
-    //D TODO
-    gCameraMaxWidth = 640;
-    gCameraMaxHeight = 480;
-    gMaxNumOfCamerasSupported = 2;
-    //mNumOfCamerasRequested = 2;
-    /*gCameraFacingBack = false;
-    gCameraSensorOrientation = (uint32_t)SensorOrientation::ORIENTATION_270;*/
-    gCodecType = (uint32_t)VideoCodecType::kI420;
+    ALOGI("%s camera socket server path is %s", __FUNCTION__, mSocketPath.c_str());
+    mNumOfCamerasRequested = 0;
 }
 
 CameraSocketServerThread::~CameraSocketServerThread() {
@@ -106,7 +99,7 @@ CameraSocketServerThread::~CameraSocketServerThread() {
 }
 
 status_t CameraSocketServerThread::requestExitAndWait() {
-    ALOGV("%s: Not implemented. Use requestExit + join instead", __FUNCTION__);
+    ALOGE("%s: Not implemented. Use requestExit + join instead", __FUNCTION__);
     return INVALID_OPERATION;
 }
 
@@ -130,7 +123,7 @@ status_t CameraSocketServerThread::readyToRun() {
 }
 
 void CameraSocketServerThread::setCameraMaxSupportedResolution(int32_t width, int32_t height) {
-    ALOGV(LOG_TAG "%s: E", __FUNCTION__);
+    ALOGVV(LOG_TAG "%s: E", __FUNCTION__);
 
     if (gMaxSupportedWidth < width && gMaxSupportedHeight < height) {
         gMaxSupportedWidth = width;
@@ -141,7 +134,7 @@ void CameraSocketServerThread::setCameraMaxSupportedResolution(int32_t width, in
 }
 
 void CameraSocketServerThread::setCameraResolution(uint32_t resolution) {
-    ALOGV(LOG_TAG "%s: E", __FUNCTION__);
+    ALOGVV(LOG_TAG "%s: E", __FUNCTION__);
 
     switch (resolution) {
         case uint32_t(FrameResolution::k480p):
@@ -166,7 +159,7 @@ void CameraSocketServerThread::setCameraResolution(uint32_t resolution) {
 }
 
 bool CameraSocketServerThread::configureCapabilities() {
-    ALOGV(LOG_TAG " %s Enter", __FUNCTION__);
+    ALOGVV(LOG_TAG " %s Enter", __FUNCTION__);
 
     bool status = false;
     bool valid_client_cap_info = false;
@@ -183,21 +176,21 @@ bool CameraSocketServerThread::configureCapabilities() {
     camera_packet_t *cap_packet = NULL;
     camera_packet_t *ack_packet = NULL;
     camera_header_t header = {};
-/*
+
     if ((recv_size = recv(mClientFd, (char *)&header, sizeof(camera_header_t), MSG_WAITALL)) < 0) {
-        ALOGV(LOG_TAG "%s: Failed to receive header, err: %s ", __FUNCTION__, strerror(errno));
+        ALOGE(LOG_TAG "%s: Failed to receive header, err: %s ", __FUNCTION__, strerror(errno));
         goto out;
     }
 
     if (header.type != REQUEST_CAPABILITY) {
-        ALOGV(LOG_TAG "%s: Invalid packet type\n", __FUNCTION__);
+        ALOGE(LOG_TAG "%s: Invalid packet type\n", __FUNCTION__);
         goto out;
     }
     ALOGI(LOG_TAG "%s: Received REQUEST_CAPABILITY header from client", __FUNCTION__);
-*/
+
     cap_packet = (camera_packet_t *)malloc(cap_packet_size);
     if (cap_packet == NULL) {
-        ALOGV(LOG_TAG "%s: cap camera_packet_t allocation failed: %d ", __FUNCTION__, __LINE__);
+        ALOGE(LOG_TAG "%s: cap camera_packet_t allocation failed: %d ", __FUNCTION__, __LINE__);
         return false;
     }
 
@@ -208,67 +201,55 @@ bool CameraSocketServerThread::configureCapabilities() {
     capability.maxNumberOfCameras = MAX_NUMBER_OF_SUPPORTED_CAMERAS;
 
     memcpy(cap_packet->payload, &capability, sizeof(camera_capability_t));
- /*   if (send(mClientFd, cap_packet, cap_packet_size, 0) < 0) {
-        ALOGV(LOG_TAG "%s: Failed to send camera capabilities, err: %s ", __FUNCTION__,
+    if (send(mClientFd, cap_packet, cap_packet_size, 0) < 0) {
+        ALOGE(LOG_TAG "%s: Failed to send camera capabilities, err: %s ", __FUNCTION__,
               strerror(errno));
         goto out;
-    }*/
+    }
     ALOGI(LOG_TAG "%s: Sent CAPABILITY packet to client", __FUNCTION__);
-/*
+
     if ((recv_size = recv(mClientFd, (char *)&header, sizeof(camera_header_t), MSG_WAITALL)) < 0) {
-        ALOGV(LOG_TAG "%s: Failed to receive header, err: %s ", __FUNCTION__, strerror(errno));
+        ALOGE(LOG_TAG "%s: Failed to receive header, err: %s ", __FUNCTION__, strerror(errno));
         goto out;
     }
 
     if (header.type != CAMERA_INFO) {
-        ALOGV(LOG_TAG "%s: invalid camera_packet_type: %s", __FUNCTION__,
+        ALOGE(LOG_TAG "%s: invalid camera_packet_type: %s", __FUNCTION__,
               camera_type_to_str(header.type));
         goto out;
     }
-*/
+
     // Get the number fo cameras requested to support from client.
-/*    for (int i = 1; i <= MAX_NUMBER_OF_SUPPORTED_CAMERAS; i++) {
+    for (int i = 1; i <= MAX_NUMBER_OF_SUPPORTED_CAMERAS; i++) {
         if (header.size == i * sizeof(camera_info_t)) {
             mNumOfCamerasRequested = i;
             break;
         } else if (mNumOfCamerasRequested == 0 && i == MAX_NUMBER_OF_SUPPORTED_CAMERAS) {
-            ALOGV(LOG_TAG
+            ALOGE(LOG_TAG
                   "%s: Failed to support number of cameras requested by client "
                   "which is higher than the max number of cameras supported in the HAL",
                   __FUNCTION__);
             goto out;
         }
     }
-*/
-    /*if (mNumOfCamerasRequested == 0) {
-        ALOGV(LOG_TAG "%s: invalid header size received, size = %zu", __FUNCTION__, recv_size);
+
+    if (mNumOfCamerasRequested == 0) {
+        ALOGE(LOG_TAG "%s: invalid header size received, size = %zu", __FUNCTION__, recv_size);
         goto out;
     } else {
         // Update the number of cameras globally to create camera pipeline.
         gMaxNumOfCamerasSupported = mNumOfCamerasRequested;
-    }*/
-/*
+    }
     if ((recv_size = recv(mClientFd, (char *)&camera_info,
                           mNumOfCamerasRequested * sizeof(camera_info_t), MSG_WAITALL)) < 0) {
-        ALOGV(LOG_TAG "%s: Failed to receive camera info, err: %s ", __FUNCTION__, strerror(errno));
+        ALOGE(LOG_TAG "%s: Failed to receive camera info, err: %s ", __FUNCTION__, strerror(errno));
         goto out;
     }
-*/
-    camera_info[0].cameraId = 0;
-    camera_info[0].codec_type = (uint32_t)VideoCodecType::kI420;
-    camera_info[0].sensorOrientation =  (uint32_t)SensorOrientation::ORIENTATION_0;
-    camera_info[0].facing =       (uint32_t)CameraFacing::BACK_FACING;
-    camera_info[0].resolution =  (uint32_t)FrameResolution::k480p;
-    camera_info[1].cameraId = 1;
-    camera_info[1].codec_type = (uint32_t)VideoCodecType::kI420;
-    camera_info[1].sensorOrientation =  (uint32_t)SensorOrientation::ORIENTATION_0;
-    camera_info[1].facing =       (uint32_t)CameraFacing::FRONT_FACING;
-    camera_info[1].resolution =  (uint32_t)FrameResolution::k480p;
-    mNumOfCamerasRequested =2;
+
     ALOGI(LOG_TAG "%s: Received CAMERA_INFO packet from client with recv_size: %zd ", __FUNCTION__,
           recv_size);
     ALOGI(LOG_TAG "%s: Number of cameras requested = %d", __FUNCTION__, mNumOfCamerasRequested);
-   gMaxNumOfCamerasSupported = mNumOfCamerasRequested;
+
     // Update status globally after received successful capability info.
     gCapabilityInfoReceived = true;
 
@@ -276,7 +257,7 @@ bool CameraSocketServerThread::configureCapabilities() {
     for (int i = 0; i < mNumOfCamerasRequested; i++) {
         expctd_cam_id = i;
         if (expctd_cam_id == (int)camera_info[i].cameraId)
-            ALOGV(LOG_TAG
+            ALOGVV(LOG_TAG
                    "%s: Camera Id number %u received from client is matching with expected Id",
                    __FUNCTION__, camera_info[i].cameraId);
         else
@@ -287,8 +268,8 @@ bool CameraSocketServerThread::configureCapabilities() {
 
         switch (camera_info[i].codec_type) {
             case uint32_t(VideoCodecType::kH264):
-            case uint32_t(VideoCodecType::kH265):
             case uint32_t(VideoCodecType::kI420):
+            case uint32_t(VideoCodecType::kH265):
                 val_client_cap[i].validCodecType = true;
                 break;
             default:
@@ -332,28 +313,27 @@ bool CameraSocketServerThread::configureCapabilities() {
 
     // Check whether recceived any invalid capability info or not.
     // ACK packet to client would be updated based on this verification.
-    /*for (int i = 0; i < mNumOfCamerasRequested; i++) {
+    for (int i = 0; i < mNumOfCamerasRequested; i++) {
         if (!val_client_cap[i].validCodecType || !val_client_cap[i].validResolution ||
             !val_client_cap[i].validOrientation || !val_client_cap[i].validCameraFacing) {
             valid_client_cap_info = false;
-            ALOGV("%s: capability info received from client is not completely correct and expected",
+            ALOGE("%s: capability info received from client is not completely correct and expected",
                   __FUNCTION__);
             break;
-        else {
-            ALOGV("%s: capability info received from client is correct and expected",
+        } else {
+            ALOGVV("%s: capability info received from client is correct and expected",
                    __FUNCTION__);
             valid_client_cap_info = true;
         }
-    }*/
+    }
 
-            valid_client_cap_info = true;
     // Updating metadata for each camera seperately with its capability info received.
     for (int i = 0; i < mNumOfCamerasRequested; i++) {
         // Going to update metadata for each camera, so update the status.
         gStartMetadataUpdate = false;
         gDoneMetadataUpdate = false;
         camera_id = i;
-        ALOGV(LOG_TAG
+        ALOGI(LOG_TAG
               "%s - Client requested for codec_type: %s, resolution: %s, orientation: %u, and "
               "facing: %u for camera Id %d",
               __FUNCTION__, codec_type_to_str(camera_info[i].codec_type),
@@ -367,7 +347,7 @@ bool CameraSocketServerThread::configureCapabilities() {
             // Set default resolution if receive invalid capability info from client.
             // Default resolution would be 480p.
             setCameraResolution((uint32_t)FrameResolution::k480p);
-            ALOGV(LOG_TAG
+            ALOGE(LOG_TAG
                   "%s: Not received valid resolution, "
                   "hence selected 480p as default",
                   __FUNCTION__);
@@ -380,7 +360,7 @@ bool CameraSocketServerThread::configureCapabilities() {
             // Set default codec type if receive invalid capability info from client.
             // Default codec type would be H264.
             gCodecType = (uint32_t)VideoCodecType::kH264;
-            ALOGV(LOG_TAG "%s: Not received valid codec type, hence selected H264 as default",
+            ALOGE(LOG_TAG "%s: Not received valid codec type, hence selected H264 as default",
                   __FUNCTION__);
         }
 
@@ -392,7 +372,7 @@ bool CameraSocketServerThread::configureCapabilities() {
             // client. Default sensor orientation would be zero deg and consider as landscape
             // display.
             gCameraSensorOrientation = (uint32_t)SensorOrientation::ORIENTATION_0;
-            ALOGV(LOG_TAG
+            ALOGE(LOG_TAG
                   "%s: Not received valid sensor orientation, "
                   "hence selected ORIENTATION_0 as default",
                   __FUNCTION__);
@@ -411,7 +391,7 @@ bool CameraSocketServerThread::configureCapabilities() {
                 gCameraFacingBack = false;
             else
                 gCameraFacingBack = true;
-            ALOGV(LOG_TAG
+            ALOGE(LOG_TAG
                   "%s: Not received valid camera facing info, "
                   "hence selected default",
                   __FUNCTION__);
@@ -422,7 +402,7 @@ bool CameraSocketServerThread::configureCapabilities() {
 
         // Wait till complete the metadata update for a camera.
         while (!gDoneMetadataUpdate) {
-            ALOGV("%s: wait till complete the metadata update for a camera", __FUNCTION__);
+            ALOGVV("%s: wait till complete the metadata update for a camera", __FUNCTION__);
             // 200us sleep for this thread.
             std::this_thread::sleep_for(std::chrono::microseconds(200));
         }
@@ -430,7 +410,7 @@ bool CameraSocketServerThread::configureCapabilities() {
 
     ack_packet = (camera_packet_t *)malloc(ack_packet_size);
     if (ack_packet == NULL) {
-        ALOGV(LOG_TAG "%s: ack camera_packet_t allocation failed: %d ", __FUNCTION__, __LINE__);
+        ALOGE(LOG_TAG "%s: ack camera_packet_t allocation failed: %d ", __FUNCTION__, __LINE__);
         goto out;
     }
     ack_payload = (valid_client_cap_info) ? ACK_CONFIG : NACK_CONFIG;
@@ -439,11 +419,11 @@ bool CameraSocketServerThread::configureCapabilities() {
     ack_packet->header.size = sizeof(camera_ack_t);
 
     memcpy(ack_packet->payload, &ack_payload, sizeof(camera_ack_t));
-/*    if (send(mClientFd, ack_packet, ack_packet_size, 0) < 0) {
-        ALOGV(LOG_TAG "%s: Failed to send camera capabilities, err: %s ", __FUNCTION__,
+    if (send(mClientFd, ack_packet, ack_packet_size, 0) < 0) {
+        ALOGE(LOG_TAG "%s: Failed to send camera capabilities, err: %s ", __FUNCTION__,
               strerror(errno));
         goto out;
-    }*/
+    }
     ALOGI(LOG_TAG "%s: Sent ACK packet to client with ack_size: %zu ", __FUNCTION__,
           ack_packet_size);
 
@@ -451,7 +431,7 @@ bool CameraSocketServerThread::configureCapabilities() {
 out:
     free(ack_packet);
     free(cap_packet);
-    ALOGV(LOG_TAG " %s: Exit", __FUNCTION__);
+    ALOGVV(LOG_TAG " %s: Exit", __FUNCTION__);
     return status;
 }
 
@@ -490,7 +470,7 @@ bool CameraSocketServerThread::threadLoop() {
             ALOGV("%s:%d Fail to construct camera socket with error: %s", __FUNCTION__, __LINE__,
               strerror(errno));
         return false;
-        }
+    }
 
     struct sockaddr_un addr_un;
     memset(&addr_un, 0, sizeof(addr_un));
@@ -502,7 +482,7 @@ bool CameraSocketServerThread::threadLoop() {
         ALOGI(" %s camera socket server file is %s", __FUNCTION__, mSocketPath.c_str());
         ret = unlink(mSocketPath.c_str());
         if (ret < 0) {
-            ALOGV(LOG_TAG " %s Failed to unlink %s address %d, %s", __FUNCTION__,
+            ALOGE(LOG_TAG " %s Failed to unlink %s address %d, %s", __FUNCTION__,
                   mSocketPath.c_str(), ret, strerror(errno));
             return false;
         }
@@ -514,7 +494,7 @@ bool CameraSocketServerThread::threadLoop() {
     ret = ::bind(mSocketServerFd, (struct sockaddr *)&addr_un,
                  sizeof(sa_family_t) + strlen(mSocketPath.c_str()) + 1);
     if (ret < 0) {
-        ALOGV(LOG_TAG " %s Failed to bind %s address %d, %s", __FUNCTION__, mSocketPath.c_str(),
+        ALOGE(LOG_TAG " %s Failed to bind %s address %d, %s", __FUNCTION__, mSocketPath.c_str(),
               ret, strerror(errno));
         return false;
     }
@@ -529,7 +509,7 @@ bool CameraSocketServerThread::threadLoop() {
 
         ret = listen(mSocketServerFd, 5);
         if (ret < 0) {
-            ALOGV("%s Failed to listen on %s", __FUNCTION__, mSocketPath.c_str());
+            ALOGE("%s Failed to listen on %s", __FUNCTION__, mSocketPath.c_str());
             return false;
         }
     }
@@ -571,10 +551,7 @@ bool CameraSocketServerThread::threadLoop() {
         addr_vm.svm_family = AF_VSOCK;
         addr_vm.svm_port = 1982;
         addr_vm.svm_cid = 3;
-        //addr_vm.svm_port = htons(1234);
-        //addr_vm.svm_cid = 4;
         int ret = 0;
-        int port = 1234;
         int so_reuseaddr = 1;
         size_update = 0;
         mSocketServerFd = ::socket(AF_VSOCK, SOCK_STREAM, 0);
@@ -586,7 +563,7 @@ bool CameraSocketServerThread::threadLoop() {
         ret = ::bind(mSocketServerFd, (struct sockaddr *)&addr_vm,
             sizeof(struct sockaddr_vm));
         if (ret < 0) {
-            ALOGV(LOG_TAG " %s Failed to bind port(%d). ret: %d, %s", __func__, port, ret,
+            ALOGV(LOG_TAG " %s Failed to bind port(%d). ret: %d, %s", __func__, addr_vm.svm_port, ret,
             strerror(errno));
             return false;
         }
@@ -598,7 +575,7 @@ bool CameraSocketServerThread::threadLoop() {
 
     }
     while (mRunning) {
-        ALOGV(LOG_TAG " %s: Wait for camera client to connect. . .", __FUNCTION__);
+        ALOGI(LOG_TAG " %s: Wait for camera client to connect. . .", __FUNCTION__);
 
         if (trans_mode == TCP) {
             socklen_t alen = sizeof(struct sockaddr_in);
@@ -615,10 +592,11 @@ bool CameraSocketServerThread::threadLoop() {
         }
         ALOGI(LOG_TAG " %s: Accepted client: [%d]", __FUNCTION__, new_client_fd);
         if (new_client_fd < 0) {
-            ALOGV(LOG_TAG " %s: Fail to accept client. Error: [%s]", __FUNCTION__, strerror(errno));
+            ALOGE(LOG_TAG " %s: Fail to accept client. Error: [%s]", __FUNCTION__, strerror(errno));
             continue;
         }
- 
+        mClientFd = new_client_fd;
+
         bool status = false;
         status = configureCapabilities();
         if (status) {
@@ -627,7 +605,6 @@ bool CameraSocketServerThread::threadLoop() {
                   "for %d camera(s) completed successfully..",
                   __FUNCTION__, mNumOfCamerasRequested);
         }
-        mClientFd =  new_client_fd; 
 
         ClientVideoBuffer *handle = ClientVideoBuffer::getClientInstance();
         char *fbuffer = (char *)handle->clientBuf[handle->clientRevCount % 1].buffer;
@@ -636,10 +613,10 @@ bool CameraSocketServerThread::threadLoop() {
 
         struct pollfd fd;
         int event;
+
         fd.fd = mClientFd;  // your socket handler
         fd.events = POLLIN | POLLHUP;
 
-
         while (true) {
             // check if there are any events on fd.
             int ret = poll(&fd, 1, 3000);  // 3 seconds for timeout
@@ -649,25 +626,24 @@ bool CameraSocketServerThread::threadLoop() {
             if (event & POLLHUP) {
                 // connnection disconnected => socket is closed at the other end => close the
                 // socket.
-                ALOGV(LOG_TAG " %s: POLLHUP: Close camera socket connection", __FUNCTION__);
+                ALOGE(LOG_TAG " %s: POLLHUP: Close camera socket connection", __FUNCTION__);
                 shutdown(mClientFd, SHUT_RDWR);
                 close(mClientFd);
                 mClientFd = -1;
                 handle->reset();
                 break;
-            } else if ((event & POLLIN)) {  // preview / record
+            } else if (event & POLLIN) {  // preview / record
                 // data is available in socket => read data
                 if (gIsInFrameI420) {
-                     
                      if(trans_mode == VSOCK){
-                        char buffer_header[5];
+
                         int size_header =0; 
                         ssize_t size_pending =0; 
-                        size_header = recv(mClientFd, (char *)buffer_header, 2, 0);
-                        if(size_header < 0)
-                          ALOGE("header recv error %d",size_header); 
-                        if(!strncmp(buffer_header,"OK",2)){
-                        size_pending = 460800;  
+                        //Check if the header type is data
+                        camera_header_t buffer_header = {};
+                        size_header = recv(mClientFd, (char *)&buffer_header, sizeof(camera_header_t), 0);
+                        if(buffer_header.type == CAMERA_DATA){
+                          size_pending = buffer_header.size;
                         while(size_pending != 0){
                             ssize_t size_data = 0;
                             size_data = recv(mClientFd, (char *)fbuffer+size_update, size_pending, 0);
@@ -701,81 +677,112 @@ bool CameraSocketServerThread::threadLoop() {
                        
                     }else{
                     ssize_t size = 0;
+
                     if ((size = recv(mClientFd, (char *)fbuffer, 460800, MSG_WAITALL)) > 0) {
                         handle->clientRevCount++;
-                        ALOGV(LOG_TAG
-                               "[I420] %s: Packet rev %d and "
+                        ALOGVV(LOG_TAG
+                               "[I420] %s: Pocket rev %d and "
                                "size %zd",
                                __FUNCTION__, handle->clientRevCount, size);
                         } 
                     }
                 } else if (gIsInFrameH264) {  // default H264
 #ifdef ENABLE_FFMPEG
-                    size_t recv_frame_size = 0;
                     ssize_t size = 0;
-                    if ((size = recv(mClientFd, (char *)&recv_frame_size, sizeof(size_t),
+                    camera_header_t header = {};
+                    if ((size = recv(mClientFd, (char *)&header, sizeof(camera_header_t),
                                      MSG_WAITALL)) > 0) {
-                        ALOGV("[H264] Received Header %zd bytes. Payload size: %zu", size,
-                              recv_frame_size);
-                        if (recv_frame_size > mSocketBuffer.size()) {
+                        ALOGVV("%s: Received Header %zd bytes. Payload size: %u", __FUNCTION__,
+                               size, header.size);
+                        if (header.type == REQUEST_CAPABILITY) {
+                            ALOGI(LOG_TAG
+                                  "%s: [Warning] Capability negotiation was already "
+                                  "done for %d camera(s); Can't do re-negotiation again!!!",
+                                  __FUNCTION__, mNumOfCamerasRequested);
+                            continue;
+                        } else if (header.type != CAMERA_DATA) {
+                            ALOGE(LOG_TAG "%s: invalid camera_packet_type: %s", __FUNCTION__,
+                                  camera_type_to_str(header.type));
+                            continue;
+                        }
+
+                        if (header.size > mSocketBuffer.size()) {
                             // maximum size of a H264 packet in any aggregation packet is 65535
                             // bytes. Source: https://tools.ietf.org/html/rfc6184#page-13
-                            ALOGV(
-                                "%s Fatal: Unusual H264 packet size detected: %zu! Max is %zu, ...",
-                                __func__, recv_frame_size, mSocketBuffer.size());
+                            ALOGE(
+                                "%s Fatal: Unusual encoded packet size detected: %u! Max is %zu, "
+                                "...",
+                                __func__, header.size, mSocketBuffer.size());
                             continue;
                         }
 
                         // recv frame
-                        if ((size = recv(mClientFd, (char *)mSocketBuffer.data(), recv_frame_size,
+                        if ((size = recv(mClientFd, (char *)mSocketBuffer.data(), header.size,
                                          MSG_WAITALL)) > 0) {
-                            mSocketBufferSize = recv_frame_size;
-                            ALOGV("%s [H264] Camera session state: %s", __func__,
-                                  kCameraSessionStateNames.at(mCameraSessionState).c_str());
+                            if (size < header.size) {
+                                ALOGW("%s : Incomplete data read %zd/%u bytes", __func__, size,
+                                      header.size);
+                                size_t remaining_size = header.size;
+                                remaining_size -= size;
+                                while (remaining_size > 0) {
+                                    if ((size = recv(mClientFd, (char *)mSocketBuffer.data() + size,
+                                                     remaining_size, MSG_WAITALL)) > 0) {
+                                        remaining_size -= size;
+                                        ALOGI("%s : Read-%zd after Incomplete data, remaining-%lu",
+                                              __func__, size, remaining_size);
+                                    }
+                                }
+                                size = header.size;
+                            }
+
+                            mSocketBufferSize = header.size;
+                            ALOGVV("%s: Camera session state: %s", __func__,
+                                   kCameraSessionStateNames.at(mCameraSessionState).c_str());
                             switch (mCameraSessionState) {
                                 case CameraSessionState::kCameraOpened:
                                     mCameraSessionState = CameraSessionState::kDecodingStarted;
-                                    ALOGV("%s [H264] Decoding started now.", __func__);
-                                    [[fallthrough]];
+                                    ALOGVV("%s: Decoding started now.", __func__);
                                 case CameraSessionState::kDecodingStarted:
                                     mVideoDecoder->decode(mSocketBuffer.data(), mSocketBufferSize);
                                     handle->clientRevCount++;
-                                    ALOGV("%s [H264] Received Payload #%d %zd/%zu bytes", __func__,
-                                          handle->clientRevCount, size, recv_frame_size);
+                                    ALOGVV("%s: Received Payload #%d %zd/%u bytes", __func__,
+                                           handle->clientRevCount, size, header.size);
+                                    mSocketBuffer.fill(0);
                                     break;
                                 case CameraSessionState::kCameraClosed:
-                                    mVideoDecoder->flush_decoder();
-                                    mVideoDecoder->destroy();
+                                    ALOGI("%s: Decoding stopping and flushing decoder.", __func__);
                                     mCameraSessionState = CameraSessionState::kDecodingStopped;
-                                    ALOGI("%s [H264] Decoding stopped now.", __func__);
+                                    ALOGI("%s: Decoding stopped now.", __func__);
                                     break;
                                 case CameraSessionState::kDecodingStopped:
-                                    ALOGV("%s [H264] Decoding is already stopped, skip the packets",
-                                          __func__);
-                                    [[fallthrough]];
+                                    ALOGVV("%s: Decoding is already stopped, skip the packets",
+                                           __func__);
+                                    mSocketBuffer.fill(0);
+                                    break;
                                 default:
-                                    ALOGV("%s [H264] Invalid Camera session state!", __func__);
+                                    ALOGE("%s: Invalid Camera session state!", __func__);
                                     break;
                             }
                         }
                     }
 #endif
                 } else {
-                    ALOGV("%s: only H264, I420 input frames supported", __FUNCTION__);
+                    ALOGE(
+                        "%s: Only H264, H265, I420 Input frames are supported. Check Input format",
+                        __FUNCTION__);
                 }
             } else {
-                //    ALOGV("%s: continue polling..", __FUNCTION__);
+                //    ALOGE("%s: continue polling..", __FUNCTION__);
             }
         }
     }
-    ALOGV(" %s: Quit CameraSocketServerThread... %s(%d)", __FUNCTION__, mSocketPath.c_str(),
+    ALOGE(" %s: Quit CameraSocketServerThread... %s(%d)", __FUNCTION__, mSocketPath.c_str(),
           mClientFd);
     shutdown(mClientFd, SHUT_RDWR);
     close(mClientFd);
     mClientFd = -1;
     close(mSocketServerFd);
     mSocketServerFd = -1;
-    size_update = 0;
     return true;
 }
 
diff --git a/src/Exif.cpp b/src/Exif.cpp
index 2ed9db3..57e0574 100644
--- a/src/Exif.cpp
+++ b/src/Exif.cpp
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-#define LOG_NDEBUG 0
+// #define LOG_NDEBUG 0
 #define LOG_TAG "VirtualCamera_Exif"
 #include <log/log.h>
 #include <cutils/properties.h>
@@ -338,7 +338,6 @@ static ExifData *createExifDataCommon(const CameraMetadata &params, int width, i
         EXIF_ROTATE_CAMERA_CW270 = 8,
     };
     uint16_t exifOrien = 1;
-    ALOGE("degrees in VHAL EXIF %d",degrees);
     switch (degrees) {
         case 0:
             exifOrien = EXIF_ROTATE_CAMERA_CW0;
diff --git a/src/VirtualBaseCamera.cpp b/src/VirtualBaseCamera.cpp
index ad1205e..9d65978 100644
--- a/src/VirtualBaseCamera.cpp
+++ b/src/VirtualBaseCamera.cpp
@@ -24,7 +24,7 @@
  * camera_device_t/camera_module_t structures.
  */
 
-//#define LOG_NDEBUG 0
+// #define LOG_NDEBUG 0
 #define LOG_TAG "VirtualCamera_BaseCamera"
 #include <log/log.h>
 
diff --git a/src/VirtualCameraFactory.cpp b/src/VirtualCameraFactory.cpp
index 70c999d..e463174 100644
--- a/src/VirtualCameraFactory.cpp
+++ b/src/VirtualCameraFactory.cpp
@@ -20,8 +20,8 @@
  */
 
 //#define LOG_NDEBUG 0
-#define LOG_TAG "VirtualCamera_Factory "
-#include "VirtualBuffer.h"
+#define LOG_TAG "VirtualCamera_Factory"
+
 #include "VirtualCameraFactory.h"
 #include "VirtualFakeCamera3.h"
 #include "CameraSocketServerThread.h"
@@ -30,7 +30,7 @@
 #endif
 #include <log/log.h>
 #include <cutils/properties.h>
-
+#include "VirtualBuffer.h"
 extern camera_module_t HAL_MODULE_INFO_SYM;
 
 /*
@@ -76,6 +76,7 @@ VirtualCameraFactory::VirtualCameraFactory()
         mDecoder = std::make_shared<CGVideoDecoder>();
 #endif
     }
+
     // Create socket server which is used to communicate with client device.
 #ifdef ENABLE_FFMPEG
     createSocketServer(mDecoder);
@@ -103,7 +104,7 @@ VirtualCameraFactory::VirtualCameraFactory()
     // Allocate space for each cameras requested.
     mVirtualCameras = new VirtualBaseCamera *[mNumOfCamerasSupported];
     if (mVirtualCameras == nullptr) {
-        ALOGV("%s: Unable to allocate virtual camera array", __FUNCTION__);
+        ALOGE("%s: Unable to allocate virtual camera array", __FUNCTION__);
         return;
     } else {
         for (int n = 0; n < mNumOfCamerasSupported; n++) {
@@ -115,7 +116,7 @@ VirtualCameraFactory::VirtualCameraFactory()
     for (int cameraId = 0; cameraId < mNumOfCamerasSupported; cameraId++) {
         // Wait until start updating metadata for each camera.
         while (!gStartMetadataUpdate) {
-            //ALOGV("%s: wait until start updating metadata for a single camera", __func__);
+            ALOGV("%s: wait until start updating metadata for a single camera", __func__);
             // 200us sleep for this thread.
             std::this_thread::sleep_for(std::chrono::microseconds(200));
         }
@@ -128,7 +129,6 @@ VirtualCameraFactory::VirtualCameraFactory()
         // Created a camera successfully hence update the status.
         gDoneMetadataUpdate = true;
         gStartMetadataUpdate = false;
-      
     }
 
     ALOGI("%s: Total number of cameras supported: %d", __FUNCTION__, mNumOfCamerasSupported);
@@ -148,8 +148,10 @@ bool VirtualCameraFactory::createSocketServer() {
     if (property_get("ro.boot.container.id", id, "") > 0) {
         mSocketServer =
             std::make_shared<CameraSocketServerThread>(id, decoder, std::ref(mCameraSessionState));
+
+        mSocketServer->run("FrontBackCameraSocketServerThread");
     } else
-        ALOGV("%s: FATAL: container id is not set!!", __func__);
+        ALOGE("%s: FATAL: container id is not set!!", __func__);
 
     ALOGV("%s: X", __FUNCTION__);
 #else
@@ -191,12 +193,12 @@ int VirtualCameraFactory::cameraDeviceOpen(int cameraId, hw_device_t **device) {
     *device = nullptr;
 
     if (!isConstructedOK()) {
-        ALOGV("%s: VirtualCameraFactory has failed to initialize", __FUNCTION__);
+        ALOGE("%s: VirtualCameraFactory has failed to initialize", __FUNCTION__);
         return -EINVAL;
     }
 
     if (cameraId < 0 || cameraId >= getVirtualCameraNum()) {
-        ALOGV("%s: Camera id %d is out of bounds (%d)", __FUNCTION__, cameraId,
+        ALOGE("%s: Camera id %d is out of bounds (%d)", __FUNCTION__, cameraId,
               getVirtualCameraNum());
         return -ENODEV;
     }
@@ -208,12 +210,12 @@ int VirtualCameraFactory::getCameraInfo(int cameraId, struct camera_info *info)
     ALOGI("%s: id = %d", __FUNCTION__, cameraId);
 
     if (!isConstructedOK()) {
-        ALOGV("%s: VirtualCameraFactory has failed to initialize", __FUNCTION__);
+        ALOGE("%s: VirtualCameraFactory has failed to initialize", __FUNCTION__);
         return -EINVAL;
     }
 
     if (cameraId < 0 || cameraId >= getVirtualCameraNum()) {
-        ALOGV("%s: Camera id %d is out of bounds (%d)", __FUNCTION__, cameraId,
+        ALOGE("%s: Camera id %d is out of bounds (%d)", __FUNCTION__, cameraId,
               getVirtualCameraNum());
         return -ENODEV;
     }
@@ -251,12 +253,12 @@ int VirtualCameraFactory::device_open(const hw_module_t *module, const char *nam
      */
 
     if (module != &HAL_MODULE_INFO_SYM.common) {
-        ALOGV("%s: Invalid module %p expected %p", __FUNCTION__, module,
+        ALOGE("%s: Invalid module %p expected %p", __FUNCTION__, module,
               &HAL_MODULE_INFO_SYM.common);
         return -EINVAL;
     }
     if (name == nullptr) {
-        ALOGV("%s: NULL name is not expected here", __FUNCTION__);
+        ALOGE("%s: NULL name is not expected here", __FUNCTION__);
         return -EINVAL;
     }
 
@@ -310,7 +312,7 @@ void VirtualCameraFactory::createVirtualRemoteCamera(
                                std::ref(mCameraSessionState));
 #endif							   
     if (mVirtualCameras[cameraId] == nullptr) {
-        ALOGV("%s: Unable to instantiate fake camera class", __FUNCTION__);
+        ALOGE("%s: Unable to instantiate fake camera class", __FUNCTION__);
     } else {
         status_t res = mVirtualCameras[cameraId]->Initialize();
         if (res == NO_ERROR) {
@@ -318,7 +320,7 @@ void VirtualCameraFactory::createVirtualRemoteCamera(
                   gCameraFacingBack ? "Back" : "Front", cameraId);
             // Camera creation and initialization was successful.
         } else {
-            ALOGV("%s: Unable to initialize %s camera %d: %s (%d)", __FUNCTION__,
+            ALOGE("%s: Unable to initialize %s camera %d: %s (%d)", __FUNCTION__,
                   gCameraFacingBack ? "back" : "front", cameraId, strerror(-res), res);
             delete mVirtualCameras[cameraId];
         }
diff --git a/src/VirtualFakeCamera3.cpp b/src/VirtualFakeCamera3.cpp
index f1b599a..bf1c0b7 100644
--- a/src/VirtualFakeCamera3.cpp
+++ b/src/VirtualFakeCamera3.cpp
@@ -22,7 +22,7 @@
 #include <inttypes.h>
 
 //#define LOG_NNDEBUG 0
-//#define LOG_NDEBUG 0
+#define LOG_NDEBUG 0
 #define LOG_TAG "VirtualFakeCamera3: "
 #include <cutils/properties.h>
 #include <log/log.h>
@@ -126,11 +126,10 @@ VirtualFakeCamera3::VirtualFakeCamera3(int cameraId, struct hw_module_t *module,
     mAeTargetExposureTime = kNormalExposureTime;
     mAeCurrentExposureTime = kNormalExposureTime;
     mAeCurrentSensitivity = kNormalSensitivity;
-    mSensorWidth = 640;
-    mSensorHeight = 480;
-    
-	mSrcWidth = 640;
-    mSrcHeight = 480;
+    mSensorWidth = 0;
+    mSensorHeight = 0;
+    mSrcWidth = gCameraMaxWidth;
+    mSrcHeight = gCameraMaxHeight;
     mCodecType = 0;
     mDecoderResolution = 0;
     mFacingBack = false;
@@ -150,23 +149,23 @@ VirtualFakeCamera3::~VirtualFakeCamera3() {
 }
 
 status_t VirtualFakeCamera3::Initialize() {
-    ALOGV("%s: E", __FUNCTION__);
+    ALOGVV("%s: E", __FUNCTION__);
     status_t res;
 
     if (mStatus != STATUS_ERROR) {
-        ALOGV("%s: Already initialized!", __FUNCTION__);
+        ALOGE("%s: Already initialized!", __FUNCTION__);
         return INVALID_OPERATION;
     }
 
     res = getCameraCapabilities();
     if (res != OK) {
-        ALOGV("%s: Unable to get camera capabilities: %s (%d)", __FUNCTION__, strerror(-res), res);
+        ALOGE("%s: Unable to get camera capabilities: %s (%d)", __FUNCTION__, strerror(-res), res);
         return res;
     }
 
     res = constructStaticInfo();
     if (res != OK) {
-        ALOGV("%s: Unable to allocate static info: %s (%d)", __FUNCTION__, strerror(-res), res);
+        ALOGE("%s: Unable to allocate static info: %s (%d)", __FUNCTION__, strerror(-res), res);
         return res;
     }
 
@@ -181,7 +180,7 @@ status_t VirtualFakeCamera3::openCamera(hw_device_t **device) {
 }
 
 uint32_t VirtualFakeCamera3::setDecoderResolution(uint32_t resolution) {
-    ALOGV(LOG_TAG "%s: E", __FUNCTION__);
+    ALOGVV(LOG_TAG "%s: E", __FUNCTION__);
     uint32_t res = 0;
     switch (resolution) {
         case DECODER_SUPPORTED_RESOLUTION_480P:
@@ -204,6 +203,7 @@ uint32_t VirtualFakeCamera3::setDecoderResolution(uint32_t resolution) {
 }
 status_t VirtualFakeCamera3::sendCommandToClient(camera_cmd_t cmd) {
     ALOGI("%s E", __func__);
+
     status_t status = INVALID_OPERATION;
     size_t config_cmd_packet_size = sizeof(camera_header_t) + sizeof(camera_config_cmd_t);
     camera_config_cmd_t config_cmd = {};
@@ -214,17 +214,16 @@ status_t VirtualFakeCamera3::sendCommandToClient(camera_cmd_t cmd) {
     config_cmd.config.resolution = mDecoderResolution;
 
     camera_packet_t *config_cmd_packet = NULL;
-#if 0
 
     int client_fd = mSocketServer->getClientFd();
     if (client_fd < 0) {
-        ALOGV("%s: We're not connected to client yet!", __FUNCTION__);
+        ALOGE("%s: We're not connected to client yet!", __FUNCTION__);
         return status;
     }
 
     config_cmd_packet = (camera_packet_t *)malloc(config_cmd_packet_size);
     if (config_cmd_packet == NULL) {
-        ALOGV(LOG_TAG "%s: config camera_packet_t allocation failed: %d ", __FUNCTION__, __LINE__);
+        ALOGE(LOG_TAG "%s: config camera_packet_t allocation failed: %d ", __FUNCTION__, __LINE__);
         goto out;
     }
 
@@ -234,7 +233,7 @@ status_t VirtualFakeCamera3::sendCommandToClient(camera_cmd_t cmd) {
 
     ALOGI("%s: Camera client fd %d!", __FUNCTION__, client_fd);
     if (send(client_fd, config_cmd_packet, config_cmd_packet_size, 0) < 0) {
-        ALOGV(LOG_TAG "%s: Failed to send Camera %s command to client, err %s ", __FUNCTION__,
+        ALOGE(LOG_TAG "%s: Failed to send Camera %s command to client, err %s ", __FUNCTION__,
               (cmd == camera_cmd_t::CMD_CLOSE) ? "CloseCamera" : "OpenCamera", strerror(errno));
         goto out;
     }
@@ -242,40 +241,6 @@ status_t VirtualFakeCamera3::sendCommandToClient(camera_cmd_t cmd) {
     ALOGI("%s: Sent cmd %s to client %d!", __FUNCTION__,
           (cmd == camera_cmd_t::CMD_CLOSE) ? "CloseCamera" : "OpenCamera", client_fd);
     status = OK;
-#endif
-    CameraConfig camera_config = {};
-    if(cmd == CMD_OPEN)
-    {
-    camera_config.operation = socket::CameraOperation::kOpen;
-    } 
-    else
-    camera_config.operation = socket::CameraOperation::kClose;
-
-    int client_fd = mSocketServer->getClientFd();
-    if (client_fd < 0) {
-        ALOGV("%s: We're not connected to client yet!", __FUNCTION__);
-        return INVALID_OPERATION;
-    }
-    char mode[PROPERTY_VALUE_MAX];
-    //incase vsock add yuv command
-    //D :to do
-    //if ((property_get("ro.vendor.camera.transference", mode, nullptr) > 0))
-    {
-    //    if (!strcmp(mode, "VSOCK"))
-            ALOGV("%s:! sending Vsock ingo!", __FUNCTION__);
-            camera_config.frame_info.codec_type = VideoCodecType::kI420;
-    }
-    ALOGI("%s: Camera client fd %d!", __FUNCTION__, client_fd);
-    if (send(client_fd, &camera_config, sizeof(camera_config), 0) < 0) {
-        ALOGV(LOG_TAG "%s: Failed to send Camera Open command to client, err %s ", __FUNCTION__,
-              strerror(errno));
-        return INVALID_OPERATION;
-    }
-
-    std::string cmd_str =
-        (cmd == CMD_CLOSE) ? "CloseCamera" : "OpenCamera";
-    ALOGI("%s: Sent cmd %s to client %d!", __FUNCTION__, cmd_str.c_str(), client_fd);
-    return OK;
 out:
     free(config_cmd_packet);
     return status;
@@ -290,7 +255,7 @@ status_t VirtualFakeCamera3::connectCamera() {
         // initialize decoder
         if (mDecoder->init((android::socket::FrameResolution)mDecoderResolution, mCodecType,
                            device_name, 0) < 0) {
-            ALOGV("%s VideoDecoder init failed. %s decoding", __func__,
+            ALOGE("%s VideoDecoder init failed. %s decoding", __func__,
                   !device_name ? "SW" : device_name);
         } else {
             mDecoderInitDone = true;
@@ -305,12 +270,13 @@ status_t VirtualFakeCamera3::connectCamera() {
     ALOGI("%s Calling sendCommandToClient", __func__);
     status_t ret;
     if ((ret = sendCommandToClient(camera_cmd_t::CMD_OPEN)) != OK) {
-        ALOGV("%s sendCommandToClient failed", __func__);
+        ALOGE("%s sendCommandToClient failed", __func__);
         return ret;
     }
     ALOGI("%s Called sendCommandToClient", __func__);
     mCameraSessionState = CameraSessionState::kCameraOpened;
-
+    mSrcWidth = gCameraMaxWidth;
+    mSrcHeight = gCameraMaxHeight;
     // create sensor who gets decoded frames and forwards them to framework
 #ifdef ENABLE_FFMPEG
     mSensor = new Sensor(mSrcWidth, mSrcHeight, mDecoder);
@@ -364,7 +330,7 @@ status_t VirtualFakeCamera3::closeCamera() {
     // remote. If NO processCaptureRequest received between open and close then wait.
 
     if (!mprocessCaptureRequestFlag) {
-        ALOGV(LOG_TAG " %s: wait:..", __FUNCTION__);
+        ALOGE(LOG_TAG " %s: wait:..", __FUNCTION__);
         std::this_thread::sleep_for(2500ms);
     }
     mprocessCaptureRequestFlag = false;
@@ -379,7 +345,7 @@ status_t VirtualFakeCamera3::closeCamera() {
 
         auto ret = mSensor->shutDown();
         if (ret != NO_ERROR) {
-            ALOGV("%s: Unable to shut down sensor: %d", __FUNCTION__, ret);
+            ALOGE("%s: Unable to shut down sensor: %d", __FUNCTION__, ret);
         }
         mSensor.clear();
 
@@ -417,13 +383,13 @@ status_t VirtualFakeCamera3::closeCamera() {
     // Send close command to client
     status_t ret = sendCommandToClient(camera_cmd_t::CMD_CLOSE);
     if (ret != OK) {
-        ALOGV("%s sendCommandToClient failed", __func__);
+        ALOGE("%s sendCommandToClient failed", __func__);
     }
 
     // Set NULL or Zero to some local members which would be updated in the
     // next configure_streams call to support Dynamic multi-resolution.
-    mSrcWidth = 640;
-    mSrcHeight = 480;
+    mSrcWidth = 0;
+    mSrcHeight = 0;
     mDecoderResolution = 0;
     mDecoderInitDone = false;
     mSensor = NULL;
@@ -451,7 +417,7 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
     status_t res;
 
     if (mStatus != STATUS_OPEN && mStatus != STATUS_READY) {
-        ALOGV("%s: Cannot configure streams in state %d", __FUNCTION__, mStatus);
+        ALOGE("%s: Cannot configure streams in state %d", __FUNCTION__, mStatus);
         return NO_INIT;
     }
 
@@ -459,19 +425,19 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
      * Sanity-check input list.
      */
     if (streamList == NULL) {
-        ALOGV("%s: NULL stream configuration", __FUNCTION__);
+        ALOGE("%s: NULL stream configuration", __FUNCTION__);
         return BAD_VALUE;
     }
 
     ALOGI("%s: %d streams", __FUNCTION__, streamList->num_streams);
     if (streamList->streams == NULL) {
-        ALOGV("%s: NULL stream list", __FUNCTION__);
+        ALOGE("%s: NULL stream list", __FUNCTION__);
         return BAD_VALUE;
     }
 
     ALOGI("%s: %d streams", __FUNCTION__, streamList->num_streams);
     if (streamList->num_streams < 1) {
-        ALOGV("%s: Bad number of streams requested: %d", __FUNCTION__, streamList->num_streams);
+        ALOGE("%s: Bad number of streams requested: %d", __FUNCTION__, streamList->num_streams);
         return BAD_VALUE;
     }
 
@@ -480,7 +446,7 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
         camera3_stream_t *newStream = streamList->streams[i];
 
         if (newStream == NULL) {
-            ALOGV("%s: Stream index %zu was NULL", __FUNCTION__, i);
+            ALOGE("%s: Stream index %zu was NULL", __FUNCTION__, i);
             return BAD_VALUE;
         }
 
@@ -493,7 +459,7 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
         if (newStream->stream_type == CAMERA3_STREAM_INPUT ||
             newStream->stream_type == CAMERA3_STREAM_BIDIRECTIONAL) {
             if (inputStream != NULL) {
-                ALOGV("%s: Multiple input streams requested!", __FUNCTION__);
+                ALOGE("%s: Multiple input streams requested!", __FUNCTION__);
                 return BAD_VALUE;
             }
             inputStream = newStream;
@@ -502,7 +468,7 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
         if (newStream->stream_type != CAMERA3_STREAM_INPUT) {
             if (newStream->rotation < CAMERA3_STREAM_ROTATION_0 ||
                 newStream->rotation > CAMERA3_STREAM_ROTATION_270) {
-                ALOGV("%s: Unsupported stream rotation 0x%x requested", __FUNCTION__,
+                ALOGE("%s: Unsupported stream rotation 0x%x requested", __FUNCTION__,
                       newStream->rotation);
                 return BAD_VALUE;
             }
@@ -511,7 +477,7 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
         if (newStream->width == 0 || newStream->height == 0 ||
             newStream->width > (uint32_t)mSensorWidth ||
             newStream->height > (uint32_t)mSensorHeight) {
-            ALOGV("%s: Unsupported stream width 0x%x height 0x%x", __FUNCTION__, newStream->width,
+            ALOGE("%s: Unsupported stream width 0x%x height 0x%x", __FUNCTION__, newStream->width,
                   newStream->height);
             return BAD_VALUE;
         }
@@ -525,7 +491,7 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
             }
         }
         if (!validFormat) {
-            ALOGV("%s: Unsupported stream format 0x%x requested", __FUNCTION__, newStream->format);
+            ALOGE("%s: Unsupported stream format 0x%x requested", __FUNCTION__, newStream->format);
             return BAD_VALUE;
         }
 
@@ -577,12 +543,13 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
                 // Workarroud: SG1:  HAL_PIXEL_FORMAT_RGBA_8888 &&
                 // GRALLOC_USAGE_HW_CAMERA_WRITE combination doesn't supported by minigbm
                 newStream->usage |= GRALLOC_USAGE_HW_CAMERA_WRITE;
-                ALOGV("%s: GRALLOC0", __FUNCTION__);
+                ALOGE("%s: GRALLOC0", __FUNCTION__);
 #else
-                ALOGV("%s: GRALLOC1", __FUNCTION__);
-                  //WA: configure usage when requrested for buffer overlay, WA provided during vts run
+                newStream->usage |= GRALLOC_USAGE_SW_WRITE_OFTEN;
+                ALOGE("%s: GRALLOC1 GRALLOC_USAGE_SW_WRITE_OFTEN", __FUNCTION__);
+                 //WA: configure usage when requrested for buffer overlay, WA provided during vts run
                   // cases of configure single stream and flush 
-                   newStream->usage = 0x100;
+                //   newStream->usage = 0x100;
 #endif
                 break;
             case CAMERA3_STREAM_INPUT:
@@ -597,11 +564,17 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
 #ifndef USE_GRALLOC1
             if (newStream->usage & GRALLOC_USAGE_HW_CAMERA_WRITE) {
 #endif
-                if (newStream->usage & GRALLOC_USAGE_HW_TEXTURE) {
+                if ((newStream->usage & GRALLOC_USAGE_HW_TEXTURE) ||
+                    (newStream->usage & GRALLOC_USAGE_HW_VIDEO_ENCODER)) {
+                    // Both preview and video capture output format would
+                    // be RGB32 always if it is HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED.
                     newStream->format = HAL_PIXEL_FORMAT_RGBA_8888;
-                } else if (newStream->usage & GRALLOC_USAGE_HW_VIDEO_ENCODER) {
-                    newStream->format = HAL_PIXEL_FORMAT_YCbCr_420_888;
-                } else {
+                }
+				 //TODO: present in old VHAL, need to check video usecase
+				 //else if (newStream->usage & GRALLOC_USAGE_HW_VIDEO_ENCODER) {
+                   // newStream->format = HAL_PIXEL_FORMAT_YCbCr_420_888;
+                //}
+				else {
                     newStream->format = HAL_PIXEL_FORMAT_RGB_888;
                 }
 #ifndef USE_GRALLOC1
@@ -649,25 +622,26 @@ status_t VirtualFakeCamera3::configureStreams(camera3_stream_configuration *stre
 }
 
 status_t VirtualFakeCamera3::registerStreamBuffers(const camera3_stream_buffer_set *bufferSet) {
-    ALOGV("%s: E", __FUNCTION__);
+    ALOGVV("%s: E", __FUNCTION__);
     Mutex::Autolock l(mLock);
 
     // Should not be called in HAL versions >= 3.2
 
-    ALOGV("%s: Should not be invoked on new HALs!", __FUNCTION__);
+    ALOGE("%s: Should not be invoked on new HALs!", __FUNCTION__);
     return NO_INIT;
 }
 
 const camera_metadata_t *VirtualFakeCamera3::constructDefaultRequestSettings(int type) {
-    ALOGV("%s: E", __FUNCTION__);
+    ALOGVV("%s: E", __FUNCTION__);
     Mutex::Autolock l(mLock);
+
     if (type < 0 || type >= CAMERA3_TEMPLATE_COUNT) {
-        ALOGV("%s: Unknown request settings template: %d", __FUNCTION__, type);
+        ALOGE("%s: Unknown request settings template: %d", __FUNCTION__, type);
         return NULL;
     }
 
     if (!hasCapability(BACKWARD_COMPATIBLE) && type != CAMERA3_TEMPLATE_PREVIEW) {
-        ALOGV("%s: Template %d not supported w/o BACKWARD_COMPATIBLE capability", __FUNCTION__,
+        ALOGE("%s: Template %d not supported w/o BACKWARD_COMPATIBLE capability", __FUNCTION__,
               type);
         return NULL;
     }
@@ -978,34 +952,34 @@ const camera_metadata_t *VirtualFakeCamera3::constructDefaultRequestSettings(int
     }
 
     mDefaultTemplates[type] = settings.release();
-    ALOGV("%s: X", __FUNCTION__);
+
     return mDefaultTemplates[type];
 }
 
 status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *request) {
-    ALOGV("%s: E", __FUNCTION__);
+    ALOGVV("%s: E", __FUNCTION__);
     Mutex::Autolock l(mLock);
     status_t res;
     mprocessCaptureRequestFlag = true;
     /** Validation */
 
     if (mStatus < STATUS_READY) {
-        ALOGV("%s: Can't submit capture requests in state %d", __FUNCTION__, mStatus);
+        ALOGE("%s: Can't submit capture requests in state %d", __FUNCTION__, mStatus);
         return INVALID_OPERATION;
     }
 
     if (request == NULL) {
-        ALOGV("%s: NULL request!", __FUNCTION__);
+        ALOGE("%s: NULL request!", __FUNCTION__);
         return BAD_VALUE;
     }
 
-    ALOGV("%s: Number of requested buffers = %u, Frame no: %u", __FUNCTION__,
+    ALOGVV("%s: Number of requested buffers = %u, Frame no: %u", __FUNCTION__,
            request->num_output_buffers, request->frame_number);
 
     uint32_t frameNumber = request->frame_number;
 
     if (request->settings == NULL && mPrevSettings.isEmpty()) {
-        ALOGV(
+        ALOGE(
             "%s: Request %d: NULL settings for first request after"
             "configureStreams()",
             __FUNCTION__, frameNumber);
@@ -1013,7 +987,7 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
     }
 
     if (request->input_buffer != NULL && request->input_buffer->stream != mInputStream) {
-        ALOGV("%s: Request %d: Input buffer not from input stream!", __FUNCTION__, frameNumber);
+        ALOGE("%s: Request %d: Input buffer not from input stream!", __FUNCTION__, frameNumber);
         ALOGV("%s: Bad stream %p, expected: %p", __FUNCTION__, request->input_buffer->stream,
               mInputStream);
         ALOGV("%s: Bad stream type %d, expected stream type %d", __FUNCTION__,
@@ -1024,7 +998,7 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
     }
 
     if (request->num_output_buffers < 1 || request->output_buffers == NULL) {
-        ALOGV("%s: Request %d: No output buffers provided!", __FUNCTION__, frameNumber);
+        ALOGE("%s: Request %d: No output buffers provided!", __FUNCTION__, frameNumber);
         return BAD_VALUE;
     }
 
@@ -1042,25 +1016,25 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
     do {
         PrivateStreamInfo *priv = static_cast<PrivateStreamInfo *>(b->stream->priv);
         if (priv == NULL) {
-            ALOGV("%s: Request %d: Buffer %zu: Unconfigured stream!", __FUNCTION__, frameNumber,
+            ALOGE("%s: Request %d: Buffer %zu: Unconfigured stream!", __FUNCTION__, frameNumber,
                   idx);
             return BAD_VALUE;
         }
         if (!priv->alive) {
-            ALOGV("%s: Request %d: Buffer %zu: Dead stream!", __FUNCTION__, frameNumber, idx);
+            ALOGE("%s: Request %d: Buffer %zu: Dead stream!", __FUNCTION__, frameNumber, idx);
             return BAD_VALUE;
         }
         if (b->status != CAMERA3_BUFFER_STATUS_OK) {
-            ALOGV("%s: Request %d: Buffer %zu: Status not OK!", __FUNCTION__, frameNumber, idx);
+            ALOGE("%s: Request %d: Buffer %zu: Status not OK!", __FUNCTION__, frameNumber, idx);
             return BAD_VALUE;
         }
         if (b->release_fence != -1) {
-            ALOGV("%s: Request %d: Buffer %zu: Has a release fence!", __FUNCTION__, frameNumber,
+            ALOGE("%s: Request %d: Buffer %zu: Has a release fence!", __FUNCTION__, frameNumber,
                   idx);
             return BAD_VALUE;
         }
         if (b->buffer == NULL) {
-            ALOGV("%s: Request %d: Buffer %zu: NULL buffer handle!", __FUNCTION__, frameNumber,
+            ALOGE("%s: Request %d: Buffer %zu: NULL buffer handle!", __FUNCTION__, frameNumber,
                   idx);
             return BAD_VALUE;
         }
@@ -1137,11 +1111,16 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
 #ifndef USE_GRALLOC1
             if (srcBuf.stream->usage & GRALLOC_USAGE_HW_CAMERA_WRITE) {
 #endif
-                if (srcBuf.stream->usage & GRALLOC_USAGE_HW_TEXTURE) {
+                if ((srcBuf.stream->usage & GRALLOC_USAGE_HW_TEXTURE) ||
+                    (srcBuf.stream->usage & GRALLOC_USAGE_HW_VIDEO_ENCODER)) {
+                    // Both preview and video capture output format would
+                    // be RGB32 always if it is HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED.
                     destBuf.format = HAL_PIXEL_FORMAT_RGBA_8888;
-                } else if (srcBuf.stream->usage & GRALLOC_USAGE_HW_VIDEO_ENCODER) {
-                    destBuf.format = HAL_PIXEL_FORMAT_YCbCr_420_888;
-                } else if ((srcBuf.stream->usage & GRALLOC_USAGE_HW_CAMERA_MASK) ==
+               //TODO: present in old VHAL
+			   //  } else if (srcBuf.stream->usage & GRALLOC_USAGE_HW_VIDEO_ENCODER) {
+                //    destBuf.format = HAL_PIXEL_FORMAT_YCbCr_420_888;
+                //}
+				 }else if ((srcBuf.stream->usage & GRALLOC_USAGE_HW_CAMERA_MASK) ==
                            GRALLOC_USAGE_HW_CAMERA_ZSL) {
                     // Note: Currently no support for ZSL mode
                     destBuf.format = HAL_PIXEL_FORMAT_RGB_888;
@@ -1159,20 +1138,22 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
         sp<Fence> bufferAcquireFence = new Fence(srcBuf.acquire_fence);
         res = bufferAcquireFence->wait(kFenceTimeoutMs);
         if (res == TIMED_OUT) {
-            ALOGV("%s: Request %d: Buffer %zu: Fence timed out after %d ms", __FUNCTION__,
+            ALOGE("%s: Request %d: Buffer %zu: Fence timed out after %d ms", __FUNCTION__,
                   frameNumber, i, kFenceTimeoutMs);
         }
         if (res == OK) {
             // Lock buffer for writing
-            if (srcBuf.stream->format == HAL_PIXEL_FORMAT_YCbCr_420_888) {
-                if (destBuf.format == HAL_PIXEL_FORMAT_YCbCr_420_888) {
+            if (srcBuf.stream->format == HAL_PIXEL_FORMAT_YCbCr_420_888 ||
+                srcBuf.stream->format == HAL_PIXEL_FORMAT_YCrCb_420_SP) {
+                if (destBuf.format == HAL_PIXEL_FORMAT_YCbCr_420_888 ||
+                    destBuf.format == HAL_PIXEL_FORMAT_YCrCb_420_SP) {
                     android_ycbcr ycbcr = android_ycbcr();
                     bufferHandle2 = native_handle_clone(*(destBuf.buffer));
 #ifdef GRALLOC_MAPPER4
                     res = GrallocModule::getInstance().importBuffer(bufferHandle2, &bufferHandle1);
                     //res = GrallocModule::getInstance().importBuffer(*(destBuf.buffer), &bufferHandle1);
                     if (res!= OK) {
-                      //  ALOGV("%s: Gralloc importBuffer failed",__FUNCTION__);
+                        ALOGV("%s: Gralloc importBuffer failed",__FUNCTION__);
                     }
                     res = GrallocModule::getInstance().lock_ycbcr(bufferHandle2,
                     //res = GrallocModule::getInstance().lock_ycbcr(bufferHandle1,
@@ -1189,7 +1170,7 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
                                                                   destBuf.height, &ycbcr);
                     destBuf.img = static_cast<uint8_t *>(ycbcr.y);
                 } else {
-                    ALOGV("Unexpected private format for flexible YUV: 0x%x", destBuf.format);
+                    ALOGE("Unexpected private format for flexible YUV: 0x%x", destBuf.format);
                     res = INVALID_OPERATION;
                 }
             } else {
@@ -1216,10 +1197,10 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
                                                         (void **)&(destBuf.img));
             }
             if (res != OK) {
-                ALOGV("%s: Request %d: Buffer %zu: Unable to lock buffer", __FUNCTION__,
+                ALOGE("%s: Request %d: Buffer %zu: Unable to lock buffer", __FUNCTION__,
                       frameNumber, i);
             } else {
-                ALOGV(" %s, stream format 0x%x width %d height %d buffer 0x%p img 0x%p",
+                ALOGVV(" %s, stream format 0x%x width %d height %d buffer 0x%p img 0x%p",
                        __FUNCTION__, destBuf.format, destBuf.width, destBuf.height, destBuf.buffer,
                        destBuf.img);
             }
@@ -1261,13 +1242,13 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
     if (needJpeg) {
         bool ready = mJpegCompressor->waitForDone(kJpegTimeoutNs);
         if (!ready) {
-            ALOGV("%s: Timeout waiting for JPEG compression to complete!", __FUNCTION__);
+            ALOGE("%s: Timeout waiting for JPEG compression to complete!", __FUNCTION__);
             res = NO_INIT;
             goto out;
         }
         res = mJpegCompressor->reserve();
         if (res != OK) {
-            ALOGV("%s: Error managing JPEG compressor resources, can't reserve it!", __FUNCTION__);
+            ALOGE("%s: Error managing JPEG compressor resources, can't reserve it!", __FUNCTION__);
             res = NO_INIT;
             goto out;
         }
@@ -1278,7 +1259,7 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
      */
     res = mReadoutThread->waitForReadout();
     if (res != OK) {
-        ALOGV("%s: Timeout waiting for previous requests to complete!", __FUNCTION__);
+        ALOGE("%s: Timeout waiting for previous requests to complete!", __FUNCTION__);
         res = NO_INIT;
         goto out;
     }
@@ -1294,7 +1275,7 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
             goto out;
         }
         if (syncTimeoutCount == kMaxSyncTimeoutCount) {
-            ALOGV("%s: Request %d: Sensor sync timed out after %" PRId64 " ms", __FUNCTION__,
+            ALOGE("%s: Request %d: Sensor sync timed out after %" PRId64 " ms", __FUNCTION__,
                   frameNumber, kSyncWaitTimeout * kMaxSyncTimeoutCount / 1000000);
             res = NO_INIT;
             goto out;
@@ -1317,7 +1298,7 @@ status_t VirtualFakeCamera3::processCaptureRequest(camera3_capture_request *requ
     r.buffers = buffers;
 
     mReadoutThread->queueCaptureRequest(r);
-    ALOGV("%s: Queued frame %d", __FUNCTION__, request->frame_number);
+    ALOGVV("%s: Queued frame %d", __FUNCTION__, request->frame_number);
 
     // Cache the settings for next time
     mPrevSettings.acquire(settings);
@@ -1330,7 +1311,7 @@ out:
 }
 
 status_t VirtualFakeCamera3::flush() {
-    ALOGV("%s: Not implemented; ignored", __FUNCTION__);
+    ALOGVV("%s: Not implemented; ignored", __FUNCTION__);
     return OK;
 }
 
@@ -1361,7 +1342,7 @@ status_t VirtualFakeCamera3::getCameraCapabilities() {
             cap = strtok_r(NULL, " ,", &saveptr);
         }
         if (mCapabilities.size() == 0) {
-            ALOGV("remote.sf.back_camera_caps had no valid capabilities: %s", prop);
+            ALOGE("remote.sf.back_camera_caps had no valid capabilities: %s", prop);
         }
     }
     // Default to FULL_LEVEL plus RAW if nothing is defined
@@ -1431,7 +1412,7 @@ status_t VirtualFakeCamera3::constructStaticInfo() {
     status_t res;
     int32_t width = 0, height = 0;
 
-    ALOGV("%s: Updating metadata for Camera %d", __func__, mCameraID);
+    ALOGVV("%s: Updating metadata for Camera %d", __func__, mCameraID);
 
     // Setting the max supported Camera resolution.
     setMaxSupportedResolution();
@@ -1640,6 +1621,7 @@ status_t VirtualFakeCamera3::constructStaticInfo() {
         720,
         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
     };
+
     const std::vector<int32_t> availableStreamConfigurations720p = {
         HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED,
         640,
@@ -1821,6 +1803,7 @@ status_t VirtualFakeCamera3::constructStaticInfo() {
         240,
         Sensor::kFrameDurationRange[0],
     };
+
     const std::vector<int64_t> availableMinFrameDurationsRaw = {
         HAL_PIXEL_FORMAT_RAW16,
         width,
@@ -2368,7 +2351,7 @@ status_t VirtualFakeCamera3::process3A(CameraMetadata &settings) {
 
     e = settings.find(ANDROID_CONTROL_MODE);
     if (e.count == 0) {
-        ALOGV("%s: No control mode entry!", __FUNCTION__);
+        ALOGE("%s: No control mode entry!", __FUNCTION__);
         return BAD_VALUE;
     }
     uint8_t controlMode = e.data.u8[0];
@@ -2384,13 +2367,13 @@ status_t VirtualFakeCamera3::process3A(CameraMetadata &settings) {
         return OK;
     } else if (controlMode == ANDROID_CONTROL_MODE_USE_SCENE_MODE) {
         if (!hasCapability(BACKWARD_COMPATIBLE)) {
-            ALOGV("%s: Can't use scene mode when BACKWARD_COMPATIBLE not supported!", __FUNCTION__);
+            ALOGE("%s: Can't use scene mode when BACKWARD_COMPATIBLE not supported!", __FUNCTION__);
             return BAD_VALUE;
         }
 
         e = settings.find(ANDROID_CONTROL_SCENE_MODE);
         if (e.count == 0) {
-            ALOGV("%s: No scene mode entry!", __FUNCTION__);
+            ALOGE("%s: No scene mode entry!", __FUNCTION__);
             return BAD_VALUE;
         }
         uint8_t sceneMode = e.data.u8[0];
@@ -2400,7 +2383,7 @@ status_t VirtualFakeCamera3::process3A(CameraMetadata &settings) {
                 mFacePriority = true;
                 break;
             default:
-                ALOGV("%s: Emulator doesn't support scene mode %d", __FUNCTION__, sceneMode);
+                ALOGE("%s: Emulator doesn't support scene mode %d", __FUNCTION__, sceneMode);
                 return BAD_VALUE;
         }
     } else {
@@ -2428,7 +2411,7 @@ status_t VirtualFakeCamera3::doFakeAE(CameraMetadata &settings) {
 
     e = settings.find(ANDROID_CONTROL_AE_MODE);
     if (e.count == 0 && hasCapability(BACKWARD_COMPATIBLE)) {
-        ALOGV("%s: No AE mode entry!", __FUNCTION__);
+        ALOGE("%s: No AE mode entry!", __FUNCTION__);
         return BAD_VALUE;
     }
     uint8_t aeMode = (e.count > 0) ? e.data.u8[0] : (uint8_t)ANDROID_CONTROL_AE_MODE_ON;
@@ -2524,7 +2507,7 @@ status_t VirtualFakeCamera3::doFakeAE(CameraMetadata &settings) {
                 mAeCounter = 0;
                 break;
             default:
-                ALOGV("%s: Emulator in unexpected AE state %d", __FUNCTION__, mAeState);
+                ALOGE("%s: Emulator in unexpected AE state %d", __FUNCTION__, mAeState);
                 return INVALID_OPERATION;
         }
     } else {
@@ -2540,7 +2523,7 @@ status_t VirtualFakeCamera3::doFakeAF(CameraMetadata &settings) {
 
     e = settings.find(ANDROID_CONTROL_AF_MODE);
     if (e.count == 0 && hasCapability(BACKWARD_COMPATIBLE)) {
-        ALOGV("%s: No AF mode entry!", __FUNCTION__);
+        ALOGE("%s: No AF mode entry!", __FUNCTION__);
         return BAD_VALUE;
     }
     uint8_t afMode = (e.count > 0) ? e.data.u8[0] : (uint8_t)ANDROID_CONTROL_AF_MODE_OFF;
@@ -2572,7 +2555,7 @@ status_t VirtualFakeCamera3::doFakeAF(CameraMetadata &settings) {
             }
             break;
         default:
-            ALOGV("%s: Emulator doesn't support AF mode %d", __FUNCTION__, afMode);
+            ALOGE("%s: Emulator doesn't support AF mode %d", __FUNCTION__, afMode);
             return BAD_VALUE;
     }
 
@@ -2597,12 +2580,12 @@ status_t VirtualFakeCamera3::doFakeAF(CameraMetadata &settings) {
             // Cancel trigger always transitions into INACTIVE
             mAfState = ANDROID_CONTROL_AF_STATE_INACTIVE;
 
-            ALOGV("%s: AF State transition to STATE_INACTIVE", __FUNCTION__);
+            ALOGVV("%s: AF State transition to STATE_INACTIVE", __FUNCTION__);
 
             // Stay in 'inactive' until at least next frame
             return OK;
         default:
-            ALOGV("%s: Unknown af trigger value %d", __FUNCTION__, afTrigger);
+            ALOGE("%s: Unknown af trigger value %d", __FUNCTION__, afTrigger);
             return BAD_VALUE;
     }
 
@@ -2719,7 +2702,7 @@ status_t VirtualFakeCamera3::doFakeAF(CameraMetadata &settings) {
             }
             break;
         default:
-            ALOGV("%s: Bad af state %d", __FUNCTION__, mAfState);
+            ALOGE("%s: Bad af state %d", __FUNCTION__, mAfState);
     }
 
     {
@@ -2734,7 +2717,7 @@ status_t VirtualFakeCamera3::doFakeAF(CameraMetadata &settings) {
         };
         camera_metadata_enum_snprint(ANDROID_CONTROL_AF_STATE, mAfState, afNewStateString,
                                      sizeof(afNewStateString));
-        ALOGV("%s: AF state transitioned from %s to %s", __FUNCTION__, afStateString,
+        ALOGVV("%s: AF state transitioned from %s to %s", __FUNCTION__, afStateString,
                afNewStateString);
     }
 
@@ -2746,7 +2729,7 @@ status_t VirtualFakeCamera3::doFakeAWB(CameraMetadata &settings) {
 
     e = settings.find(ANDROID_CONTROL_AWB_MODE);
     if (e.count == 0 && hasCapability(BACKWARD_COMPATIBLE)) {
-        ALOGV("%s: No AWB mode entry!", __FUNCTION__);
+        ALOGE("%s: No AWB mode entry!", __FUNCTION__);
         return BAD_VALUE;
     }
     uint8_t awbMode = (e.count > 0) ? e.data.u8[0] : (uint8_t)ANDROID_CONTROL_AWB_MODE_AUTO;
@@ -2770,7 +2753,7 @@ status_t VirtualFakeCamera3::doFakeAWB(CameraMetadata &settings) {
                 awbLocked ? ANDROID_CONTROL_AWB_STATE_LOCKED : ANDROID_CONTROL_AWB_STATE_CONVERGED;
             break;
         default:
-            ALOGV("%s: Emulator doesn't support AWB mode %d", __FUNCTION__, awbMode);
+            ALOGE("%s: Emulator doesn't support AWB mode %d", __FUNCTION__, awbMode);
             return BAD_VALUE;
     }
 
@@ -2854,7 +2837,7 @@ void VirtualFakeCamera3::signalReadoutIdle() {
 void VirtualFakeCamera3::onSensorEvent(uint32_t frameNumber, Event e, nsecs_t timestamp) {
     switch (e) {
         case Sensor::SensorListener::EXPOSURE_START: {
-            //          ALOGV("%s: Frame %d: Sensor started exposure at %lld",
+            //          ALOGVV("%s: Frame %d: Sensor started exposure at %lld",
             //               __FUNCTION__, frameNumber, timestamp);
             // Trigger shutter notify to framework
             camera3_notify_msg_t msg;
@@ -2907,11 +2890,11 @@ status_t VirtualFakeCamera3::ReadoutThread::waitForReadout() {
     while (mInFlightQueue.size() >= kMaxQueueSize) {
         res = mInFlightSignal.waitRelative(mLock, kWaitPerLoop);
         if (res != OK && res != TIMED_OUT) {
-            ALOGV("%s: Error waiting for in-flight queue to shrink", __FUNCTION__);
+            ALOGE("%s: Error waiting for in-flight queue to shrink", __FUNCTION__);
             return INVALID_OPERATION;
         }
         if (loopCount == kMaxWaitLoops) {
-            ALOGV("%s: Timed out waiting for in-flight queue to shrink", __FUNCTION__);
+            ALOGE("%s: Timed out waiting for in-flight queue to shrink", __FUNCTION__);
             return TIMED_OUT;
         }
         loopCount++;
@@ -2922,7 +2905,7 @@ status_t VirtualFakeCamera3::ReadoutThread::waitForReadout() {
 bool VirtualFakeCamera3::ReadoutThread::threadLoop() {
     status_t res = NO_ERROR;
 
-    ALOGV("%s: ReadoutThread waiting for request", __FUNCTION__);
+    ALOGVV("%s: ReadoutThread waiting for request", __FUNCTION__);
 
     // First wait for a request from the in-flight queue
 
@@ -2931,10 +2914,10 @@ bool VirtualFakeCamera3::ReadoutThread::threadLoop() {
         if (mInFlightQueue.empty()) {
             res = mInFlightSignal.waitRelative(mLock, kWaitPerLoop);
             if (res == TIMED_OUT) {
-                ALOGV("%s: ReadoutThread: Timed out waiting for request", __FUNCTION__);
+                ALOGVV("%s: ReadoutThread: Timed out waiting for request", __FUNCTION__);
                 return true;
             } else if (res != NO_ERROR) {
-                ALOGV("%s: Error waiting for capture requests: %d", __FUNCTION__, res);
+                ALOGE("%s: Error waiting for capture requests: %d", __FUNCTION__, res);
                 return false;
             }
         }
@@ -2945,20 +2928,20 @@ bool VirtualFakeCamera3::ReadoutThread::threadLoop() {
         mInFlightQueue.erase(mInFlightQueue.begin());
         mInFlightSignal.signal();
         mThreadActive = true;
-        ALOGV("%s: Beginning readout of frame %d", __FUNCTION__, mCurrentRequest.frameNumber);
+        ALOGVV("%s: Beginning readout of frame %d", __FUNCTION__, mCurrentRequest.frameNumber);
     }
 
     // Then wait for it to be delivered from the sensor
-    ALOGV("%s: ReadoutThread: Wait for frame to be delivered from sensor", __FUNCTION__);
+    ALOGVV("%s: ReadoutThread: Wait for frame to be delivered from sensor", __FUNCTION__);
 
     nsecs_t captureTime;
     bool gotFrame = mParent->mSensor->waitForNewFrame(kWaitPerLoop, &captureTime);
     if (!gotFrame) {
-        ALOGV("%s: ReadoutThread: Timed out waiting for sensor frame", __FUNCTION__);
+        ALOGVV("%s: ReadoutThread: Timed out waiting for sensor frame", __FUNCTION__);
         return true;
     }
 
-    //     ALOGV("Sensor done with readout for frame %d, captured at %lld ",
+    //     ALOGVV("Sensor done with readout for frame %d, captured at %lld ",
     //          mCurrentRequest.frameNumber, captureTime);
 
     // Check if we need to JPEG encode a buffer, and send it for async
@@ -2984,7 +2967,7 @@ bool VirtualFakeCamera3::ReadoutThread::threadLoop() {
             }
             if (goodBuffer) {
                 needJpeg = true;
-                ALOGV("Sensor done with readout for frame %d, needJpeg = %d",
+                ALOGVV("Sensor done with readout for frame %d, needJpeg = %d",
                        mCurrentRequest.frameNumber, needJpeg);
 
                 mJpegHalBuffer = *buf;
@@ -2996,7 +2979,7 @@ bool VirtualFakeCamera3::ReadoutThread::threadLoop() {
 
                 continue;
             }
-            ALOGV("%s: Error compressing output buffer: %s (%d)", __FUNCTION__, strerror(-res),
+            ALOGE("%s: Error compressing output buffer: %s (%d)", __FUNCTION__, strerror(-res),
                   res);
             // fallthrough for cleanup
         }
@@ -3073,7 +3056,7 @@ bool VirtualFakeCamera3::ReadoutThread::threadLoop() {
     if (signalIdle) mParent->signalReadoutIdle();
 
     // Send it off to the framework
-    ALOGV("%s: ReadoutThread: Send result to framework", __FUNCTION__);
+    ALOGVV("%s: ReadoutThread: Send result to framework", __FUNCTION__);
     mParent->sendCaptureResult(&result);
 
     // Clean up
@@ -3110,7 +3093,7 @@ void VirtualFakeCamera3::ReadoutThread::onJpegDone(const StreamBuffer &jpegBuffe
     result.partial_result = 0;
 
     if (!success) {
-        ALOGV(
+        ALOGE(
             "%s: Compression failure, returning error state buffer to"
             " framework",
             __FUNCTION__);
@@ -3124,7 +3107,7 @@ void VirtualFakeCamera3::ReadoutThread::onJpegDone(const StreamBuffer &jpegBuffe
 void VirtualFakeCamera3::ReadoutThread::onJpegInputDone(const StreamBuffer &inputBuffer) {
     // Should never get here, since the input buffer has to be returned
     // by end of processCaptureRequest
-    ALOGV("%s: Unexpected input buffer from JPEG compressor!", __FUNCTION__);
+    ALOGE("%s: Unexpected input buffer from JPEG compressor!", __FUNCTION__);
 }
 
 };  // namespace android
diff --git a/src/fake-pipeline2/Sensor.cpp b/src/fake-pipeline2/Sensor.cpp
index 6a98bfa..2877074 100644
--- a/src/fake-pipeline2/Sensor.cpp
+++ b/src/fake-pipeline2/Sensor.cpp
@@ -131,10 +131,8 @@ Sensor::Sensor(uint32_t width, uint32_t height)
 {
     // Max supported resolution of the camera sensor.
     // It is based on client camera capability info.
-    //mSrcWidth = width;
-    //mSrcHeight = height;
-    mSrcWidth = 640;
-    mSrcHeight = 480;
+    mSrcWidth = width;
+    mSrcHeight = height;
     mSrcFrameSize = mSrcWidth * mSrcHeight * BPP_NV12;
 }
 
@@ -333,7 +331,6 @@ bool Sensor::threadLoop() {
     uint32_t gain;
     Buffers *nextBuffers;
     uint32_t frameNumber;
-    bool needJpeg = false;
     ALOGVV("Sensor Thread stage E :1");
     SensorListener *listener = nullptr;
     {
@@ -443,24 +440,20 @@ bool Sensor::threadLoop() {
                         bAux.streamId = 0;
                         bAux.width = b.width;
                         bAux.height = b.height;
-                        bAux.format =
-                            HAL_PIXEL_FORMAT_YCbCr_420_888;
+                        bAux.format = HAL_PIXEL_FORMAT_YCrCb_420_SP;
                         bAux.stride = b.width;
                         bAux.buffer = nullptr;
                         bAux.img = new uint8_t[b.width * b.height * 3];
-                        needJpeg = true;
                         mNextCapturedBuffers->push_back(bAux);
                     } else {
                         captureDepthCloud(b.img);
                     }
                     break;
+                case HAL_PIXEL_FORMAT_YCrCb_420_SP:
+                    captureNV21(b.img, gain, b.width, b.height);
+                    break;
                 case HAL_PIXEL_FORMAT_YCbCr_420_888:
-                    if (!needJpeg) {
-                        captureNV12(b.img, gain, b.width, b.height);
-                    } else {
-                        needJpeg = false;
-                        captureJPEG(b.img, gain, b.width, b.height);
-                    }
+                    captureNV12(b.img, gain, b.width, b.height);
                     break;
                 case HAL_PIXEL_FORMAT_YV12:
                     // TODO:
@@ -495,7 +488,6 @@ bool Sensor::threadLoop() {
     }
 
     ALOGVV("Sensor Thread stage X :4");
-    ClientVideoBuffer *handle = ClientVideoBuffer::getClientInstance();
     ALOGVV("Frame No: %d took %d ms, target %d ms", frameNumber,
            (int)(workDoneRealTime - startRealTime) / 1000000, (int)(frameDuration / 1000000));
     return true;
@@ -1054,7 +1046,7 @@ void Sensor::captureNV12(uint8_t *img, uint32_t gain, uint32_t width, uint32_t h
     ALOGVV(LOG_TAG " %s: Captured NV12 image sucessfully..", __FUNCTION__);
 }
 
-void Sensor::captureJPEG(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height) {
+void Sensor::captureNV21(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height) {
     ALOGVV("%s: E", __FUNCTION__);
 
     ClientVideoBuffer *handle = ClientVideoBuffer::getClientInstance();
@@ -1068,50 +1060,40 @@ void Sensor::captureJPEG(uint8_t *img, uint32_t gain, uint32_t width, uint32_t h
     int src_size = mSrcWidth * mSrcHeight;
     int dstFrameSize = width * height;
 
-    int out_size;
+    int cameraInputDataSize;
 
     if (!gIsInFrameI420 && !gIsInFrameH264) {
-	ALOGE("%s Exit - only H264, I420 input frames supported", __FUNCTION__);
-	return;
-    }
-
-    //TODO: handle other resolutions as required
-    if (width == 320 && height == 240) {
-        mDstJpegBufSize = FRAME_SIZE_240P;
-    } else if (width == 640 && height == 480) {
-        mDstJpegBufSize = FRAME_SIZE_480P;
-    } else {
-        //TODO: adjust default
-        mDstJpegBufSize = FRAME_SIZE_480P;
+        ALOGE("%s Exit - only H264, H265, I420 input frames supported", __FUNCTION__);
+        return;
     }
 
-    //Initialize to the size based on resolution.
-    out_size = mDstJpegBufSize;
+    // Initialize the input data size based on client camera resolution.
+    cameraInputDataSize = mSrcFrameSize;
 
 #ifdef ENABLE_FFMPEG
     if (gIsInFrameH264) {
         if (handle->clientBuf[handle->clientRevCount % 1].decoded) {
-	   //Note: bufData already assigned in the function start
-	   ALOGVV("%s - Already Decoded", __FUNCTION__);
-	   out_size = mDstJpegBufSize;
-	} else {
-	   getNV12Frames(bufData, &out_size);
-	   handle->clientBuf[handle->clientRevCount % 1].decoded = true;
-	   ALOGVV("%s - getNV12Framesout_size: %d\n", __func__, out_size);
-	   std::unique_lock<std::mutex> ulock(client_buf_mutex);
-	   handle->decodedFrameNo++;
-	   ALOGVV("%s Decoded frame #[%zd]", __FUNCTION__, handle->decodedFrameNo);
-	   ulock.unlock();
-	}
+            // If already decoded camera input frame.
+            ALOGVV("%s - Already Decoded Camera Input frame", __FUNCTION__);
+        } else {
+            // To get the decoded frame.
+            getNV12Frames(bufData, &cameraInputDataSize);
+            handle->clientBuf[handle->clientRevCount % 1].decoded = true;
+            std::unique_lock<std::mutex> ulock(client_buf_mutex);
+            handle->decodedFrameNo++;
+            ALOGVV("%s Decoded Camera Input Frame No: %zd with size of %d", __FUNCTION__,
+                   handle->decodedFrameNo, cameraInputDataSize);
+            ulock.unlock();
+        }
     }
 #endif
 
     //For default resolution 640x480p
     if (width == (uint32_t)mSrcWidth && height == (uint32_t)mSrcHeight) {
-	//For I420 input
+        // For I420 input
         if (gIsInFrameI420) {
-            ALOGVV(LOG_TAG "%s: I420 input without scaling required Size = %dx%d for JPEG conversion",
-			    __FUNCTION__, width, height);
+            ALOGVV(LOG_TAG "%s: I420 to NV21 conversion without scaling: Size = %dx%d",
+                   __FUNCTION__, width, height);
 
             const uint8_t *src_y = bufData;
             int src_stride_y = mSrcWidth;
@@ -1131,8 +1113,8 @@ void Sensor::captureJPEG(uint8_t *img, uint32_t gain, uint32_t width, uint32_t h
             }
             // For NV12 input
         } else {
-	    ALOGVV(LOG_TAG "%s: NV12 to NV21 conversion for JPEG conversion: Size = %dx%d",
-			   __FUNCTION__, width, height);
+            ALOGVV(LOG_TAG "%s: NV12 to NV21 conversion without scaling: Size = %dx%d",
+                   __FUNCTION__, width, height);
 
             const uint8_t *src_y = bufData;
             int src_stride_y = mSrcWidth;
@@ -1146,10 +1128,10 @@ void Sensor::captureJPEG(uint8_t *img, uint32_t gain, uint32_t width, uint32_t h
             uint8_t *dst_v = mDstJpegBuf.data() + src_size + src_size / 4;
             int dst_stride_v = mSrcWidth >> 1;
 
-	    if (int ret = libyuv::NV12ToI420(src_y, src_stride_y, src_uv, src_stride_uv,
-				             dst_y,dst_stride_y, dst_u, dst_stride_u, dst_v, dst_stride_v,
-					     mSrcWidth, mSrcHeight)) {
-	    }
+            if (int ret = libyuv::NV12ToI420(src_y, src_stride_y, src_uv, src_stride_uv, dst_y,
+                                             dst_stride_y, dst_u, dst_stride_u, dst_v, dst_stride_v,
+                                             mSrcWidth, mSrcHeight)) {
+            }
 
             src_y = mDstJpegBuf.data();
             src_stride_y = mSrcWidth;
@@ -1172,8 +1154,8 @@ void Sensor::captureJPEG(uint8_t *img, uint32_t gain, uint32_t width, uint32_t h
     } else {
         // For I420 input
         if (gIsInFrameI420) {
-	    ALOGVV(LOG_TAG "%s: I420 with scaling: Size = %dx%d for JPEG conversion",
-			    __FUNCTION__, width, height);
+            ALOGVV(LOG_TAG "%s: I420 to NV21 with scaling: Size = %dx%d", __FUNCTION__, width,
+                   height);
 
             const uint8_t *src_y = bufData;
             int src_stride_y = mSrcWidth;
@@ -1194,33 +1176,32 @@ void Sensor::captureJPEG(uint8_t *img, uint32_t gain, uint32_t width, uint32_t h
             int dst_height = height;
             auto filtering = libyuv::kFilterNone;
 
-	    if (int ret = libyuv::I420Scale(src_y, src_stride_y, src_u, src_stride_u, src_v,
-				            src_stride_v, src_width, src_height, dst_y,
-					    dst_stride_y, dst_u, dst_stride_u, dst_v,
-					    dst_stride_v,dst_width, dst_height, filtering)) {
-	    }
-
-	    ALOGVV("%s: I420 Scaling done for JPEG conversion", __FUNCTION__);
+            if (int ret = libyuv::I420Scale(src_y, src_stride_y, src_u, src_stride_u, src_v,
+                                            src_stride_v, src_width, src_height, dst_y,
+                                            dst_stride_y, dst_u, dst_stride_u, dst_v, dst_stride_v,
+                                            dst_width, dst_height, filtering)) {
+            }
 
-	    src_y = mDstJpegBuf.data();
-	    src_stride_y = width;
-	    src_u = mDstJpegBuf.data() + dstFrameSize;
-	    src_stride_u = width >> 1;
-	    src_v = mDstJpegBuf.data() + dstFrameSize + dstFrameSize / 4;
-	    src_stride_v = width >> 1;
-	    dst_y = img;
-	    dst_stride_y = width;
+            src_y = mDstJpegBuf.data();
+            src_stride_y = width;
+            src_u = mDstJpegBuf.data() + dstFrameSize;
+            src_stride_u = width >> 1;
+            src_v = mDstJpegBuf.data() + dstFrameSize + dstFrameSize / 4;
+            src_stride_v = width >> 1;
+            dst_y = img;
+            dst_stride_y = width;
 
             uint8_t *dst_vu = dst_y + width * height;
             int dst_stride_vu = width;
 
-	    if (int ret = libyuv::I420ToNV21(src_y, src_stride_y, src_u, src_stride_u, src_v,
-				             src_stride_v, dst_y, dst_stride_y,
-					     dst_vu, dst_stride_vu, width, height)) {
+            if (int ret = libyuv::I420ToNV21(src_y, src_stride_y, src_u, src_stride_u, src_v,
+                                             src_stride_v, dst_y, dst_stride_y, dst_vu,
+                                             dst_stride_vu, width, height)) {
             }
-	//For NV12 input
-	} else {
-	    ALOGVV(LOG_TAG "%s: NV12 input with scaling Size = %dx%d for JPEG conversion", __FUNCTION__, width, height);
+            // For NV12 input
+        } else {
+            ALOGVV(LOG_TAG "%s: NV12 to NV21 conversion with scaling: Size = %dx%d", __FUNCTION__,
+                   width, height);
 
             const uint8_t *src_y = bufData;
             int src_stride_y = mSrcWidth;
@@ -1282,7 +1263,7 @@ void Sensor::captureJPEG(uint8_t *img, uint32_t gain, uint32_t width, uint32_t h
             }
         }
     }
-    ALOGVV("%s: Successfully Converted to NV21 for JPEG Capture!!!", __FUNCTION__);
+    ALOGVV("%s: Captured NV21 image sucessfully..", __FUNCTION__);
 }
 
 void Sensor::captureDepth(uint8_t *img, uint32_t gain, uint32_t width, uint32_t height) {
-- 
2.17.1

