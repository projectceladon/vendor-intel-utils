From 853a4217331679eb76748e04cc510bec1de47af5 Mon Sep 17 00:00:00 2001
From: Marc Mao <marc.mao@intel.com>
Date: Sun, 12 Feb 2023 12:56:42 +0800
Subject: [PATCH] [WA] Port HW ASTC to DXT5 transcoding from MR19886
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Squashed commit of the following(from https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/19886):

commit 48222003d85b5d2598d95b7d8911652d766d8fde
Author: Tapani Pälli <tapani.palli@intel.com>
Date:   Wed Jan 25 09:57:50 2023 +0200

    mesa/st: support compute shader decoding of ASTC

    Signed-off-by: Tapani Pälli <tapani.palli@intel.com>

commit e86c19bca22a05201332f57b99681a6a5e45d498
Author: Tapani Pälli <tapani.palli@intel.com>
Date:   Tue Jan 24 09:46:08 2023 +0200

    mesa: add astc decoder shader template (glsl es version)

    This shader originates from Granite 3D engine and has been adapted
    to be used with Open GL and some GLSL ES specifics.

    GLSL ES adaptation:

    - remove Vulkan specifics: EXT_samplerless_texture_functions usage,
      specialization constants, push constant usage
    - inline bitextract.h
    - always DECODE_8BIT and hardcode error color (for now)
    - port to GLSL ES, required some type changes, explicit type
      conversions and setting up precisions for types

    Signed-off-by: Tapani Pälli <tapani.palli@intel.com>

commit 3ce67d34f55a40a8f8da136e54ad669d7b7f41ae
Author: Tapani Pälli <tapani.palli@intel.com>
Date:   Tue Jan 24 08:55:08 2023 +0200

    mesa/st: initialize resources for ASTC decoding

    Generates required resources for ASTC texture decoding pass.

    Partition table resources will be cached in to hash during runtime
    as one is required for each block size.

    Signed-off-by: Tapani Pälli <tapani.palli@intel.com>

commit d1d9acf046ae0b669b45f515da284d4c7377ae43
Author: Tapani Pälli <tapani.palli@intel.com>
Date:   Tue Jan 10 12:41:27 2023 +0200

    mesa/st: add astc decoder lookup tables

    Commit introduces ASTC decoding lookup tables from Granite 3D engine.

    These lookup tables will be used during transcoding by a compute
    shader in later commits when decoding ASTC textures.

    Signed-off-by: Tapani Pälli <tapani.palli@intel.com>

commit d5db28b6a64687da645caa9877da6d8ba86b59ae
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Mon Nov 14 14:42:53 2022 -0800

    mesa/st: Measure compressed fallback unmap paths

    Add code to help find performance issues. The logging is disabled by
    default.

commit 7a162f6983810bedd8d116edd2df43a6415abba7
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Thu Jul 21 17:28:22 2022 -0700

    mesa/st: Enable compute-based transcoding to DXT5

    By enabling this path, we get a 56% decrease in upload time on a texture
    upload microbenchmark. This was measured on an Ice Lake with an iris
    driver that tries to use the compressed format fallback path.

commit d36c9eaf31f01d7e11a86a763c55df81061302a4
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Mon Oct 24 16:44:03 2022 -0700

    mesa/st: Add st_texture_image_resource_level

    Returns the level of the gl_texture_image with respect to the resource
    it's allocated within. Example: returns 0 for non-finalized texture.

commit b0c2b63a39bfd35df5e1e59882a223c8da7ec0f8
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Mon Dec 12 05:12:46 2022 -0800

    mesa/st: Add st_compute_transcode_astc_to_dxt5

    Add a function to upload ASTC data, transcoding it to BC3/DXT5 in the
    process.

commit 1bfae770d10af819ccb09446b569a44f6254fc10
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Tue Oct 25 10:08:21 2022 -0700

    mesa/st: Add and use create_bc1_endpoint_ssbo

    Create and cache the SSBO used by the BC1 compute shader program.

commit 7ffd661a7cee86cab7a23afc79448b74eda31bea
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Thu Jul 21 17:02:40 2022 -0700

    mesa/st: Add get_compute_program

    Add a function to create and cache the compute programs that will be
    used to transcode ASTC to DXT5.

    Note that the error paths in st_create_context_priv may actually lead to
    segfaults if hit. I've been able to work around them by 1) moving them
    further down and 2) returning early from st_glFlush if st->pipe is NULL.
    I don't know if that's the right solution however.

commit c683e734891ab973f4252d3cc760857374dc5db5
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Fri Nov 4 09:45:10 2022 -0700

    mesa: Create _mesa_CreateShaderProgramv_impl

    Factor out the implementation of _mesa_CreateShaderProgramv so that we
    can make programs that will encode DXT5.

commit 8b1d11eb1a4bf8bcea1598298aaf411d4158ddc7
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Tue Oct 4 22:10:39 2022 -0700

    glsl: Modify the #includes in the DXT5 shaders

    1. Drop the commented out includes. Shader caching is disabled if those
       are found.

    2. Replace the active includes with "%s". Later on, we'll construct the
       final strings with vasprintf. One downside to doing this is that the
       glsl file extensions are no longer true. These files are now
       templates.

commit fc110caea22410ccfcbc0730b669720f5e5e811e
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Wed Jul 27 17:01:05 2022 -0700

    glsl: Add compute shaders to encode DXT5/BC3

    These compute shaders are from the MIT-licensed GPU compressor, Betsy.
    I have included copyright headers, inlined the __sharedOnlyBarrier macro
    definition from the "UavCrossPlatform_piece_all.glsl" header when
    applicable, and made the following changes to support GLES:

       * Conditionally disable the const keyword in the BC3 shaders
       * Make the params uniform in the BC4 shader uint2
       * Avoid implicit data type conversions in the BC3 shaders
       * Use constructors for array initialization in the BC1 shader
       * Add precision qualifiers to the BC3 shaders
       * Output to an rgba16ui image for the BC1 and BC4 shaders
       * Set the version of the BC3 shaders to 310 es

    Ref: https://github.com/darksylinc/betsy/tree/cc723dcae9

commit 2ebecbfaa1f179257479e7c469ff686e45d85bb2
Author: Nanley Chery <nanley.g.chery@intel.com>
Date:   Wed Nov 23 16:20:43 2022 -0800

    docs: Document the implicit barriers around blits

    We're going to use resource_copy_region to copy from a resource that has
    been written to with imageStore. Make it clear that this is safe.

Change-Id: I12eab16f49af380994e65358a9e958e67ecb5c14
Signed-off-by: Marc Mao <marc.mao@intel.com>
---
 docs/gallium/context.rst                      |    6 +-
 .../glsl/CrossPlatformSettings_piece_all.glsl |   98 ++
 src/compiler/glsl/astc_decoder.glsl           | 1307 +++++++++++++++++
 src/compiler/glsl/bc1.glsl                    |  544 +++++++
 src/compiler/glsl/bc4.glsl                    |  187 +++
 src/compiler/glsl/etc2_rgba_stitch.glsl       |   46 +
 src/compiler/glsl/meson.build                 |   38 +-
 src/mesa/main/shaderapi.c                     |   20 +-
 src/mesa/main/shaderapi.h                     |    4 +
 src/mesa/main/texcompress_astc_luts.cpp       |  532 +++++++
 src/mesa/main/texcompress_astc_luts.h         |  127 ++
 src/mesa/main/texcompress_astc_luts_wrap.cpp  |   72 +
 src/mesa/main/texcompress_astc_luts_wrap.h    |   62 +
 src/mesa/meson.build                          |    7 +
 src/mesa/state_tracker/st_bc1_tables.h        |  124 ++
 src/mesa/state_tracker/st_cb_texture.c        |   59 +
 src/mesa/state_tracker/st_context.c           |   16 +
 src/mesa/state_tracker/st_context.h           |    7 +
 .../state_tracker/st_texcompress_compute.c    |  842 +++++++++++
 .../state_tracker/st_texcompress_compute.h    |   51 +
 src/mesa/state_tracker/st_texture.c           |   15 +
 src/mesa/state_tracker/st_texture.h           |    7 +
 22 files changed, 4163 insertions(+), 8 deletions(-)
 create mode 100644 src/compiler/glsl/CrossPlatformSettings_piece_all.glsl
 create mode 100644 src/compiler/glsl/astc_decoder.glsl
 create mode 100644 src/compiler/glsl/bc1.glsl
 create mode 100644 src/compiler/glsl/bc4.glsl
 create mode 100644 src/compiler/glsl/etc2_rgba_stitch.glsl
 create mode 100644 src/mesa/main/texcompress_astc_luts.cpp
 create mode 100644 src/mesa/main/texcompress_astc_luts.h
 create mode 100644 src/mesa/main/texcompress_astc_luts_wrap.cpp
 create mode 100644 src/mesa/main/texcompress_astc_luts_wrap.h
 create mode 100644 src/mesa/state_tracker/st_bc1_tables.h
 create mode 100644 src/mesa/state_tracker/st_texcompress_compute.c
 create mode 100644 src/mesa/state_tracker/st_texcompress_compute.h

diff --git a/docs/gallium/context.rst b/docs/gallium/context.rst
index cb7ac1f07a9..0069170952d 100644
--- a/docs/gallium/context.rst
+++ b/docs/gallium/context.rst
@@ -665,8 +665,10 @@ Blitting
 These methods emulate classic blitter controls.
 
 These methods operate directly on ``pipe_resource`` objects, and stand
-apart from any 3D state in the context.  Blitting functionality may be
-moved to a separate abstraction at some point in the future.
+apart from any 3D state in the context. Each method is assumed to have an
+implicit memory barrier around itself. They do not need any explicit
+``memory_barrier``. Blitting functionality may be moved to a separate
+abstraction at some point in the future.
 
 ``resource_copy_region`` blits a region of a resource to a region of another
 resource, provided that both resources have the same format, or compatible
diff --git a/src/compiler/glsl/CrossPlatformSettings_piece_all.glsl b/src/compiler/glsl/CrossPlatformSettings_piece_all.glsl
new file mode 100644
index 00000000000..7ef940a1603
--- /dev/null
+++ b/src/compiler/glsl/CrossPlatformSettings_piece_all.glsl
@@ -0,0 +1,98 @@
+/*
+ * Copyright 2020-2022 Matias N. Goldberg
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+
+#define min3( a, b, c ) min( a, min( b, c ) )
+#define max3( a, b, c ) max( a, max( b, c ) )
+
+#define float2 vec2
+#define float3 vec3
+#define float4 vec4
+
+#define int2 ivec2
+#define int3 ivec3
+#define int4 ivec4
+
+#define uint2 uvec2
+#define uint3 uvec3
+#define uint4 uvec4
+
+#define float2x2 mat2
+#define float3x3 mat3
+#define float4x4 mat4
+#define ogre_float4x3 mat3x4
+
+#define ushort uint
+#define ushort3 uint3
+#define ushort4 uint4
+
+//Short used for read operations. It's an int in GLSL & HLSL. An ushort in Metal
+#define rshort int
+#define rshort2 int2
+#define rint int
+//Short used for write operations. It's an int in GLSL. An ushort in HLSL & Metal
+#define wshort2 int2
+#define wshort3 int3
+
+#define toFloat3x3( x ) mat3( x )
+#define buildFloat3x3( row0, row1, row2 ) mat3( row0, row1, row2 )
+
+#define mul( x, y ) ((x) * (y))
+#define saturate(x) clamp( (x), 0.0, 1.0 )
+#define lerp mix
+#define rsqrt inversesqrt
+#define INLINE
+#define NO_INTERPOLATION_PREFIX flat
+#define NO_INTERPOLATION_SUFFIX
+
+#define PARAMS_ARG_DECL
+#define PARAMS_ARG
+
+#define reversebits bitfieldReverse
+
+#define OGRE_Sample( tex, sampler, uv ) texture( tex, uv )
+#define OGRE_SampleLevel( tex, sampler, uv, lod ) textureLod( tex, uv, lod )
+#define OGRE_SampleArray2D( tex, sampler, uv, arrayIdx ) texture( tex, vec3( uv, arrayIdx ) )
+#define OGRE_SampleArray2DLevel( tex, sampler, uv, arrayIdx, lod ) textureLod( tex, vec3( uv, arrayIdx ), lod )
+#define OGRE_SampleArrayCubeLevel( tex, sampler, uv, arrayIdx, lod ) textureLod( tex, vec4( uv, arrayIdx ), lod )
+#define OGRE_SampleGrad( tex, sampler, uv, ddx, ddy ) textureGrad( tex, uv, ddx, ddy )
+#define OGRE_SampleArray2DGrad( tex, sampler, uv, arrayIdx, ddx, ddy ) textureGrad( tex, vec3( uv, arrayIdx ), ddx, ddy )
+#define OGRE_ddx( val ) dFdx( val )
+#define OGRE_ddy( val ) dFdy( val )
+#define OGRE_Load2D( tex, iuv, lod ) texelFetch( tex, iuv, lod )
+#define OGRE_LoadArray2D( tex, iuv, arrayIdx, lod ) texelFetch( tex, ivec3( iuv, arrayIdx ), lod )
+#define OGRE_Load2DMS( tex, iuv, subsample ) texelFetch( tex, iuv, subsample )
+
+#define OGRE_Load3D( tex, iuv, lod ) texelFetch( tex, ivec3( iuv ), lod )
+
+#define OGRE_GatherRed( tex, sampler, uv ) textureGather( tex, uv, 0 )
+#define OGRE_GatherGreen( tex, sampler, uv ) textureGather( tex, uv, 1 )
+#define OGRE_GatherBlue( tex, sampler, uv ) textureGather( tex, uv, 2 )
+
+#define bufferFetch1( buffer, idx ) texelFetch( buffer, idx ).x
+
+#define OGRE_SAMPLER_ARG_DECL( samplerName )
+#define OGRE_SAMPLER_ARG( samplerName )
+
+#define OGRE_Texture3D_float4 sampler3D
+#define OGRE_OUT_REF( declType, variableName ) out declType variableName
+#define OGRE_INOUT_REF( declType, variableName ) inout declType variableName
diff --git a/src/compiler/glsl/astc_decoder.glsl b/src/compiler/glsl/astc_decoder.glsl
new file mode 100644
index 00000000000..838229c3c2b
--- /dev/null
+++ b/src/compiler/glsl/astc_decoder.glsl
@@ -0,0 +1,1307 @@
+#version 320 es
+precision highp float;
+precision highp int;
+precision highp usamplerBuffer;
+precision highp usampler2D;
+precision highp image2D;
+precision highp uimage2D;
+
+/* Copyright (c) 2020-2022 Hans-Kristian Arntzen
+ * Copyright (c) 2022 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be
+ * included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
+ * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+layout(local_size_x = %u, local_size_y = %u, local_size_z = 4) in;
+
+#define utextureBuffer usamplerBuffer
+#define utexture2D usampler2D
+
+layout(binding = 0) uniform utextureBuffer LUTRemainingBitsToEndpointQuantizer;
+layout(binding = 1) uniform utextureBuffer LUTEndpointUnquantize;
+layout(binding = 2) uniform utextureBuffer LUTWeightQuantizer;
+layout(binding = 3) uniform utextureBuffer LUTWeightUnquantize;
+layout(binding = 4) uniform utextureBuffer LUTTritQuintDecode;
+layout(binding = 5) uniform utexture2D LUTPartitionTable;
+layout(binding = 6) uniform utexture2D PayloadInput;
+
+layout(rgba8ui, binding = 7) writeonly uniform uimage2D OutputImage;
+const bool DECODE_8BIT = true;
+
+const int MODE_LDR = 0;
+const int MODE_HDR = 1;
+const int MODE_HDR_LDR_ALPHA = 2;
+
+const uvec4 error_color = uvec4(255, 0, 255, 255);
+
+/* bitextract.h */
+int extract_bits(uvec4 payload, int offset, int bits)
+{
+        int last_offset = offset + bits - 1;
+        int result;
+
+        if (bits <= 0)
+                result = 0;
+        else if ((last_offset >> 5) == (offset >> 5))
+                result = int(bitfieldExtract(payload[offset >> 5], offset & 31, bits));
+        else
+        {
+                int first_bits = 32 - (offset & 31);
+                int result_first = int(bitfieldExtract(payload[offset >> 5], offset & 31, first_bits));
+                int result_second = int(bitfieldExtract(payload[(offset >> 5) + 1], 0, bits - first_bits));
+                result = result_first | (result_second << first_bits);
+        }
+        return result;
+}
+
+/* bitextract.h */
+int extract_bits_sign(uvec4 payload, int offset, int bits)
+{
+        int last_offset = offset + bits - 1;
+        int result;
+
+        if (bits <= 0)
+                result = 0;
+        else if ((last_offset >> 5) == (offset >> 5))
+                result = bitfieldExtract(int(payload[offset >> 5]), offset & 31, bits);
+        else
+        {
+                int first_bits = 32 - (offset & 31);
+                int result_first = int(bitfieldExtract(payload[offset >> 5], offset & 31, first_bits));
+                int result_second = bitfieldExtract(int(payload[(offset >> 5) + 1]), 0, bits - first_bits);
+                result = result_first | (result_second << first_bits);
+        }
+        return result;
+}
+
+/* bitextract.h */
+int extract_bits_reverse(uvec4 payload, int offset, int bits)
+{
+        int last_offset = offset + bits - 1;
+        int result;
+
+        if (bits <= 0)
+                result = 0;
+        else if ((last_offset >> 5) == (offset >> 5))
+                result = int(bitfieldReverse(bitfieldExtract(payload[offset >> 5], offset & 31, bits)) >> (32 - bits));
+        else
+        {
+                int first_bits = 32 - (offset & 31);
+                uint result_first = bitfieldExtract(payload[offset >> 5], offset & 31, first_bits);
+                uint result_second = bitfieldExtract(payload[(offset >> 5) + 1], 0, bits - first_bits);
+                result = int(bitfieldReverse(result_first | (result_second << first_bits)) >> (32 - bits));
+        }
+        return result;
+}
+
+void swap(inout int a, inout int b)
+{
+    int tmp = a;
+    a = b;
+    b = tmp;
+}
+
+ivec4 build_coord()
+{
+    ivec2 payload_coord = ivec2(gl_WorkGroupID.xy) * 2;
+    payload_coord.x += int(gl_LocalInvocationID.z) & 1;
+    payload_coord.y += (int(gl_LocalInvocationID.z) >> 1) & 1;
+    ivec2 coord = payload_coord * ivec2(gl_WorkGroupSize.xy);
+    coord += ivec2(gl_LocalInvocationID.xy);
+    return ivec4(coord, payload_coord);
+}
+
+ivec4 interpolate_endpoint(ivec4 ep0, ivec4 ep1, ivec4 weight, int decode_mode)
+{
+    if (decode_mode == MODE_HDR)
+    {
+        ep0 <<= 4;
+        ep1 <<= 4;
+    }
+    else if (decode_mode == MODE_HDR_LDR_ALPHA)
+    {
+        ep0.rgb <<= 4;
+        ep1.rgb <<= 4;
+        ep0.a *= 0x101;
+        ep1.a *= 0x101;
+    }
+    else if (DECODE_8BIT)
+    {
+        // This isn't quite right in all cases.
+        // In normal ASTC with sRGB, the alpha channel is supposed to
+        // be decoded as FP16,
+        // even when color components are SRGB 8-bit (?!?!?!?!).
+        // This is correct if decode_unorm8 mode is used though,
+        // for sanity, we're going to assume unorm8 decoding mode
+        // is implied when using sRGB.
+        ep0 = (ep0 << 8) | ivec4(0x80);
+        ep1 = (ep1 << 8) | ivec4(0x80);
+    }
+    else
+    {
+        ep0 *= 0x101;
+        ep1 *= 0x101;
+    }
+
+    ivec4 color = (ep0 * (64 - weight) + ep1 * weight + 32) >> 6;
+    return color;
+}
+
+bvec4 bvec_or(bvec4 a, bvec4 b)
+{
+    return bvec4(ivec4(a) | ivec4(b));
+}
+
+uint round_down_quantize_fp16(int color)
+{
+    // ASTC has a very peculiar way of converting the decoded result to FP16.
+    // 0xffff -> 1.0, and for everything else we get roundDownQuantizeFP16(vec4(c) / vec4(0x10000)).
+    int msb = findMSB(color);
+    int shamt = msb;
+    int m = ((color << 10) >> shamt) & 0x3ff;
+    int e = msb - 1;
+    uint decoded = color == 0xffff ? 0x3c00u : uint(e < 1 ? (color << 8) : (m | (e << 10)));
+    return decoded;
+}
+
+uvec4 round_down_quantize_fp16(ivec4 color)
+{
+    // ASTC has a very peculiar way of converting the decoded result to FP16.
+    // 0xffff -> 1.0, and for everything else we get roundDownQuantizeFP16(vec4(c) / vec4(0x10000)).
+    ivec4 msb = findMSB(color);
+    ivec4 shamt = msb;
+    ivec4 m = ((color << 10) >> shamt) & 0x3ff;
+    ivec4 e = msb - 1;
+    uvec4 decoded = uvec4(m | (e << 10));
+    uvec4 denorm_decode = uvec4(color << 8);
+    decoded = mix(decoded, uvec4(denorm_decode), lessThan(e, ivec4(1)));
+    decoded = mix(decoded, uvec4(0x3c00), equal(color, ivec4(0xffff)));
+    return decoded;
+}
+
+uvec4 decode_fp16(ivec4 color, int decode_mode)
+{
+    if (decode_mode != MODE_LDR)
+    {
+        // Interpret the value as FP16, but with some extra fixups along the way to make the interpolation more
+        // logarithmic (apparently). From spec:
+        ivec4 e = color >> 11;
+        ivec4 m = color & 0x7ff;
+        ivec4 mt = 4 * m - 512;
+        mt = mix(mt, ivec4(3 * m), lessThan(m, ivec4(512)));
+        mt = mix(mt, ivec4(5 * m - 2048), greaterThanEqual(m, ivec4(1536)));
+
+        ivec4 decoded = (e << 10) + (mt >> 3);
+        // +Inf or NaN are decoded to 0x7bff (max finite value).
+        decoded = mix(decoded, ivec4(0x7bff), bvec_or(greaterThan(decoded & 0x7fff, ivec4(0x7c00)), equal(decoded, ivec4(0x7c00))));
+
+        if (decode_mode == MODE_HDR_LDR_ALPHA)
+            decoded.a = int(round_down_quantize_fp16(color.a));
+
+        return uvec4(decoded);
+    }
+    else
+    {
+        return round_down_quantize_fp16(color);
+    }
+}
+
+struct BlockMode
+{
+    ivec2 weight_grid_size;
+    int weight_mode_index;
+    int num_partitions;
+    int seed;
+    int cem;
+    int config_bits;
+    int primary_config_bits;
+    bool dual_plane;
+    bool void_extent;
+};
+
+bool decode_error = false;
+
+BlockMode decode_block_mode(uvec4 payload)
+{
+    BlockMode mode;
+    mode.void_extent = (payload.x & 0x1ffu) == 0x1fcu;
+    if (mode.void_extent)
+        return mode;
+
+    mode.dual_plane = (payload.x & (1u << 10u)) != 0u;
+
+    uint higher = (payload.x >> 2u) & 3u;
+    uint lower = payload.x & 3u;
+
+    if (lower != 0u)
+    {
+        mode.weight_mode_index = int((payload.x >> 4u) & 1u);
+        mode.weight_mode_index |= int((payload.x << 1u) & 6u);
+        mode.weight_mode_index |= int((payload.x >> 6u) & 8u);
+
+        if (higher < 2u)
+        {
+            mode.weight_grid_size.x = int(bitfieldExtract(payload.x, 7, 2) + 4u + 4u * higher);
+            mode.weight_grid_size.y = int(bitfieldExtract(payload.x, 5, 2) + 2u);
+        }
+        else if (higher == 2u)
+        {
+            mode.weight_grid_size.x = int(bitfieldExtract(payload.x, 5, 2) + 2u);
+            mode.weight_grid_size.y = int(bitfieldExtract(payload.x, 7, 2) + 8u);
+        }
+        else
+        {
+            if ((payload.x & (1u << 8u)) != 0u)
+            {
+                mode.weight_grid_size.x = int(bitfieldExtract(payload.x, 7, 1) + 2u);
+                mode.weight_grid_size.y = int(bitfieldExtract(payload.x, 5, 2) + 2u);
+            }
+            else
+            {
+                mode.weight_grid_size.x = int(bitfieldExtract(payload.x, 5, 2) + 2u);
+                mode.weight_grid_size.y = int(bitfieldExtract(payload.x, 7, 1) + 6u);
+            }
+        }
+    }
+    else
+    {
+        int p3 = int(bitfieldExtract(payload.x, 9, 1));
+        int hi = int(bitfieldExtract(payload.x, 7, 2));
+        int lo = int(bitfieldExtract(payload.x, 5, 2));
+        if (hi == 0)
+        {
+            mode.weight_grid_size.x = 12;
+            mode.weight_grid_size.y = lo + 2;
+        }
+        else if (hi == 1)
+        {
+            mode.weight_grid_size.x = lo + 2;
+            mode.weight_grid_size.y = 12;
+        }
+        else if (hi == 2)
+        {
+            mode.dual_plane = false;
+            p3 = 0;
+            mode.weight_grid_size.x = lo + 6;
+            mode.weight_grid_size.y = int(bitfieldExtract(payload.x, 9, 2) + 6u);
+        }
+        else
+        {
+            if (lo == 0)
+                mode.weight_grid_size = ivec2(6, 10);
+            else if (lo == 1)
+                mode.weight_grid_size = ivec2(10, 6);
+            else
+                decode_error = true;
+        }
+
+        int p0 = int(bitfieldExtract(payload.x, 4, 1));
+        int p1 = int(bitfieldExtract(payload.x, 2, 1));
+        int p2 = int(bitfieldExtract(payload.x, 3, 1));
+        mode.weight_mode_index = p0 + (p1 << 1) + (p2 << 2) + (p3 << 3);
+    }
+
+    // 11 bits for block mode.
+    // 2 bits for partition select
+    // If partitions > 1:
+    //   4 bits CEM selector
+    //   If dual_plane:
+    //     2 bits of CCS
+    // else:
+    //   10 for partition seed
+    //   2 bits for CEM main selector
+    //   If CEM[1:0] = 00:
+    //     4 bits for CEM extra selector if all same type.
+    //   else:
+    //     (1 + 2) * num_partitions if different types.
+    //     First 4 bits are encoded next to CEM[1:0], otherwise, packed before weights.
+    //   If dual_plane:
+    //     2 bits of CCS before extra CEM bits.
+    const int CONFIG_BITS_BLOCK = 11;
+    const int CONFIG_BITS_PARTITION_MODE = 2;
+    const int CONFIG_BITS_SEED = 10;
+    const int CONFIG_BITS_PRIMARY_MULTI_CEM = 2;
+    const int CONFIG_BITS_CEM = 4;
+    const int CONFIG_BITS_EXTRA_CEM_PER_PARTITION = 3;
+    const int CONFIG_BITS_CCS = 2;
+
+    mode.num_partitions = int(bitfieldExtract(payload.x, CONFIG_BITS_BLOCK, CONFIG_BITS_PARTITION_MODE)) + 1;
+
+    if (mode.num_partitions > 1)
+    {
+        mode.seed = int(bitfieldExtract(payload.x, CONFIG_BITS_BLOCK + CONFIG_BITS_PARTITION_MODE, CONFIG_BITS_SEED));
+        mode.cem = int(bitfieldExtract(payload.x, CONFIG_BITS_BLOCK + CONFIG_BITS_PARTITION_MODE + CONFIG_BITS_SEED,
+                                       CONFIG_BITS_PRIMARY_MULTI_CEM + CONFIG_BITS_CEM));
+    }
+    else
+        mode.cem = int(bitfieldExtract(payload.x, CONFIG_BITS_BLOCK + CONFIG_BITS_PARTITION_MODE, CONFIG_BITS_CEM));
+
+    int config_bits;
+    if (mode.num_partitions > 1)
+    {
+        bool single_cem = (mode.cem & 3) == 0;
+        if (single_cem)
+        {
+            config_bits = CONFIG_BITS_BLOCK + CONFIG_BITS_PARTITION_MODE +
+                          CONFIG_BITS_SEED + CONFIG_BITS_PRIMARY_MULTI_CEM + CONFIG_BITS_CEM;
+        }
+        else
+        {
+            config_bits = CONFIG_BITS_BLOCK + CONFIG_BITS_PARTITION_MODE +
+                          CONFIG_BITS_SEED + CONFIG_BITS_PRIMARY_MULTI_CEM +
+                          CONFIG_BITS_EXTRA_CEM_PER_PARTITION * mode.num_partitions;
+        }
+    }
+    else
+    {
+        config_bits = CONFIG_BITS_BLOCK + CONFIG_BITS_PARTITION_MODE + CONFIG_BITS_CEM;
+    }
+
+    // Other config bits are packed before the weights.
+    int primary_config_bits;
+    if (mode.num_partitions > 1)
+    {
+        primary_config_bits = CONFIG_BITS_BLOCK + CONFIG_BITS_PARTITION_MODE + CONFIG_BITS_SEED +
+                              CONFIG_BITS_PRIMARY_MULTI_CEM + CONFIG_BITS_CEM;
+    }
+    else
+        primary_config_bits = config_bits;
+
+    if (mode.dual_plane)
+        config_bits += CONFIG_BITS_CCS;
+
+    // This is not allowed.
+    if (any(greaterThan(mode.weight_grid_size, ivec2(gl_WorkGroupSize.xy))))
+        decode_error = true;
+    if (mode.dual_plane && mode.num_partitions > 3)
+        decode_error = true;
+
+    mode.config_bits = config_bits;
+    mode.primary_config_bits = primary_config_bits;
+    return mode;
+}
+
+int idiv3_floor(int v)
+{
+    return (v * 0x5556) >> 16;
+}
+
+int idiv3_ceil(int v)
+{
+    return idiv3_floor(v + 2);
+}
+
+int idiv5_floor(int v)
+{
+    return (v * 0x3334) >> 16;
+}
+
+int idiv5_ceil(int v)
+{
+    return idiv5_floor(v + 4);
+}
+
+uvec4 build_bitmask(int bits)
+{
+    ivec4 num_bits = ivec4(bits, bits - 32, bits - 64, bits - 96);
+    uvec4 mask = uvec4(1) << clamp(num_bits, ivec4(0), ivec4(31));
+    mask--;
+    mask = mix(mask, uvec4(0xffffffffu), greaterThanEqual(uvec4(bits), uvec4(32, 64, 96, 128)));
+    return mask;
+}
+
+int decode_integer_sequence(uvec4 payload, int start_bit, int index, ivec3 quant)
+{
+    int ret;
+    if (quant.y != 0)
+    {
+        // Trit-decoding.
+        int block = idiv5_floor(index);
+        int offset = index - block * 5;
+        start_bit += block * (5 * quant.x + 8);
+
+        int t0_t1_offset = start_bit + (quant.x * 1 + 0);
+        int t2_t3_offset = start_bit + (quant.x * 2 + 2);
+        int t4_offset    = start_bit + (quant.x * 3 + 4);
+        int t5_t6_offset = start_bit + (quant.x * 4 + 5);
+        int t7_offset    = start_bit + (quant.x * 5 + 7);
+
+        int t = (extract_bits(payload, t0_t1_offset, 2) << 0) |
+                (extract_bits(payload, t2_t3_offset, 2) << 2) |
+                (extract_bits(payload, t4_offset, 1) << 4) |
+                (extract_bits(payload, t5_t6_offset, 2) << 5) |
+                (extract_bits(payload, t7_offset, 1) << 7);
+
+        t = int(texelFetch(LUTTritQuintDecode, t).x);
+        t = (t >> (3 * offset)) & 7;
+
+        int m_offset = offset * quant.x;
+        m_offset += idiv5_ceil(offset * 8);
+
+        if (quant.x != 0)
+        {
+            int m = extract_bits(payload, m_offset + start_bit, quant.x);
+            ret = (t << quant.x) | m;
+        }
+        else
+            ret = t;
+    }
+    else if (quant.z != 0)
+    {
+        // Quint-decoding
+        int block = idiv3_floor(index);
+        int offset = index - block * 3;
+        start_bit += block * (3 * quant.x + 7);
+
+        int q0_q1_q2_offset = start_bit + (quant.x * 1 + 0);
+        int q3_q4_offset    = start_bit + (quant.x * 2 + 3);
+        int q5_q6_offset    = start_bit + (quant.x * 3 + 5);
+
+        int q = (extract_bits(payload, q0_q1_q2_offset, 3) << 0) |
+                (extract_bits(payload, q3_q4_offset, 2) << 3) |
+                (extract_bits(payload, q5_q6_offset, 2) << 5);
+
+        q = int(texelFetch(LUTTritQuintDecode, 256 + q).x);
+        q = (q >> (3 * offset)) & 7;
+
+        int m_offset = offset * quant.x;
+        m_offset += idiv3_ceil(offset * 7);
+
+        if (quant.x != 0)
+        {
+            int m = extract_bits(payload, m_offset + start_bit, quant.x);
+            ret = (q << quant.x) | m;
+        }
+        else
+            ret = q;
+    }
+    else
+    {
+        int bit = index * quant.x;
+        ret = extract_bits(payload, start_bit + bit, quant.x);
+    }
+    return ret;
+}
+
+ivec2 normalize_coord(ivec2 pixel_coord)
+{
+    // This resolves to a compile-time constant.
+    const ivec2 D = ivec2((vec2((1024 + ivec2(gl_WorkGroupSize.xy >> 1u))) + 0.5) / vec2(gl_WorkGroupSize.xy - 1u));
+    ivec2 c = D * pixel_coord;
+    return c;
+}
+
+int decode_weight(uvec4 payload, int weight_index, ivec4 quant)
+{
+    int primary_weight = decode_integer_sequence(payload, 0, weight_index, quant.xyz);
+    primary_weight = int(texelFetch(LUTWeightUnquantize, primary_weight + quant.w).x);
+    return primary_weight;
+}
+
+int decode_weight_bilinear(uvec4 payload, ivec2 coord, int weight_resolution,
+                           int stride, int offset, ivec2 fractional, ivec4 quant)
+{
+    int index = coord.y * weight_resolution + coord.x;
+    int p00 = decode_weight(payload, stride * index + offset, quant);
+    int p10, p01, p11;
+
+    if (fractional.x != 0)
+        p10 = decode_weight(payload, stride * (index + 1) + offset, quant);
+    else
+        p10 = p00;
+
+    if (fractional.y != 0)
+    {
+        p01 = decode_weight(payload, stride * (index + weight_resolution) + offset, quant);
+        if (fractional.x != 0)
+            p11 = decode_weight(payload, stride * (index + weight_resolution + 1) + offset, quant);
+        else
+            p11 = p01;
+    }
+    else
+    {
+        p01 = p00;
+        p11 = p10;
+    }
+
+    int w11 = (fractional.x * fractional.y + 8) >> 4;
+    int w10 = fractional.x - w11;
+    int w01 = fractional.y - w11;
+    int w00 = 16 - fractional.x - fractional.y + w11;
+    return (p00 * w00 + p10 * w10 + p01 * w01 + p11 * w11 + 8) >> 4;
+}
+
+ivec4 decode_weights(uvec4 payload, BlockMode mode, ivec2 normalized_pixel, out int weight_cost_bits)
+{
+    ivec4 quant = ivec4(texelFetch(LUTWeightQuantizer, mode.weight_mode_index));
+    int num_weights = mode.weight_grid_size.x * mode.weight_grid_size.y;
+    num_weights <<= int(mode.dual_plane);
+    weight_cost_bits =
+        quant.x * num_weights +
+        idiv5_ceil(num_weights * 8 * quant.y) +
+        idiv3_ceil(num_weights * 7 * quant.z);
+
+    // Decoders must deal with error conditions and return the correct error color.
+    if (weight_cost_bits < 24 || weight_cost_bits > 96 || num_weights > 64)
+    {
+        decode_error = true;
+        return ivec4(0);
+    }
+
+    int ccs;
+    if (mode.dual_plane)
+    {
+        int extra_cem_bits = 0;
+        if ((mode.cem & 3) != 0)
+            extra_cem_bits = max(mode.num_partitions * 3 - 4, 0);
+        ccs = extract_bits(payload, 126 - weight_cost_bits - extra_cem_bits, 2);
+    }
+
+    payload = bitfieldReverse(payload);
+    payload = payload.wzyx;
+    payload &= build_bitmask(weight_cost_bits);
+
+    // Scale the normalized coordinate to weight grid.
+    ivec2 weight_pixel_fixed_point = (normalized_pixel * (mode.weight_grid_size - 1) + 32) >> 6;
+    ivec2 weight_pixel = weight_pixel_fixed_point >> 4;
+    ivec2 weight_pixel_fractional = weight_pixel_fixed_point & 0xf;
+
+    ivec4 ret;
+    int primary_weight = decode_weight_bilinear(payload, weight_pixel, mode.weight_grid_size.x,
+                                                1 << int(mode.dual_plane), 0,
+                                                weight_pixel_fractional, quant);
+    if (mode.dual_plane)
+    {
+        int secondary_weight = decode_weight_bilinear(payload, weight_pixel, mode.weight_grid_size.x,
+                                                      2, 1,
+                                                      weight_pixel_fractional, quant);
+        ret = mix(ivec4(primary_weight), ivec4(secondary_weight), equal(ivec4(ccs), ivec4(0, 1, 2, 3)));
+    }
+    else
+        ret = ivec4(primary_weight);
+
+    return ret;
+}
+
+void decode_endpoint_ldr_luma_direct(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1)
+{
+    ep0 = ivec4(ivec3(v0), 0xff);
+    ep1 = ivec4(ivec3(v1), 0xff);
+}
+
+void decode_endpoint_hdr_luma_direct(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1)
+{
+    int y0, y1;
+    if (v1 >= v0)
+    {
+        y0 = v0 << 4;
+        y1 = v1 << 4;
+    }
+    else
+    {
+        y0 = (v1 << 4) + 8;
+        y1 = (v0 << 4) - 8;
+    }
+
+    ep0 = ivec4(ivec3(y0), 0x780);
+    ep1 = ivec4(ivec3(y1), 0x780);
+}
+
+void decode_endpoint_hdr_luma_direct_small_range(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1)
+{
+    int y0, y1, d;
+
+    if ((v0 & 0x80) != 0)
+    {
+        y0 = ((v1 & 0xe0) << 4) | ((v0 & 0x7f) << 2);
+        d = (v1 & 0x1f) << 2;
+    }
+    else
+    {
+        y0 = ((v1 & 0xf0) << 4) | ((v0 & 0x7f) << 1);
+        d = (v1 & 0x0f)  << 1;
+    }
+
+    y1 = min(y0 + d, 0xfff);
+
+    ep0 = ivec4(ivec3(y0), 0x780);
+    ep1 = ivec4(ivec3(y1), 0x780);
+}
+
+void decode_endpoint_ldr_luma_base_offset(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1)
+{
+    int l0 = (v0 >> 2) | (v1 & 0xc0);
+    int l1 = l0 + (v1 & 0x3f);
+    l1 = min(l1, 0xff);
+    ep0 = ivec4(ivec3(l0), 0xff);
+    ep1 = ivec4(ivec3(l1), 0xff);
+}
+
+void decode_endpoint_ldr_luma_alpha_direct(out ivec4 ep0, out ivec4 ep1,
+    int v0, int v1, int v2, int v3)
+{
+    ep0 = ivec4(ivec3(v0), v2);
+    ep1 = ivec4(ivec3(v1), v3);
+}
+
+ivec4 blue_contract(int r, int g, int b, int a)
+{
+    ivec4 ret;
+    ret.r = (r + b) >> 1;
+    ret.g = (g + b) >> 1;
+    ret.b = b;
+    ret.a = a;
+    return ret;
+}
+
+void bit_transfer_signed(inout int a, inout int b)
+{
+    b >>= 1;
+    b |= a & 0x80;
+    a >>= 1;
+    a &= 0x3f;
+    a = bitfieldExtract(a, 0, 6);
+}
+
+void decode_endpoint_ldr_luma_alpha_base_offset(out ivec4 ep0, out ivec4 ep1,
+    int v0, int v1, int v2, int v3)
+{
+    bit_transfer_signed(v1, v0);
+    bit_transfer_signed(v3, v2);
+    int v0_v1 = clamp(v0 + v1, 0, 0xff);
+    int v2_v3 = clamp(v2 + v3, 0, 0xff);
+    v0 = clamp(v0, 0, 0xff);
+    v2 = clamp(v2, 0, 0xff);
+    ep0 = ivec4(ivec3(v0), v2);
+    ep1 = ivec4(ivec3(v0_v1), v2_v3);
+}
+
+void decode_endpoint_ldr_rgb_base_scale(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1, int v2, int v3)
+{
+    ep0 = ivec4((ivec3(v0, v1, v2) * v3) >> 8, 0xff);
+    ep1 = ivec4(v0, v1, v2, 0xff);
+}
+
+void decode_endpoint_ldr_rgb_base_scale_two_a(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1, int v2, int v3, int v4, int v5)
+{
+    ep0 = ivec4((ivec3(v0, v1, v2) * v3) >> 8, v4);
+    ep1 = ivec4(v0, v1, v2, v5);
+}
+
+void decode_endpoint_ldr_rgb_direct(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1, int v2, int v3, int v4, int v5)
+{
+    int s0 = v0 + v2 + v4;
+    int s1 = v1 + v3 + v5;
+    if (s1 >= s0)
+    {
+        ep0 = ivec4(v0, v2, v4, 0xff);
+        ep1 = ivec4(v1, v3, v5, 0xff);
+    }
+    else
+    {
+        ep0 = blue_contract(v1, v3, v5, 0xff);
+        ep1 = blue_contract(v0, v2, v4, 0xff);
+    }
+}
+
+void decode_endpoint_hdr_rgb_scale(out ivec4 ep0, out ivec4 ep1,
+    int v0, int v1, int v2, int v3)
+{
+    // Mind-numbing weird format, just copy from spec ...
+    int mode_value = ((v0 & 0xc0) >> 6) | ((v1 & 0x80) >> 5) | ((v2 & 0x80) >> 4);
+    int major_component;
+    int mode;
+
+    if ((mode_value & 0xc) != 0xc)
+    {
+        major_component = mode_value >> 2;
+        mode = mode_value & 3;
+    }
+    else if (mode_value != 0xf)
+    {
+        major_component = mode_value & 3;
+        mode = 4;
+    }
+    else
+    {
+        major_component = 0;
+        mode = 5;
+    }
+
+    int red = v0 & 0x3f;
+    int green = v1 & 0x1f;
+    int blue = v2 & 0x1f;
+    int scale = v3 & 0x1f;
+
+    int x0 = (v1 >> 6) & 1;
+    int x1 = (v1 >> 5) & 1;
+    int x2 = (v2 >> 6) & 1;
+    int x3 = (v2 >> 5) & 1;
+    int x4 = (v3 >> 7) & 1;
+    int x5 = (v3 >> 6) & 1;
+    int x6 = (v3 >> 5) & 1;
+
+    int ohm = 1 << mode;
+    if ((ohm & 0x30) != 0) green |= x0 << 6;
+    if ((ohm & 0x3a) != 0) green |= x1 << 5;
+    if ((ohm & 0x30) != 0) blue |= x2 << 6;
+    if ((ohm & 0x3a) != 0) blue |= x3 << 5;
+    if ((ohm & 0x3d) != 0) scale |= x6 << 5;
+    if ((ohm & 0x2d) != 0) scale |= x5 << 6;
+    if ((ohm & 0x04) != 0) scale |= x4 << 7;
+    if ((ohm & 0x3b) != 0) red |= x4 << 6;
+    if ((ohm & 0x04) != 0) red |= x3 << 6;
+    if ((ohm & 0x10) != 0) red |= x5 << 7;
+    if ((ohm & 0x0f) != 0) red |= x2 << 7;
+    if ((ohm & 0x05) != 0) red |= x1 << 8;
+    if ((ohm & 0x0a) != 0) red |= x0 << 8;
+    if ((ohm & 0x05) != 0) red |= x0 << 9;
+    if ((ohm & 0x02) != 0) red |= x6 << 9;
+    if ((ohm & 0x01) != 0) red |= x3 << 10;
+    if ((ohm & 0x02) != 0) red |= x5 << 10;
+
+    int shamt = max(mode, 1);
+    red <<= shamt;
+    green <<= shamt;
+    blue <<= shamt;
+    scale <<= shamt;
+
+    if (mode != 5)
+    {
+        green = red - green;
+        blue = red - blue;
+    }
+
+    if (major_component == 1)
+        swap(red, green);
+    else if (major_component == 2)
+        swap(red, blue);
+
+    ep1 = ivec4(clamp(ivec3(red, green, blue), ivec3(0), ivec3(0xfff)), 0x780);
+    ep0 = ivec4(clamp(ivec3(red, green, blue) - scale, ivec3(0), ivec3(0xfff)), 0x780);
+}
+
+void decode_endpoint_hdr_rgb_direct(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1, int v2, int v3, int v4, int v5)
+{
+    int major_component = ((v4 & 0x80) >> 7) | ((v5 & 0x80) >> 6);
+
+    if (major_component == 3)
+    {
+        ep0 = ivec4(v0 << 4, v2 << 4, (v4 & 0x7f) << 5, 0x780);
+        ep1 = ivec4(v1 << 4, v3 << 4, (v5 & 0x7f) << 5, 0x780);
+        return;
+    }
+
+    int mode = ((v1 & 0x80) >> 7) | ((v2 & 0x80) >> 6) | ((v3 & 0x80) >> 5);
+    int va = v0 | ((v1 & 0x40) << 2);
+    int vb0 = v2 & 0x3f;
+    int vb1 =  v3 & 0x3f;
+    int vc = v1 & 0x3f;
+    int vd0 = v4 & 0x7f;
+    int vd1 = v5 & 0x7f;
+
+    int d_bits = 7 - (mode & 1);
+    if ((mode & 5) == 4)
+        d_bits -= 2;
+
+    vd0 = bitfieldExtract(vd0, 0, d_bits);
+    vd1 = bitfieldExtract(vd1, 0, d_bits);
+
+    int x0 = (v2 >> 6) & 1;
+    int x1 = (v3 >> 6) & 1;
+    int x2 = (v4 >> 6) & 1;
+    int x3 = (v5 >> 6) & 1;
+    int x4 = (v4 >> 5) & 1;
+    int x5 = (v5 >> 5) & 1;
+
+    int ohm = 1 << mode;
+    if ((ohm & 0xa4) != 0) va |= x0 << 9;
+    if ((ohm & 0x08) != 0) va |= x2 << 9;
+    if ((ohm & 0x50) != 0) va |= x4 << 9;
+    if ((ohm & 0x50) != 0) va |= x5 << 10;
+    if ((ohm & 0xa0) != 0) va |= x1 << 10;
+    if ((ohm & 0xc0) != 0) va |= x2 << 11;
+
+    if ((ohm & 0x04) != 0) vc |= x1 << 6;
+    if ((ohm & 0xe8) != 0) vc |= x3 << 6;
+    if ((ohm & 0x20) != 0) vc |= x2 << 7;
+
+    if ((ohm & 0x5b) != 0) vb0 |= x0 << 6;
+    if ((ohm & 0x5b) != 0) vb1 |= x1 << 6;
+    if ((ohm & 0x12) != 0) vb0 |= x2 << 7;
+    if ((ohm & 0x12) != 0) vb1 |= x3 << 7;
+
+    int shamt = (mode >> 1) ^ 3;
+    va <<= shamt;
+    vb0 <<= shamt;
+    vb1 <<= shamt;
+    vc <<= shamt;
+    vd0 <<= shamt;
+    vd1 <<= shamt;
+
+    ep1 = ivec4(clamp(ivec3(va, va - vb0, va - vb1), ivec3(0), ivec3(0xfff)), 0x780);
+    ep0 = ivec4(clamp(ivec3(va - vc, va - vb0 - vc - vd0, va - vb1 - vc - vd1), ivec3(0), ivec3(0xfff)), 0x780);
+
+    if (major_component == 1)
+    {
+        swap(ep0.r, ep0.g);
+        swap(ep1.r, ep1.g);
+    }
+    else if (major_component == 2)
+    {
+        swap(ep0.r, ep0.b);
+        swap(ep1.r, ep1.b);
+    }
+}
+
+void decode_endpoint_ldr_rgb_base_offset(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1, int v2, int v3, int v4, int v5)
+{
+    bit_transfer_signed(v1, v0);
+    bit_transfer_signed(v3, v2);
+    bit_transfer_signed(v5, v4);
+    if (v1 + v3 + v5 >= 0)
+    {
+        ep0 = ivec4(v0, v2, v4, 0xff);
+        ep1 = ivec4(v0 + v1, v2 + v3, v4 + v5, 0xff);
+    }
+    else
+    {
+        ep0 = blue_contract(v0 + v1, v2 + v3, v4 + v5, 0xff);
+        ep1 = blue_contract(v0, v2, v4, 0xff);
+    }
+
+    ep0.rgb = clamp(ep0.rgb, ivec3(0), ivec3(0xff));
+    ep1.rgb = clamp(ep1.rgb, ivec3(0), ivec3(0xff));
+}
+
+void decode_endpoint_ldr_rgba_direct(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1, int v2, int v3,
+        int v4, int v5, int v6, int v7)
+{
+    int s0 = v0 + v2 + v4;
+    int s1 = v1 + v3 + v5;
+    if (s1 >= s0)
+    {
+        ep0 = ivec4(v0, v2, v4, v6);
+        ep1 = ivec4(v1, v3, v5, v7);
+    }
+    else
+    {
+        ep0 = blue_contract(v1, v3, v5, v7);
+        ep1 = blue_contract(v0, v2, v4, v6);
+    }
+}
+
+void decode_endpoint_ldr_rgba_base_offset(out ivec4 ep0, out ivec4 ep1,
+        int v0, int v1, int v2, int v3, int v4, int v5, int v6, int v7)
+{
+    bit_transfer_signed(v1, v0);
+    bit_transfer_signed(v3, v2);
+    bit_transfer_signed(v5, v4);
+    bit_transfer_signed(v7, v6);
+
+    if (v1 + v3 + v5 >= 0)
+    {
+        ep0 = ivec4(v0, v2, v4, v6);
+        ep1 = ivec4(v0 + v1, v2 + v3, v4 + v5, v6 + v7);
+    }
+    else
+    {
+        ep0 = blue_contract(v0 + v1, v2 + v3, v4 + v5, v6 + v7);
+        ep1 = blue_contract(v0, v2, v4, v6);
+    }
+
+    ep0 = clamp(ep0, ivec4(0), ivec4(0xff));
+    ep1 = clamp(ep1, ivec4(0), ivec4(0xff));
+}
+
+void decode_endpoint_hdr_alpha(out int ep0, out int ep1, int v6, int v7)
+{
+    int mode = ((v6 >> 7) & 1) | ((v7 >> 6) & 2);
+    v6 &= 0x7f;
+    v7 &= 0x7f;
+
+    if (mode == 3)
+    {
+        ep0 = v6 << 5;
+        ep1 = v7 << 5;
+    }
+    else
+    {
+        v6 |= (v7 << (mode + 1)) & 0x780;
+        v7 &= 0x3f >> mode;
+        v7 ^= 0x20 >> mode;
+        v7 -= 0x20 >> mode;
+        v6 <<= 4 - mode;
+        v7 <<= 4 - mode;
+        v7 += v6;
+        v7 = clamp(v7, 0, 0xfff);
+        ep0 = v6;
+        ep1 = v7;
+    }
+}
+
+void decode_endpoint(out ivec4 ep0, out ivec4 ep1, out int decode_mode,
+                     uvec4 payload, int bit_offset, ivec4 quant, int ep_mode,
+                     int base_endpoint_index, int num_endpoint_bits)
+{
+    num_endpoint_bits += bit_offset;
+    payload &= build_bitmask(num_endpoint_bits);
+
+    // Could of course use an array, but that doesn't lower nicely to indexed registers on all GPUs.
+    int v0, v1, v2, v3, v4, v5, v6, v7;
+    int num_values = 2 * ((ep_mode >> 2) + 1);
+
+#define DECODE_EP(i) \
+    int(texelFetch(LUTEndpointUnquantize, quant.w + decode_integer_sequence(payload, bit_offset, i + base_endpoint_index, quant.xyz)).x)
+
+    int hi_bits = ep_mode >> 2;
+    v0 = DECODE_EP(0);
+    v1 = DECODE_EP(1);
+
+    if (hi_bits >= 1)
+    {
+        v2 = DECODE_EP(2);
+        v3 = DECODE_EP(3);
+    }
+
+    if (hi_bits >= 2)
+    {
+        v4 = DECODE_EP(4);
+        v5 = DECODE_EP(5);
+    }
+
+    if (hi_bits >= 3)
+    {
+        v6 = DECODE_EP(6);
+        v7 = DECODE_EP(7);
+    }
+
+    switch (ep_mode)
+    {
+    case 0:
+        decode_endpoint_ldr_luma_direct(ep0, ep1,
+            v0, v1);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 1:
+        decode_endpoint_ldr_luma_base_offset(ep0, ep1,
+            v0, v1);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 2:
+        decode_endpoint_hdr_luma_direct(ep0, ep1,
+            v0, v1);
+        decode_mode = MODE_HDR;
+        break;
+
+    case 3:
+        decode_endpoint_hdr_luma_direct_small_range(ep0, ep1,
+            v0, v1);
+        decode_mode = MODE_HDR;
+        break;
+
+    case 4:
+        decode_endpoint_ldr_luma_alpha_direct(ep0, ep1,
+            v0, v1, v2, v3);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 5:
+        decode_endpoint_ldr_luma_alpha_base_offset(ep0, ep1,
+            v0, v1, v2, v3);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 6:
+        decode_endpoint_ldr_rgb_base_scale(ep0, ep1,
+            v0, v1, v2, v3);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 7:
+        decode_endpoint_hdr_rgb_scale(ep0, ep1,
+            v0, v1, v2, v3);
+        decode_mode = MODE_HDR;
+        break;
+
+    case 8:
+        decode_endpoint_ldr_rgb_direct(ep0, ep1,
+            v0, v1, v2, v3, v4, v5);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 9:
+        decode_endpoint_ldr_rgb_base_offset(ep0, ep1,
+            v0, v1, v2, v3, v4, v5);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 10:
+        decode_endpoint_ldr_rgb_base_scale_two_a(ep0, ep1,
+            v0, v1, v2, v3, v4, v5);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 11:
+    case 14:
+    case 15:
+        decode_endpoint_hdr_rgb_direct(ep0, ep1,
+            v0, v1, v2, v3, v4, v5);
+        if (ep_mode == 14)
+        {
+            ep0.a = v6;
+            ep1.a = v7;
+            decode_mode = MODE_HDR_LDR_ALPHA;
+        }
+        else if (ep_mode == 15)
+        {
+            decode_endpoint_hdr_alpha(ep0.a, ep1.a, v6, v7);
+            decode_mode = MODE_HDR;
+        }
+        else
+            decode_mode = MODE_HDR;
+        break;
+
+    case 12:
+        decode_endpoint_ldr_rgba_direct(ep0, ep1,
+            v0, v1, v2, v3, v4, v5, v6, v7);
+        decode_mode = MODE_LDR;
+        break;
+
+    case 13:
+        decode_endpoint_ldr_rgba_base_offset(ep0, ep1,
+            v0, v1, v2, v3, v4, v5, v6, v7);
+        decode_mode = MODE_LDR;
+        break;
+    }
+
+    if (DECODE_8BIT && decode_mode != MODE_LDR)
+        decode_error = true;
+}
+
+#define CHECK_DECODE_ERROR() do { \
+    if (decode_error) \
+    { \
+        emit_decode_error(coord.xy); \
+        return; \
+    } \
+} while(false)
+
+void emit_decode_error(ivec2 coord)
+{
+    imageStore(OutputImage, coord, error_color);
+}
+
+int compute_num_endpoint_pairs(int num_partitions, int cem)
+{
+    int ret;
+    if (num_partitions > 1)
+    {
+        bool single_cem = (cem & 3) == 0;
+        if (single_cem)
+            ret = ((cem >> 4) + 1) * num_partitions;
+        else
+            ret = (cem & 3) * num_partitions + bitCount(bitfieldExtract(uint(cem), 2, num_partitions));
+    }
+    else
+    {
+        ret = (cem >> 2) + 1;
+    }
+    return ret;
+}
+
+void decode_cem_base_endpoint(uvec4 payload, int weight_cost_bits, inout int cem, out int base_endpoint_index,
+    int num_partitions, int partition_index)
+{
+    if (num_partitions > 1)
+    {
+        bool single_cem = (cem & 3) == 0;
+        if (single_cem)
+        {
+            cem >>= 2;
+            base_endpoint_index = ((cem >> 2) + 1) * partition_index;
+        }
+        else
+        {
+            if (partition_index != 0)
+                base_endpoint_index = (cem & 3) * partition_index + bitCount(bitfieldExtract(uint(cem), 2, partition_index));
+            else
+                base_endpoint_index = 0;
+
+            int base_class = (cem & 3) - 1;
+            int extra_cem_bits = num_partitions * 3 - 4;
+            int extra_bits = extract_bits(payload, 128 - weight_cost_bits - extra_cem_bits, extra_cem_bits);
+            cem = (extra_bits << 4) | (cem >> 2);
+
+            int class_offset_bit = (cem >> partition_index) & 1;
+            int ep_bits = (cem >> (num_partitions + 2 * partition_index)) & 3;
+
+            cem = 4 * (base_class + class_offset_bit) + ep_bits;
+        }
+        base_endpoint_index *= 2;
+    }
+    else
+    {
+        base_endpoint_index = 0;
+    }
+}
+
+ivec4 void_extent_color(uvec4 payload, out int decode_mode)
+{
+    int min_s = extract_bits(payload, 12, 13);
+    int max_s = extract_bits(payload, 12 + 13, 13);
+    int min_t = extract_bits(payload, 12 + 2 * 13, 13);
+    int max_t = extract_bits(payload, 12 + 3 * 13, 13);
+
+    int reserved = extract_bits(payload, 10, 2);
+    if (reserved != 3)
+    {
+        decode_error = true;
+        return ivec4(0);
+    }
+
+    if (!all(equal(ivec4(min_s, max_s, min_t, max_t), ivec4((1 << 13) - 1))))
+    {
+        if (any(greaterThanEqual(ivec2(min_s, min_t), ivec2(max_s, max_t))))
+        {
+            decode_error = true;
+            return ivec4(0);
+        }
+    }
+
+    decode_mode = (payload.x & (1u << 9)) != 0u ? MODE_HDR : MODE_LDR;
+
+    int r = extract_bits(payload, 64, 16);
+    int g = extract_bits(payload, 64 + 16, 16);
+    int b = extract_bits(payload, 64 + 32, 16);
+    int a = extract_bits(payload, 64 + 48, 16);
+
+    return ivec4(r, g, b, a);
+}
+
+void main()
+{
+    ivec4 coord = build_coord();
+    if (any(greaterThanEqual(coord.xy, imageSize(OutputImage))))
+        return;
+
+    ivec2 pixel_coord = ivec2(gl_LocalInvocationID.xy);
+    int linear_pixel = int(gl_WorkGroupSize.x) * pixel_coord.y + pixel_coord.x;
+    uvec4 payload = texelFetch(PayloadInput, coord.zw, 0);
+
+    BlockMode block_mode = decode_block_mode(payload);
+    CHECK_DECODE_ERROR();
+
+    ivec4 final_color;
+    int decode_mode;
+    if (block_mode.void_extent)
+    {
+        final_color = void_extent_color(payload, decode_mode);
+        CHECK_DECODE_ERROR();
+    }
+    else
+    {
+        int weight_cost_bits;
+        ivec4 weights = decode_weights(payload, block_mode, normalize_coord(pixel_coord), weight_cost_bits);
+
+        int partition_index = 0;
+        if (block_mode.num_partitions > 1)
+        {
+            int lut_x = pixel_coord.x + int(gl_WorkGroupSize.x) * (block_mode.seed & 31);
+            int lut_y = pixel_coord.y + int(gl_WorkGroupSize.y) * (block_mode.seed >> 5);
+            partition_index = int(texelFetch(LUTPartitionTable, ivec2(lut_x, lut_y), 0).x);
+            partition_index = (partition_index >> (2 * block_mode.num_partitions - 4)) & 3;
+        }
+
+        int available_endpoint_bits = max(128 - block_mode.config_bits - weight_cost_bits, 0);
+
+        // In multi-partition mode, the 6-bit CEM field is encoded as
+        // First two bits tell if all CEM field are the same, if not we specify a class offset, and N bits
+        // after that will offset the class by 1.
+        int num_endpoint_pairs = compute_num_endpoint_pairs(block_mode.num_partitions, block_mode.cem);
+
+        // Error color must be emitted if we need more than 18 integer sequence encoded values of color.
+        if (num_endpoint_pairs > 9)
+        {
+            decode_error = true;
+            emit_decode_error(coord.xy);
+            return;
+        }
+
+        ivec4 endpoint_quant = ivec4(texelFetch(LUTRemainingBitsToEndpointQuantizer,
+                128 * (num_endpoint_pairs - 1) + available_endpoint_bits));
+
+        // Only read the bits we need for endpoints.
+        int num_endpoint_values = num_endpoint_pairs * 2;
+        available_endpoint_bits =
+            endpoint_quant.x * num_endpoint_values +
+            idiv5_ceil(endpoint_quant.y * 8 * num_endpoint_values) +
+            idiv3_ceil(endpoint_quant.z * 7 * num_endpoint_values);
+
+        // No space left for color endpoints.
+        if (all(equal(endpoint_quant.xyz, ivec3(0))))
+        {
+            decode_error = true;
+            emit_decode_error(coord.xy);
+            return;
+        }
+
+        int endpoint_bit_offset = block_mode.primary_config_bits;
+        ivec4 ep0, ep1;
+
+        // Decode CEM for multi-partition schemes.
+        int cem = block_mode.cem;
+        int base_endpoint_index;
+        decode_cem_base_endpoint(payload, weight_cost_bits, cem, base_endpoint_index,
+                                 block_mode.num_partitions, partition_index);
+
+        decode_endpoint(ep0, ep1, decode_mode, payload, endpoint_bit_offset, endpoint_quant,
+                        cem, base_endpoint_index, available_endpoint_bits);
+        CHECK_DECODE_ERROR();
+
+        final_color = interpolate_endpoint(ep0, ep1, weights, decode_mode);
+    }
+
+    if (DECODE_8BIT)
+    {
+        imageStore(OutputImage, coord.xy, uvec4(final_color >> 8));
+    }
+    else
+    {
+        uvec4 encoded;
+        if (block_mode.void_extent && decode_mode == MODE_HDR)
+            encoded = uvec4(final_color);
+        else
+            encoded = decode_fp16(final_color, decode_mode);
+        imageStore(OutputImage, coord.xy, encoded);
+    }
+}
diff --git a/src/compiler/glsl/bc1.glsl b/src/compiler/glsl/bc1.glsl
new file mode 100644
index 00000000000..251635d7b69
--- /dev/null
+++ b/src/compiler/glsl/bc1.glsl
@@ -0,0 +1,544 @@
+/*
+ * Copyright 2020-2022 Matias N. Goldberg
+ * Copyright 2022 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#version 310 es
+
+#if defined(GL_ES) && GL_ES == 1
+	// Desktop GLSL allows the const keyword for either compile-time or
+	// run-time constants. GLSL ES only allows the keyword for compile-time
+	// constants. Since we use const on run-time constants, define it to
+	// nothing.
+	#define const
+#endif
+
+%s // include "CrossPlatformSettings_piece_all.glsl"
+
+#define FLT_MAX 340282346638528859811704183484516925440.0f
+
+layout( location = 0 ) uniform uint p_numRefinements;
+
+uniform sampler2D srcTex;
+
+layout( rgba16ui ) uniform restrict writeonly mediump uimage2D dstTexture;
+
+layout( std430, binding = 1 ) readonly restrict buffer globalBuffer
+{
+	float2 c_oMatch5[256];
+	float2 c_oMatch6[256];
+};
+
+layout( local_size_x = 8,  //
+		local_size_y = 8,  //
+		local_size_z = 1 ) in;
+
+float3 rgb565to888( float rgb565 )
+{
+	float3 retVal;
+	retVal.x = floor( rgb565 / 2048.0f );
+	retVal.y = floor( mod( rgb565, 2048.0f ) / 32.0f );
+	retVal.z = floor( mod( rgb565, 32.0f ) );
+
+	// This is the correct 565 to 888 conversion:
+	//		rgb = floor( rgb * ( 255.0f / float3( 31.0f, 63.0f, 31.0f ) ) + 0.5f )
+	//
+	// However stb_dxt follows a different one:
+	//		rb = floor( rb * ( 256 / 32 + 8 / 32 ) );
+	//		g  = floor( g  * ( 256 / 64 + 4 / 64 ) );
+	//
+	// I'm not sure exactly why but it's possible this is how the S3TC specifies it should be decoded
+	// It's quite possible this is the reason:
+	//		http://www.ludicon.com/castano/blog/2009/03/gpu-dxt-decompression/
+	//
+	// Or maybe it's just because it's cheap to do with integer shifts.
+	// Anyway, we follow stb_dxt's conversion just in case
+	// (gives almost the same result, with 1 or -1 of difference for a very few values)
+	//
+	// Perhaps when we make 888 -> 565 -> 888 it doesn't matter
+	// because they end up mapping to the original number
+
+	return floor( retVal * float3( 8.25f, 4.0625f, 8.25f ) );
+}
+
+float rgb888to565( float3 rgbValue )
+{
+	rgbValue.rb = floor( rgbValue.rb * 31.0f / 255.0f + 0.5f );
+	rgbValue.g = floor( rgbValue.g * 63.0f / 255.0f + 0.5f );
+
+	return rgbValue.r * 2048.0f + rgbValue.g * 32.0f + rgbValue.b;
+}
+
+// linear interpolation at 1/3 point between a and b, using desired rounding type
+float3 lerp13( float3 a, float3 b )
+{
+#ifdef STB_DXT_USE_ROUNDING_BIAS
+	// with rounding bias
+	return a + floor( ( b - a ) * ( 1.0f / 3.0f ) + 0.5f );
+#else
+	// without rounding bias
+	return floor( ( 2.0f * a + b ) / 3.0f );
+#endif
+}
+
+/// Unpacks a block of 4 colours from two 16-bit endpoints
+void EvalColors( out float3 colours[4], float c0, float c1 )
+{
+	colours[0] = rgb565to888( c0 );
+	colours[1] = rgb565to888( c1 );
+	colours[2] = lerp13( colours[0], colours[1] );
+	colours[3] = lerp13( colours[1], colours[0] );
+}
+
+/** The color optimization function. (Clever code, part 1)
+@param outMinEndp16 [out]
+	Minimum endpoint, in RGB565
+@param outMaxEndp16 [out]
+	Maximum endpoint, in RGB565
+*/
+void OptimizeColorsBlock( const uint srcPixelsBlock[16], out float outMinEndp16, out float outMaxEndp16 )
+{
+	// determine color distribution
+	float3 avgColour;
+	float3 minColour;
+	float3 maxColour;
+
+	avgColour = minColour = maxColour = unpackUnorm4x8( srcPixelsBlock[0] ).xyz;
+	for( int i = 1; i < 16; ++i )
+	{
+		const float3 currColourUnorm = unpackUnorm4x8( srcPixelsBlock[i] ).xyz;
+		avgColour += currColourUnorm;
+		minColour = min( minColour, currColourUnorm );
+		maxColour = max( maxColour, currColourUnorm );
+	}
+
+	avgColour = round( avgColour * 255.0f / 16.0f );
+	maxColour *= 255.0f;
+	minColour *= 255.0f;
+
+	// determine covariance matrix
+	float cov[6];
+	for( int i = 0; i < 6; ++i )
+		cov[i] = 0.0f;
+
+	for( int i = 0; i < 16; ++i )
+	{
+		const float3 currColour = unpackUnorm4x8( srcPixelsBlock[i] ).xyz * 255.0f;
+		float3 rgbDiff = currColour - avgColour;
+
+		cov[0] += rgbDiff.r * rgbDiff.r;
+		cov[1] += rgbDiff.r * rgbDiff.g;
+		cov[2] += rgbDiff.r * rgbDiff.b;
+		cov[3] += rgbDiff.g * rgbDiff.g;
+		cov[4] += rgbDiff.g * rgbDiff.b;
+		cov[5] += rgbDiff.b * rgbDiff.b;
+	}
+
+	// convert covariance matrix to float, find principal axis via power iter
+	for( int i = 0; i < 6; ++i )
+		cov[i] /= 255.0f;
+
+	float3 vF = maxColour - minColour;
+
+	const int nIterPower = 4;
+	for( int iter = 0; iter < nIterPower; ++iter )
+	{
+		const float r = vF.r * cov[0] + vF.g * cov[1] + vF.b * cov[2];
+		const float g = vF.r * cov[1] + vF.g * cov[3] + vF.b * cov[4];
+		const float b = vF.r * cov[2] + vF.g * cov[4] + vF.b * cov[5];
+
+		vF.r = r;
+		vF.g = g;
+		vF.b = b;
+	}
+
+	float magn = max3( abs( vF.r ), abs( vF.g ), abs( vF.b ) );
+	float3 v;
+
+	if( magn < 4.0f )
+	{                  // too small, default to luminance
+		v.r = 299.0f;  // JPEG YCbCr luma coefs, scaled by 1000.
+		v.g = 587.0f;
+		v.b = 114.0f;
+	}
+	else
+	{
+		v = trunc( vF * ( 512.0f / magn ) );
+	}
+
+	// Pick colors at extreme points
+	float3 minEndpoint, maxEndpoint;
+	float minDot = FLT_MAX;
+	float maxDot = -FLT_MAX;
+	for( int i = 0; i < 16; ++i )
+	{
+		const float3 currColour = unpackUnorm4x8( srcPixelsBlock[i] ).xyz * 255.0f;
+		const float dotValue = dot( currColour, v );
+
+		if( dotValue < minDot )
+		{
+			minDot = dotValue;
+			minEndpoint = currColour;
+		}
+
+		if( dotValue > maxDot )
+		{
+			maxDot = dotValue;
+			maxEndpoint = currColour;
+		}
+	}
+
+	outMinEndp16 = rgb888to565( minEndpoint );
+	outMaxEndp16 = rgb888to565( maxEndpoint );
+}
+
+// The color matching function
+uint MatchColorsBlock( const uint srcPixelsBlock[16], float3 colour[4] )
+{
+	uint mask = 0u;
+	float3 dir = colour[0] - colour[1];
+	float stops[4];
+
+	for( int i = 0; i < 4; ++i )
+		stops[i] = dot( colour[i], dir );
+
+	// think of the colors as arranged on a line; project point onto that line, then choose
+	// next color out of available ones. we compute the crossover points for "best color in top
+	// half"/"best in bottom half" and then the same inside that subinterval.
+	//
+	// relying on this 1d approximation isn't always optimal in terms of euclidean distance,
+	// but it's very close and a lot faster.
+	// http://cbloomrants.blogspot.com/2008/12/12-08-08-dxtc-summary.html
+
+	float c0Point = trunc( ( stops[1] + stops[3] ) * 0.5f );
+	float halfPoint = trunc( ( stops[3] + stops[2] ) * 0.5f );
+	float c3Point = trunc( ( stops[2] + stops[0] ) * 0.5f );
+
+#ifndef BC1_DITHER
+	// the version without dithering is straightforward
+	for( uint i = 16u; i-- > 0u; )
+	{
+		const float3 currColour = unpackUnorm4x8( srcPixelsBlock[i] ).xyz * 255.0f;
+
+		const float dotValue = dot( currColour, dir );
+		mask <<= 2u;
+
+		if( dotValue < halfPoint )
+			mask |= ( ( dotValue < c0Point ) ? 1u : 3u );
+		else
+			mask |= ( ( dotValue < c3Point ) ? 2u : 0u );
+	}
+#else
+	// with floyd-steinberg dithering
+	float4 ep1 = float4( 0, 0, 0, 0 );
+	float4 ep2 = float4( 0, 0, 0, 0 );
+
+	c0Point *= 16.0f;
+	halfPoint *= 16.0f;
+	c3Point *= 16.0f;
+
+	for( uint y = 0u; y < 4u; ++y )
+	{
+		float ditherDot;
+		uint lmask, step;
+
+		float3 currColour;
+		float dotValue;
+
+		currColour = unpackUnorm4x8( srcPixelsBlock[y * 4u + 0u] ).xyz * 255.0f;
+		dotValue = dot( currColour, dir );
+
+		ditherDot = ( dotValue * 16.0f ) + ( 3.0f * ep2[1] + 5.0f * ep2[0] );
+		if( ditherDot < halfPoint )
+			step = ( ditherDot < c0Point ) ? 1u : 3u;
+		else
+			step = ( ditherDot < c3Point ) ? 2u : 0u;
+		ep1[0] = dotValue - stops[step];
+		lmask = step;
+
+		currColour = unpackUnorm4x8( srcPixelsBlock[y * 4u + 1u] ).xyz * 255.0f;
+		dotValue = dot( currColour, dir );
+
+		ditherDot = ( dotValue * 16.0f ) + ( 7.0f * ep1[0] + 3.0f * ep2[2] + 5.0f * ep2[1] + ep2[0] );
+		if( ditherDot < halfPoint )
+			step = ( ditherDot < c0Point ) ? 1u : 3u;
+		else
+			step = ( ditherDot < c3Point ) ? 2u : 0u;
+		ep1[1] = dotValue - stops[step];
+		lmask |= step << 2u;
+
+		currColour = unpackUnorm4x8( srcPixelsBlock[y * 4u + 2u] ).xyz * 255.0f;
+		dotValue = dot( currColour, dir );
+
+		ditherDot = ( dotValue * 16.0f ) + ( 7.0f * ep1[1] + 3.0f * ep2[3] + 5.0f * ep2[2] + ep2[1] );
+		if( ditherDot < halfPoint )
+			step = ( ditherDot < c0Point ) ? 1u : 3u;
+		else
+			step = ( ditherDot < c3Point ) ? 2u : 0u;
+		ep1[2] = dotValue - stops[step];
+		lmask |= step << 4u;
+
+		currColour = unpackUnorm4x8( srcPixelsBlock[y * 4u + 2u] ).xyz * 255.0f;
+		dotValue = dot( currColour, dir );
+
+		ditherDot = ( dotValue * 16.0f ) + ( 7.0f * ep1[2] + 5.0f * ep2[3] + ep2[2] );
+		if( ditherDot < halfPoint )
+			step = ( ditherDot < c0Point ) ? 1u : 3u;
+		else
+			step = ( ditherDot < c3Point ) ? 2u : 0u;
+		ep1[3] = dotValue - stops[step];
+		lmask |= step << 6u;
+
+		mask |= lmask << ( y * 8u );
+		{
+			float4 tmp = ep1;
+			ep1 = ep2;
+			ep2 = tmp;
+		}  // swap
+	}
+#endif
+
+	return mask;
+}
+
+// The refinement function. (Clever code, part 2)
+// Tries to optimize colors to suit block contents better.
+// (By solving a least squares system via normal equations+Cramer's rule)
+bool RefineBlock( const uint srcPixelsBlock[16], uint mask, inout float inOutMinEndp16,
+				  inout float inOutMaxEndp16 )
+{
+	float newMin16, newMax16;
+	const float oldMin = inOutMinEndp16;
+	const float oldMax = inOutMaxEndp16;
+
+	if( ( mask ^ ( mask << 2u ) ) < 4u )  // all pixels have the same index?
+	{
+		// yes, linear system would be singular; solve using optimal
+		// single-color match on average color
+		float3 rgbVal = float3( 8.0f / 255.0f, 8.0f / 255.0f, 8.0f / 255.0f );
+		for( int i = 0; i < 16; ++i )
+			rgbVal += unpackUnorm4x8( srcPixelsBlock[i] ).xyz;
+
+		rgbVal = floor( rgbVal * ( 255.0f / 16.0f ) );
+
+		newMax16 = c_oMatch5[uint( rgbVal.r )][0] * 2048.0f +  //
+				   c_oMatch6[uint( rgbVal.g )][0] * 32.0f +    //
+				   c_oMatch5[uint( rgbVal.b )][0];
+		newMin16 = c_oMatch5[uint( rgbVal.r )][1] * 2048.0f +  //
+				   c_oMatch6[uint( rgbVal.g )][1] * 32.0f +    //
+				   c_oMatch5[uint( rgbVal.b )][1];
+	}
+	else
+	{
+		const float w1Tab[4] = float[4]( 3.0f, 0.0f, 2.0f, 1.0f );
+		const float prods[4] = float[4]( 589824.0f, 2304.0f, 262402.0f, 66562.0f );
+		// ^some magic to save a lot of multiplies in the accumulating loop...
+		// (precomputed products of weights for least squares system, accumulated inside one 32-bit
+		// register)
+
+		float akku = 0.0f;
+		uint cm = mask;
+		float3 at1 = float3( 0, 0, 0 );
+		float3 at2 = float3( 0, 0, 0 );
+		for( int i = 0; i < 16; ++i, cm >>= 2u )
+		{
+			const float3 currColour = unpackUnorm4x8( srcPixelsBlock[i] ).xyz * 255.0f;
+
+			const uint step = cm & 3u;
+			const float w1 = w1Tab[step];
+			akku += prods[step];
+			at1 += currColour * w1;
+			at2 += currColour;
+		}
+
+		at2 = 3.0f * at2 - at1;
+
+		// extract solutions and decide solvability
+		const float xx = floor( akku / 65535.0f );
+		const float yy = floor( mod( akku, 65535.0f ) / 256.0f );
+		const float xy = mod( akku, 256.0f );
+
+		float2 f_rb_g;
+		f_rb_g.x = 3.0f * 31.0f / 255.0f / ( xx * yy - xy * xy );
+		f_rb_g.y = f_rb_g.x * 63.0f / 31.0f;
+
+		// solve.
+		const float3 newMaxVal = clamp( floor( ( at1 * yy - at2 * xy ) * f_rb_g.xyx + 0.5f ),
+										float3( 0.0f, 0.0f, 0.0f ), float3( 31, 63, 31 ) );
+		newMax16 = newMaxVal.x * 2048.0f + newMaxVal.y * 32.0f + newMaxVal.z;
+
+		const float3 newMinVal = clamp( floor( ( at2 * xx - at1 * xy ) * f_rb_g.xyx + 0.5f ),
+										float3( 0.0f, 0.0f, 0.0f ), float3( 31, 63, 31 ) );
+		newMin16 = newMinVal.x * 2048.0f + newMinVal.y * 32.0f + newMinVal.z;
+	}
+
+	inOutMinEndp16 = newMin16;
+	inOutMaxEndp16 = newMax16;
+
+	return oldMin != newMin16 || oldMax != newMax16;
+}
+
+#ifdef BC1_DITHER
+/// Quantizes 'srcValue' which is originally in 888 (full range),
+/// converting it to 565 and then back to 888 (quantized)
+float3 quant( float3 srcValue )
+{
+	srcValue = clamp( srcValue, 0.0f, 255.0f );
+	// Convert 888 -> 565
+	srcValue = floor( srcValue * float3( 31.0f / 255.0f, 63.0f / 255.0f, 31.0f / 255.0f ) + 0.5f );
+	// Convert 565 -> 888 back
+	srcValue = floor( srcValue * float3( 8.25f, 4.0625f, 8.25f ) );
+
+	return srcValue;
+}
+
+void DitherBlock( const uint srcPixBlck[16], out uint dthPixBlck[16] )
+{
+	float3 ep1[4] = float3[4]( float3( 0, 0, 0 ), float3( 0, 0, 0 ), float3( 0, 0, 0 ), float3( 0, 0, 0 ) );
+	float3 ep2[4] = float3[4]( float3( 0, 0, 0 ), float3( 0, 0, 0 ), float3( 0, 0, 0 ), float3( 0, 0, 0 ) );
+
+	for( uint y = 0u; y < 16u; y += 4u )
+	{
+		float3 srcPixel, dithPixel;
+
+		srcPixel = unpackUnorm4x8( srcPixBlck[y + 0u] ).xyz * 255.0f;
+		dithPixel = quant( srcPixel + trunc( ( 3.0f * ep2[1] + 5.0f * ep2[0] ) * ( 1.0f / 16.0f ) ) );
+		ep1[0] = srcPixel - dithPixel;
+		dthPixBlck[y + 0u] = packUnorm4x8( float4( dithPixel * ( 1.0f / 255.0f ), 1.0f ) );
+
+		srcPixel = unpackUnorm4x8( srcPixBlck[y + 1u] ).xyz * 255.0f;
+		dithPixel = quant(
+			srcPixel + trunc( ( 7.0f * ep1[0] + 3.0f * ep2[2] + 5.0f * ep2[1] + ep2[0] ) * ( 1.0f / 16.0f ) ) );
+		ep1[1] = srcPixel - dithPixel;
+		dthPixBlck[y + 1u] = packUnorm4x8( float4( dithPixel * ( 1.0f / 255.0f ), 1.0f ) );
+
+		srcPixel = unpackUnorm4x8( srcPixBlck[y + 2u] ).xyz * 255.0f;
+		dithPixel = quant(
+			srcPixel + trunc( ( 7.0f * ep1[1] + 3.0f * ep2[3] + 5.0f * ep2[2] + ep2[1] ) * ( 1.0f / 16.0f ) ) );
+		ep1[2] = srcPixel - dithPixel;
+		dthPixBlck[y + 2u] = packUnorm4x8( float4( dithPixel * ( 1.0f / 255.0f ), 1.0f ) );
+
+		srcPixel = unpackUnorm4x8( srcPixBlck[y + 3u] ).xyz * 255.0f;
+		dithPixel = quant( srcPixel + trunc( ( 7.0f * ep1[2] + 5.0f * ep2[3] + ep2[2] ) * ( 1.0f / 16.0f ) ) );
+		ep1[3] = srcPixel - dithPixel;
+		dthPixBlck[y + 3u] = packUnorm4x8( float4( dithPixel * ( 1.0f / 255.0f ), 1.0f ) );
+
+		// swap( ep1, ep2 )
+		for( uint i = 0u; i < 4u; ++i )
+		{
+			float3 tmp = ep1[i];
+			ep1[i] = ep2[i];
+			ep2[i] = tmp;
+		}
+	}
+}
+#endif
+
+void main()
+{
+	uint srcPixelsBlock[16];
+
+	bool bAllColoursEqual = true;
+
+	// Load the whole 4x4 block
+	const uint2 pixelsToLoadBase = gl_GlobalInvocationID.xy << 2u;
+	for( uint i = 0u; i < 16u; ++i )
+	{
+		const uint2 pixelsToLoad = pixelsToLoadBase + uint2( i & 0x03u, i >> 2u );
+		const float3 srcPixels0 = OGRE_Load2D( srcTex, int2( pixelsToLoad ), 0 ).xyz;
+		srcPixelsBlock[i] = packUnorm4x8( float4( srcPixels0, 1.0f ) );
+		bAllColoursEqual = bAllColoursEqual && srcPixelsBlock[0] == srcPixelsBlock[i];
+	}
+
+	float maxEndp16, minEndp16;
+	uint mask = 0u;
+
+	if( bAllColoursEqual )
+	{
+		const uint3 rgbVal = uint3( unpackUnorm4x8( srcPixelsBlock[0] ).xyz * 255.0f );
+		mask = 0xAAAAAAAAu;
+		maxEndp16 =
+			c_oMatch5[rgbVal.r][0] * 2048.0f + c_oMatch6[rgbVal.g][0] * 32.0f + c_oMatch5[rgbVal.b][0];
+		minEndp16 =
+			c_oMatch5[rgbVal.r][1] * 2048.0f + c_oMatch6[rgbVal.g][1] * 32.0f + c_oMatch5[rgbVal.b][1];
+	}
+	else
+	{
+#ifdef BC1_DITHER
+		uint ditherPixelsBlock[16];
+		// first step: compute dithered version for PCA if desired
+		DitherBlock( srcPixelsBlock, ditherPixelsBlock );
+#else
+#	define ditherPixelsBlock srcPixelsBlock
+#endif
+
+		// second step: pca+map along principal axis
+		OptimizeColorsBlock( ditherPixelsBlock, minEndp16, maxEndp16 );
+		if( minEndp16 != maxEndp16 )
+		{
+			float3 colours[4];
+			EvalColors( colours, maxEndp16, minEndp16 );  // Note min/max are inverted
+			mask = MatchColorsBlock( srcPixelsBlock, colours );
+		}
+
+		// third step: refine (multiple times if requested)
+		bool bStopRefinement = false;
+		for( uint i = 0u; i < p_numRefinements && !bStopRefinement; ++i )
+		{
+			const uint lastMask = mask;
+
+			if( RefineBlock( ditherPixelsBlock, mask, minEndp16, maxEndp16 ) )
+			{
+				if( minEndp16 != maxEndp16 )
+				{
+					float3 colours[4];
+					EvalColors( colours, maxEndp16, minEndp16 );  // Note min/max are inverted
+					mask = MatchColorsBlock( srcPixelsBlock, colours );
+				}
+				else
+				{
+					mask = 0u;
+					bStopRefinement = true;
+				}
+			}
+
+			bStopRefinement = mask == lastMask || bStopRefinement;
+		}
+	}
+
+	// write the color block
+	if( maxEndp16 < minEndp16 )
+	{
+		const float tmpValue = minEndp16;
+		minEndp16 = maxEndp16;
+		maxEndp16 = tmpValue;
+		mask ^= 0x55555555u;
+	}
+
+	uint4 outputBytes;
+	outputBytes.x = uint( maxEndp16 );
+	outputBytes.y = uint( minEndp16 );
+	outputBytes.z = mask & 0xFFFFu;
+	outputBytes.w = mask >> 16u;
+
+	uint2 dstUV = gl_GlobalInvocationID.xy;
+	imageStore( dstTexture, int2( dstUV ), outputBytes );
+}
diff --git a/src/compiler/glsl/bc4.glsl b/src/compiler/glsl/bc4.glsl
new file mode 100644
index 00000000000..2486fa4ae0c
--- /dev/null
+++ b/src/compiler/glsl/bc4.glsl
@@ -0,0 +1,187 @@
+/*
+ * Copyright 2020-2022 Matias N. Goldberg
+ * Copyright 2022 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#version 310 es
+
+#if defined(GL_ES) && GL_ES == 1
+	// Desktop GLSL allows the const keyword for either compile-time or
+	// run-time constants. GLSL ES only allows the keyword for compile-time
+	// constants. Since we use const on run-time constants, define it to
+	// nothing.
+	#define const
+#endif
+
+#define __sharedOnlyBarrier memoryBarrierShared();barrier();
+
+%s // include "CrossPlatformSettings_piece_all.glsl"
+
+shared float2 g_minMaxValues[4u * 4u * 4u];
+shared uint2 g_mask[4u * 4u];
+
+layout( location = 0 ) uniform uint2 params;
+
+#define p_channelIdx params.x
+#define p_useSNorm params.y
+
+uniform sampler2D srcTex;
+
+layout( rgba16ui ) uniform restrict writeonly mediump uimage2D dstTexture;
+
+layout( local_size_x = 4,  //
+		local_size_y = 4,  //
+		local_size_z = 4 ) in;
+
+/// Each block is 16 pixels
+/// Each thread works on 4 pixels
+/// Therefore each block needs 4 threads, generating 8 masks
+/// At the end these 8 masks get merged into 2 and results written to output
+///
+/// **Q: Why 4 pixels per thread? Why not 1 pixel per thread? Why not 2? Why not 16?**
+///
+/// A: It's a sweetspot.
+///  - Very short threads cannot fill expensive GPUs with enough work (dispatch bound)
+///  - Lots of threads means lots of synchronization (e.g. evaluating min/max, merging masks)
+///    overhead, and also more LDS usage which reduces occupancy.
+///  - Long threads (e.g. 1 thread per block) misses parallelism opportunities
+void main()
+{
+	float minVal, maxVal;
+	float4 srcPixel;
+
+	const uint blockThreadId = gl_LocalInvocationID.x;
+
+	const uint2 pixelsToLoadBase = gl_GlobalInvocationID.yz << 2u;
+
+	for( uint i = 0u; i < 4u; ++i )
+	{
+		const uint2 pixelsToLoad = pixelsToLoadBase + uint2( i, blockThreadId );
+
+		const float4 value = OGRE_Load2D( srcTex, int2( pixelsToLoad ), 0 ).xyzw;
+		srcPixel[i] = p_channelIdx == 0u ? value.x : ( p_channelIdx == 1u ? value.y : value.w );
+		srcPixel[i] *= 255.0f;
+	}
+
+	minVal = min3( srcPixel.x, srcPixel.y, srcPixel.z );
+	maxVal = max3( srcPixel.x, srcPixel.y, srcPixel.z );
+	minVal = min( minVal, srcPixel.w );
+	maxVal = max( maxVal, srcPixel.w );
+
+	const uint minMaxIdxBase = ( gl_LocalInvocationID.z << 4u ) + ( gl_LocalInvocationID.y << 2u );
+	const uint maskIdxBase = ( gl_LocalInvocationID.z << 2u ) + gl_LocalInvocationID.y;
+
+	g_minMaxValues[minMaxIdxBase + blockThreadId] = float2( minVal, maxVal );
+	g_mask[maskIdxBase] = uint2( 0u, 0u );
+
+	__sharedOnlyBarrier;
+
+	// Have all 4 threads in the block grab the min/max value by comparing what all 4 threads uploaded
+	for( uint i = 0u; i < 4u; ++i )
+	{
+		minVal = min( g_minMaxValues[minMaxIdxBase + i].x, minVal );
+		maxVal = max( g_minMaxValues[minMaxIdxBase + i].y, maxVal );
+	}
+
+	// determine bias and emit color indices
+	// given the choice of maxVal/minVal, these indices are optimal:
+	// http://fgiesen.wordpress.com/2009/12/15/dxt5-alpha-block-index-determination/
+	float dist = maxVal - minVal;
+	float dist4 = dist * 4.0f;
+	float dist2 = dist * 2.0f;
+	float bias = ( dist < 8.0f ) ? ( dist - 1.0f ) : ( trunc( dist * 0.5f ) + 2.0f );
+	bias -= minVal * 7.0f;
+
+	uint mask0 = 0u, mask1 = 0u;
+
+	for( uint i = 0u; i < 4u; ++i )
+	{
+		float a = srcPixel[i] * 7.0f + bias;
+
+		int ind = 0;
+
+		// select index. this is a "linear scale" lerp factor between 0 (val=min) and 7 (val=max).
+		if( a >= dist4 )
+		{
+			ind = 4;
+			a -= dist4;
+		}
+
+		if( a >= dist2 )
+		{
+			ind += 2;
+			a -= dist2;
+		}
+
+		if( a >= dist )
+			ind += 1;
+
+		// turn linear scale into DXT index (0/1 are extremal pts)
+		ind = -ind & 7;
+		ind ^= ( 2 > ind ) ? 1 : 0;
+
+		// write index
+		const uint bits = 16u + ( ( blockThreadId << 2u ) + i ) * 3u;
+		if( bits < 32u )
+		{
+			mask0 |= uint( ind ) << bits;
+			if( bits + 3u > 32u )
+			{
+				mask1 |= uint( ind ) >> ( 32u - bits );
+			}
+		}
+		else
+		{
+			mask1 |= uint( ind ) << ( bits - 32u );
+		}
+	}
+
+	if( mask0 != 0u )
+		atomicOr( g_mask[maskIdxBase].x, mask0 );
+	if( mask1 != 0u )
+		atomicOr( g_mask[maskIdxBase].y, mask1 );
+
+	__sharedOnlyBarrier;
+
+	if( blockThreadId == 0u )
+	{
+		// Save data
+		uint4 outputBytes;
+
+		if( p_useSNorm != 0u )
+		{
+			outputBytes.x =
+				packSnorm4x8( float4( maxVal * ( 1.0f / 255.0f ) * 2.0f - 1.0f,
+									  minVal * ( 1.0f / 255.0f ) * 2.0f - 1.0f, 0.0f, 0.0f ) );
+		}
+		else
+		{
+			outputBytes.x = packUnorm4x8(
+				float4( maxVal * ( 1.0f / 255.0f ), minVal * ( 1.0f / 255.0f ), 0.0f, 0.0f ) );
+		}
+		outputBytes.y = g_mask[maskIdxBase].x >> 16u;
+		outputBytes.z = g_mask[maskIdxBase].y & 0xFFFFu;
+		outputBytes.w = g_mask[maskIdxBase].y >> 16u;
+
+		uint2 dstUV = gl_GlobalInvocationID.yz;
+		imageStore( dstTexture, int2( dstUV ), outputBytes );
+	}
+}
diff --git a/src/compiler/glsl/etc2_rgba_stitch.glsl b/src/compiler/glsl/etc2_rgba_stitch.glsl
new file mode 100644
index 00000000000..f90accb82e1
--- /dev/null
+++ b/src/compiler/glsl/etc2_rgba_stitch.glsl
@@ -0,0 +1,46 @@
+/*
+ * Copyright 2020-2022 Matias N. Goldberg
+ * Copyright 2022 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+// RGB and Alpha components of ETC2 RGBA are computed separately.
+// This compute shader merely stitches them together to form the final result
+// It's also used by RG11 driver to stitch two R11 into one RG11
+
+#version 310 es
+
+%s // include "CrossPlatformSettings_piece_all.glsl"
+
+layout( local_size_x = 8,  //
+		local_size_y = 8,  //
+		local_size_z = 1 ) in;
+
+layout( binding = 0 ) uniform highp usampler2D srcRGB;
+layout( binding = 1 ) uniform highp usampler2D srcAlpha;
+layout( rgba32ui ) uniform restrict writeonly highp uimage2D dstTexture;
+
+void main()
+{
+	uint2 etcRgb = OGRE_Load2D( srcRGB, int2( gl_GlobalInvocationID.xy ), 0 ).xy;
+	uint2 etcAlpha = OGRE_Load2D( srcAlpha, int2( gl_GlobalInvocationID.xy ), 0 ).xy;
+
+	imageStore( dstTexture, int2( gl_GlobalInvocationID.xy ), uint4( etcAlpha.xy, etcRgb.xy ) );
+}
diff --git a/src/compiler/glsl/meson.build b/src/compiler/glsl/meson.build
index d2966d73f3c..d8426aa163a 100644
--- a/src/compiler/glsl/meson.build
+++ b/src/compiler/glsl/meson.build
@@ -72,6 +72,41 @@ float64_glsl_h = custom_target(
 
 float64_glsl_file = [files('float64.glsl')]
 
+cross_platform_settings_piece_all_h = custom_target(
+  'cross_platform_settings_piece_all.h',
+  input : [files_xxd, 'CrossPlatformSettings_piece_all.glsl'],
+  output : 'cross_platform_settings_piece_all.h',
+  command : [prog_python, '@INPUT@', '@OUTPUT@', '-n', 'cross_platform_settings_piece_all_header'],
+)
+
+bc1_glsl_h = custom_target(
+  'bc1_glsl.h',
+  input : [files_xxd, 'bc1.glsl'],
+  output : 'bc1_glsl.h',
+  command : [prog_python, '@INPUT@', '@OUTPUT@', '-n', 'bc1_source'],
+)
+
+bc4_glsl_h = custom_target(
+  'bc4_glsl.h',
+  input : [files_xxd, 'bc4.glsl'],
+  output : 'bc4_glsl.h',
+  command : [prog_python, '@INPUT@', '@OUTPUT@', '-n', 'bc4_source'],
+)
+
+etc2_rgba_stitch_glsl_h = custom_target(
+  'etc2_rgba_stitch_glsl.h',
+  input : [files_xxd, 'etc2_rgba_stitch.glsl'],
+  output : 'etc2_rgba_stitch_glsl.h',
+  command : [prog_python, '@INPUT@', '@OUTPUT@', '-n', 'etc2_rgba_stitch_source'],
+)
+
+astc_glsl_h = custom_target(
+  'astc_glsl.h',
+  input : [files_xxd, 'astc_decoder.glsl'],
+  output : 'astc_glsl.h',
+  command : [prog_python, '@INPUT@', '@OUTPUT@', '-n', 'astc_source'],
+)
+
 files_libglsl = files(
   'ast.h',
   'ast_array_index.cpp',
@@ -214,7 +249,8 @@ libglsl = static_library(
   'glsl',
   [files_libglsl, glsl_parser, glsl_lexer_cpp, ir_expression_operation_h,
    ir_expression_operation_strings_h, ir_expression_operation_constant_h,
-   float64_glsl_h],
+   float64_glsl_h, cross_platform_settings_piece_all_h, bc1_glsl_h, bc4_glsl_h,
+   etc2_rgba_stitch_glsl_h, astc_glsl_h],
   c_args : [c_msvc_compat_args, no_override_init_args],
   cpp_args : [cpp_msvc_compat_args],
   gnu_symbol_visibility : 'hidden',
diff --git a/src/mesa/main/shaderapi.c b/src/mesa/main/shaderapi.c
index 048106dccd5..bce384fa539 100644
--- a/src/mesa/main/shaderapi.c
+++ b/src/mesa/main/shaderapi.c
@@ -2671,12 +2671,11 @@ _mesa_copy_linked_program_data(const struct gl_shader_program *src,
 /**
  * ARB_separate_shader_objects: Compile & Link Program
  */
-GLuint GLAPIENTRY
-_mesa_CreateShaderProgramv(GLenum type, GLsizei count,
-                           const GLchar* const *strings)
+GLuint
+_mesa_CreateShaderProgramv_impl(struct gl_context *ctx,
+                                GLenum type, GLsizei count,
+                                const GLchar* const *strings)
 {
-   GET_CURRENT_CONTEXT(ctx);
-
    const GLuint shader = create_shader_err(ctx, type, "glCreateShaderProgramv");
    GLuint program = 0;
 
@@ -2728,6 +2727,17 @@ _mesa_CreateShaderProgramv(GLenum type, GLsizei count,
    return program;
 }
 
+/**
+ * ARB_separate_shader_objects: Compile & Link Program
+ */
+GLuint GLAPIENTRY
+_mesa_CreateShaderProgramv(GLenum type, GLsizei count,
+                           const GLchar* const *strings)
+{
+   GET_CURRENT_CONTEXT(ctx);
+
+   return _mesa_CreateShaderProgramv_impl(ctx, type, count, strings);
+}
 
 static void
 set_patch_vertices(struct gl_context *ctx, GLint value)
diff --git a/src/mesa/main/shaderapi.h b/src/mesa/main/shaderapi.h
index 678757404a2..35177d42f64 100644
--- a/src/mesa/main/shaderapi.h
+++ b/src/mesa/main/shaderapi.h
@@ -200,6 +200,10 @@ const char *
 _mesa_lookup_shader_include(struct gl_context *ctx, char *path,
                             bool error_check);
 
+GLuint
+_mesa_CreateShaderProgramv_impl(struct gl_context *ctx,
+                                GLenum type, GLsizei count,
+                                const GLchar* const *strings);
 #ifdef __cplusplus
 }
 #endif
diff --git a/src/mesa/main/texcompress_astc_luts.cpp b/src/mesa/main/texcompress_astc_luts.cpp
new file mode 100644
index 00000000000..6ffaf23ea88
--- /dev/null
+++ b/src/mesa/main/texcompress_astc_luts.cpp
@@ -0,0 +1,532 @@
+/* Copyright (c) 2017-2022 Hans-Kristian Arntzen
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be
+ * included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
+ * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include <assert.h>
+#include <cstdint>
+#include <cstring>
+#include <mutex>
+#include <unordered_map>
+#include <vector>
+
+#include "texcompress_astc_luts.h"
+
+namespace Granite
+{
+static void build_astc_unquant_weight_lut(uint8_t *lut, size_t range, const ASTCQuantizationMode &mode)
+{
+	for (size_t i = 0; i < range; i++)
+	{
+		auto &v = lut[i];
+
+		if (!mode.quints && !mode.trits)
+		{
+			switch (mode.bits)
+			{
+			case 1:
+				v = i * 63;
+				break;
+
+			case 2:
+				v = i * 0x15;
+				break;
+
+			case 3:
+				v = i * 9;
+				break;
+
+			case 4:
+				v = (i << 2) | (i >> 2);
+				break;
+
+			case 5:
+				v = (i << 1) | (i >> 4);
+				break;
+
+			default:
+				v = 0;
+				break;
+			}
+		}
+		else if (mode.bits == 0)
+		{
+			if (mode.trits)
+				v = 32 * i;
+			else
+				v = 16 * i;
+		}
+		else
+		{
+			unsigned b = (i >> 1) & 1;
+			unsigned c = (i >> 2) & 1;
+			unsigned A, B, C, D;
+
+			A = 0x7f * (i & 1);
+			D = i >> mode.bits;
+			B = 0;
+
+			if (mode.trits)
+			{
+				static const unsigned Cs[3] = { 50, 23, 11 };
+				C = Cs[mode.bits - 1];
+				if (mode.bits == 2)
+					B = 0x45 * b;
+				else if (mode.bits == 3)
+					B = 0x21 * b + 0x42 * c;
+			}
+			else
+			{
+				static const unsigned Cs[2] = { 28, 13 };
+				C = Cs[mode.bits - 1];
+				if (mode.bits == 2)
+					B = 0x42 * b;
+			}
+
+			unsigned unq = D * C + B;
+			unq ^= A;
+			unq = (A & 0x20) | (unq >> 2);
+			v = unq;
+		}
+
+		// Expand [0, 63] to [0, 64].
+		if (mode.bits != 0 && v > 32)
+			v++;
+	}
+}
+
+static void build_astc_unquant_endpoint_lut(uint8_t *lut, size_t range, const ASTCQuantizationMode &mode)
+{
+	for (size_t i = 0; i < range; i++)
+	{
+		auto &v = lut[i];
+
+		if (!mode.quints && !mode.trits)
+		{
+			// Bit-replication.
+			switch (mode.bits)
+			{
+			case 1:
+				v = i * 0xff;
+				break;
+
+			case 2:
+				v = i * 0x55;
+				break;
+
+			case 3:
+				v = (i << 5) | (i << 2) | (i >> 1);
+				break;
+
+			case 4:
+				v = i * 0x11;
+				break;
+
+			case 5:
+				v = (i << 3) | (i >> 2);
+				break;
+
+			case 6:
+				v = (i << 2) | (i >> 4);
+				break;
+
+			case 7:
+				v = (i << 1) | (i >> 6);
+				break;
+
+			default:
+				v = i;
+				break;
+			}
+		}
+		else
+		{
+			unsigned A, B, C, D;
+			unsigned b = (i >> 1) & 1;
+			unsigned c = (i >> 2) & 1;
+			unsigned d = (i >> 3) & 1;
+			unsigned e = (i >> 4) & 1;
+			unsigned f = (i >> 5) & 1;
+
+			B = 0;
+			D = i >> mode.bits;
+			A = (i & 1) * 0x1ff;
+
+			if (mode.trits)
+			{
+				static const unsigned Cs[6] = { 204, 93, 44, 22, 11, 5 };
+				C = Cs[mode.bits - 1];
+
+				switch (mode.bits)
+				{
+				case 2:
+					B = b * 0x116;
+					break;
+
+				case 3:
+					B = b * 0x85 + c * 0x10a;
+					break;
+
+				case 4:
+					B = b * 0x41 + c * 0x82 + d * 0x104;
+					break;
+
+				case 5:
+					B = b * 0x20 + c * 0x40 + d * 0x81 + e * 0x102;
+					break;
+
+				case 6:
+					B = b * 0x10 + c * 0x20 + d * 0x40 + e * 0x80 + f * 0x101;
+					break;
+				}
+			}
+			else
+			{
+				static const unsigned Cs[5] = { 113, 54, 26, 13, 6 };
+				C = Cs[mode.bits - 1];
+
+				switch (mode.bits)
+				{
+				case 2:
+					B = b * 0x10c;
+					break;
+
+				case 3:
+					B = b * 0x82 + c * 0x105;
+					break;
+
+				case 4:
+					B = b * 0x40 + c * 0x81 + d * 0x102;
+					break;
+
+				case 5:
+					B = b * 0x20 + c * 0x40 + d * 0x80 + e * 0x101;
+					break;
+				}
+			}
+
+			unsigned unq = D * C + B;
+			unq ^= A;
+			unq = (A & 0x80) | (unq >> 2);
+			v = uint8_t(unq);
+		}
+	}
+}
+
+static unsigned astc_value_range(const ASTCQuantizationMode &mode)
+{
+	unsigned value_range = 1u << mode.bits;
+	if (mode.trits)
+		value_range *= 3;
+	if (mode.quints)
+		value_range *= 5;
+
+	if (value_range == 1)
+		value_range = 0;
+	return value_range;
+}
+
+static uint32_t astc_hash52(uint32_t p)
+{
+	p ^= p >> 15; p -= p << 17; p += p << 7; p += p << 4;
+	p ^= p >>  5; p += p << 16; p ^= p >> 7; p ^= p >> 3;
+	p ^= p <<  6; p ^= p >> 17;
+	return p;
+}
+
+// Copy-paste from spec.
+static int astc_select_partition(int seed, int x, int y, int z, int partitioncount, bool small_block)
+{
+	if (small_block)
+	{
+		x <<= 1;
+		y <<= 1;
+		z <<= 1;
+	}
+
+	seed += (partitioncount - 1) * 1024;
+	uint32_t rnum = astc_hash52(seed);
+	uint8_t seed1 = rnum & 0xF;
+	uint8_t seed2 = (rnum >> 4) & 0xF;
+	uint8_t seed3 = (rnum >> 8) & 0xF;
+	uint8_t seed4 = (rnum >> 12) & 0xF;
+	uint8_t seed5 = (rnum >> 16) & 0xF;
+	uint8_t seed6 = (rnum >> 20) & 0xF;
+	uint8_t seed7 = (rnum >> 24) & 0xF;
+	uint8_t seed8 = (rnum >> 28) & 0xF;
+	uint8_t seed9 = (rnum >> 18) & 0xF;
+	uint8_t seed10 = (rnum >> 22) & 0xF;
+	uint8_t seed11 = (rnum >> 26) & 0xF;
+	uint8_t seed12 = ((rnum >> 30) | (rnum << 2)) & 0xF;
+
+	seed1 *= seed1; seed2 *= seed2; seed3 *= seed3; seed4 *= seed4;
+	seed5 *= seed5; seed6 *= seed6; seed7 *= seed7; seed8 *= seed8;
+	seed9 *= seed9; seed10 *= seed10; seed11 *= seed11; seed12 *= seed12;
+
+	int sh1, sh2, sh3;
+	if (seed & 1)
+	{
+		sh1 = seed & 2 ? 4 : 5;
+		sh2 = partitioncount == 3 ? 6 : 5;
+	}
+	else
+	{
+		sh1 = partitioncount == 3 ? 6 : 5;
+		sh2 = seed & 2 ? 4 : 5;
+	}
+	sh3 = (seed & 0x10) ? sh1 : sh2;
+
+	seed1 >>= sh1; seed2 >>= sh2; seed3 >>= sh1; seed4 >>= sh2;
+	seed5 >>= sh1; seed6 >>= sh2; seed7 >>= sh1; seed8 >>= sh2;
+	seed9 >>= sh3; seed10 >>= sh3; seed11 >>= sh3; seed12 >>= sh3;
+
+	int a = seed1 * x + seed2 * y + seed11 * z + (rnum >> 14);
+	int b = seed3 * x + seed4 * y + seed12 * z + (rnum >> 10);
+	int c = seed5 * x + seed6 * y + seed9 * z + (rnum >> 6);
+	int d = seed7 * x + seed8 * y + seed10 * z + (rnum >> 2);
+
+	a &= 0x3f; b &= 0x3f; c &= 0x3f; d &= 0x3f;
+
+	if (partitioncount < 4)
+		d = 0;
+	if (partitioncount < 3)
+		c = 0;
+
+	if (a >= b && a >= c && a >= d)
+		return 0;
+	else if (b >= c && b >= d)
+		return 1;
+	else if (c >= d)
+		return 2;
+	else
+		return 3;
+}
+
+ASTCLutHolder::PartitionTable::PartitionTable(unsigned block_width, unsigned block_height)
+{
+	bool small_block = (block_width * block_height) < 31;
+
+	lut_width = block_width * 32;
+	lut_height = block_height * 32;
+	lut_buffer.resize(lut_width * lut_height);
+
+	for (unsigned seed_y = 0; seed_y < 32; seed_y++)
+	{
+		for (unsigned seed_x = 0; seed_x < 32; seed_x++)
+		{
+			unsigned seed = seed_y * 32 + seed_x;
+			for (unsigned block_y = 0; block_y < block_height; block_y++)
+			{
+				for (unsigned block_x = 0; block_x < block_width; block_x++)
+				{
+					int part2 = astc_select_partition(seed, block_x, block_y, 0, 2, small_block);
+					int part3 = astc_select_partition(seed, block_x, block_y, 0, 3, small_block);
+					int part4 = astc_select_partition(seed, block_x, block_y, 0, 4, small_block);
+					lut_buffer[(seed_y * block_height + block_y) * lut_width + (seed_x * block_width + block_x)] =
+							(part2 << 0) | (part3 << 2) | (part4 << 4);
+				}
+			}
+		}
+	}
+}
+
+ASTCLutHolder::PartitionTable &ASTCLutHolder::get_partition_table(unsigned width, unsigned height)
+{
+	std::lock_guard<std::mutex> holder{table_lock};
+	auto itr = tables.find(width * 16 + height);
+	if (itr != tables.end())
+	{
+		return itr->second;
+	}
+	else
+	{
+		auto &t = tables[width * 16 + height];
+		t = { width, height };
+		return t;
+	}
+}
+
+ASTCLutHolder &get_astc_luts()
+{
+	static ASTCLutHolder holder;
+	return holder;
+}
+
+ASTCLutHolder::ASTCLutHolder()
+{
+	init_color_endpoint();
+	init_weight_luts();
+	init_trits_quints();
+}
+
+void ASTCLutHolder::init_color_endpoint()
+{
+	auto &unquant_lut = color_endpoint.unquant_lut;
+
+	for (size_t i = 0; i < astc_num_quantization_modes; i++)
+	{
+		auto value_range = astc_value_range(astc_quantization_modes[i]);
+		color_endpoint.unquant_lut_offsets[i] = color_endpoint.unquant_offset;
+		build_astc_unquant_endpoint_lut(unquant_lut + color_endpoint.unquant_offset, value_range, astc_quantization_modes[i]);
+		color_endpoint.unquant_offset += value_range;
+	}
+
+	auto &lut = color_endpoint.lut;
+
+	// We can have a maximum of 9 endpoint pairs, i.e. 18 endpoint values in total.
+	for (unsigned pairs_minus_1 = 0; pairs_minus_1 < 9; pairs_minus_1++)
+	{
+		for (unsigned remaining = 0; remaining < 128; remaining++)
+		{
+			bool found_mode = false;
+			for (auto &mode : astc_quantization_modes)
+			{
+				unsigned num_values = (pairs_minus_1 + 1) * 2;
+				unsigned total_bits = mode.bits * num_values +
+				                      (mode.quints * 7 * num_values + 2) / 3 +
+				                      (mode.trits * 8 * num_values + 4) / 5;
+
+				if (total_bits <= remaining)
+				{
+					found_mode = true;
+					lut[pairs_minus_1][remaining][0] = mode.bits;
+					lut[pairs_minus_1][remaining][1] = mode.trits;
+					lut[pairs_minus_1][remaining][2] = mode.quints;
+					lut[pairs_minus_1][remaining][3] = color_endpoint.unquant_lut_offsets[&mode - astc_quantization_modes];
+					break;
+				}
+			}
+
+			if (!found_mode)
+				memset(lut[pairs_minus_1][remaining], 0, sizeof(lut[pairs_minus_1][remaining]));
+		}
+	}
+}
+
+void ASTCLutHolder::init_weight_luts()
+{
+	auto &lut = weights.lut;
+	auto &unquant_lut = weights.unquant_lut;
+	auto &unquant_offset = weights.unquant_offset;
+
+	for (size_t i = 0; i < astc_num_weight_modes; i++)
+	{
+		auto value_range = astc_value_range(astc_weight_modes[i]);
+		lut[i][0] = astc_weight_modes[i].bits;
+		lut[i][1] = astc_weight_modes[i].trits;
+		lut[i][2] = astc_weight_modes[i].quints;
+		lut[i][3] = unquant_offset;
+		build_astc_unquant_weight_lut(unquant_lut + unquant_offset, value_range, astc_weight_modes[i]);
+		unquant_offset += value_range;
+	}
+
+	assert(unquant_offset <= 256);
+}
+
+void ASTCLutHolder::init_trits_quints()
+{
+	// From specification.
+	auto &trits_quints = integer.trits_quints;
+
+	for (unsigned T = 0; T < 256; T++)
+	{
+		unsigned C;
+		uint8_t t0, t1, t2, t3, t4;
+
+		if (((T >> 2) & 7) == 7)
+		{
+			C = (((T >> 5) & 7) << 2) | (T & 3);
+			t4 = t3 = 2;
+		}
+		else
+		{
+			C = T & 0x1f;
+			if (((T >> 5) & 3) == 3)
+			{
+				t4 = 2;
+				t3 = (T >> 7) & 1;
+			}
+			else
+			{
+				t4 = (T >> 7) & 1;
+				t3 = (T >> 5) & 3;
+			}
+		}
+
+		if ((C & 3) == 3)
+		{
+			t2 = 2;
+			t1 = (C >> 4) & 1;
+			t0 = (((C >> 3) & 1) << 1) | (((C >> 2) & 1) & ~(((C >> 3) & 1)));
+		}
+		else if (((C >> 2) & 3) == 3)
+		{
+			t2 = 2;
+			t1 = 2;
+			t0 = C & 3;
+		}
+		else
+		{
+			t2 = (C >> 4) & 1;
+			t1 = (C >> 2) & 3;
+			t0 = (((C >> 1) & 1) << 1) | ((C & 1) & ~(((C >> 1) & 1)));
+		}
+
+		trits_quints[T] = t0 | (t1 << 3) | (t2 << 6) | (t3 << 9) | (t4 << 12);
+	}
+
+	for (unsigned Q = 0; Q < 128; Q++)
+	{
+		unsigned C;
+		uint8_t q0, q1, q2;
+		if (((Q >> 1) & 3) == 3 && ((Q >> 5) & 3) == 0)
+		{
+			q2 = ((Q & 1) << 2) | ((((Q >> 4) & 1) & ~(Q & 1)) << 1) | (((Q >> 3) & 1) & ~(Q & 1));
+			q1 = q0 = 4;
+		}
+		else
+		{
+			if (((Q >> 1) & 3) == 3)
+			{
+				q2 = 4;
+				C = (((Q >> 3) & 3) << 3) | ((~(Q >> 5) & 3) << 1) | (Q & 1);
+			}
+			else
+			{
+				q2 = (Q >> 5) & 3;
+				C = Q & 0x1f;
+			}
+
+			if ((C & 7) == 5)
+			{
+				q1 = 4;
+				q0 = (C >> 3) & 3;
+			}
+			else
+			{
+				q1 = (C >> 3) & 3;
+				q0 = C & 7;
+			}
+		}
+
+		trits_quints[256 + Q] = q0 | (q1 << 3) | (q2 << 6);
+	}
+}
+}
diff --git a/src/mesa/main/texcompress_astc_luts.h b/src/mesa/main/texcompress_astc_luts.h
new file mode 100644
index 00000000000..b3c26033a9a
--- /dev/null
+++ b/src/mesa/main/texcompress_astc_luts.h
@@ -0,0 +1,127 @@
+/* Copyright (c) 2017-2022 Hans-Kristian Arntzen
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be
+ * included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
+ * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#pragma once
+
+#include <mutex>
+#include <unordered_map>
+#include <vector>
+
+namespace Granite
+{
+
+struct ASTCQuantizationMode
+{
+        uint8_t bits, trits, quints;
+};
+
+// In order to decode color endpoints, we need to convert available bits and number of values
+// into a format of (bits, trits, quints). A simple LUT texture is a reasonable approach for this.
+// Decoders are expected to have some form of LUT to deal with this ...
+static const ASTCQuantizationMode astc_quantization_modes[] = {
+        { 8, 0, 0 },
+        { 6, 1, 0 },
+        { 5, 0, 1 },
+        { 7, 0, 0 },
+        { 5, 1, 0 },
+        { 4, 0, 1 },
+        { 6, 0, 0 },
+        { 4, 1, 0 },
+        { 3, 0, 1 },
+        { 5, 0, 0 },
+        { 3, 1, 0 },
+        { 2, 0, 1 },
+        { 4, 0, 0 },
+        { 2, 1, 0 },
+        { 1, 0, 1 },
+        { 3, 0, 0 },
+        { 1, 1, 0 },
+};
+
+constexpr size_t astc_num_quantization_modes = sizeof(astc_quantization_modes) / sizeof(astc_quantization_modes[0]);
+
+static const ASTCQuantizationMode astc_weight_modes[] = {
+        { 0, 0, 0 }, // Invalid
+        { 0, 0, 0 }, // Invalid
+        { 1, 0, 0 },
+        { 0, 1, 0 },
+        { 2, 0, 0 },
+        { 0, 0, 1 },
+        { 1, 1, 0 },
+        { 3, 0, 0 },
+        { 0, 0, 0 }, // Invalid
+        { 0, 0, 0 }, // Invalid
+        { 1, 0, 1 },
+        { 2, 1, 0 },
+        { 4, 0, 0 },
+        { 2, 0, 1 },
+        { 3, 1, 0 },
+        { 5, 0, 0 },
+};
+
+constexpr size_t astc_num_weight_modes = sizeof(astc_weight_modes) / sizeof(astc_weight_modes[0]);
+
+struct ASTCLutHolder
+{
+        ASTCLutHolder();
+
+        void init_color_endpoint();
+        void init_weight_luts();
+        void init_trits_quints();
+
+        struct
+        {
+                size_t unquant_offset = 0;
+                uint8_t unquant_lut[2048];
+                uint16_t lut[9][128][4];
+                size_t unquant_lut_offsets[astc_num_quantization_modes];
+        } color_endpoint;
+
+        struct
+        {
+                size_t unquant_offset = 0;
+                uint8_t unquant_lut[2048];
+                uint8_t lut[astc_num_weight_modes][4];
+        } weights;
+
+        struct
+        {
+                uint16_t trits_quints[256 + 128];
+        } integer;
+
+        struct PartitionTable
+        {
+                PartitionTable() = default;
+                PartitionTable(unsigned width, unsigned height);
+                std::vector<uint8_t> lut_buffer;
+                unsigned lut_width = 0;
+                unsigned lut_height = 0;
+        };
+
+        std::mutex table_lock;
+        std::unordered_map<unsigned, PartitionTable> tables;
+
+        PartitionTable &get_partition_table(unsigned width, unsigned height);
+};
+
+ASTCLutHolder &get_astc_luts();
+}
diff --git a/src/mesa/main/texcompress_astc_luts_wrap.cpp b/src/mesa/main/texcompress_astc_luts_wrap.cpp
new file mode 100644
index 00000000000..2d8f149e3e0
--- /dev/null
+++ b/src/mesa/main/texcompress_astc_luts_wrap.cpp
@@ -0,0 +1,72 @@
+/*
+ * Copyright © 2022 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included
+ * in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include "texcompress_astc_luts_wrap.h"
+#include "texcompress_astc_luts.h"
+
+#include "util/u_box.h"
+
+extern "C" void
+_mesa_init_astc_decoder_luts(astc_decoder_lut_holder *holder)
+{
+   auto &luts = Granite::get_astc_luts();
+   *holder = {
+      .color_endpoint = {
+         .data = luts.color_endpoint.lut,
+         .size_B = sizeof(luts.color_endpoint.lut),
+         .format = PIPE_FORMAT_R16G16B16A16_UINT,
+      },
+      .color_endpoint_unquant = {
+         .data = luts.color_endpoint.unquant_lut,
+         .size_B = luts.color_endpoint.unquant_offset,
+         .format = PIPE_FORMAT_R8_UINT,
+      },
+      .weights = {
+         .data = luts.weights.lut,
+         .size_B = sizeof(luts.weights.lut),
+         .format = PIPE_FORMAT_R8G8B8A8_UINT,
+      },
+      .weights_unquant = {
+         .data = luts.weights.unquant_lut,
+         .size_B = luts.weights.unquant_offset,
+         .format = PIPE_FORMAT_R8_UINT,
+      },
+      .trits_quints = {
+         .data = luts.integer.trits_quints,
+         .size_B = sizeof(luts.integer.trits_quints),
+         .format = PIPE_FORMAT_R16_UINT,
+      },
+   };
+}
+
+extern "C" void *
+_mesa_get_astc_decoder_partition_table(uint32_t block_width,
+                                       uint32_t block_height,
+                                       struct pipe_box *ptable_box)
+{
+   auto &luts = Granite::get_astc_luts();
+   auto &table = luts.get_partition_table(block_width, block_height);
+
+   u_box_origin_2d(table.lut_width, table.lut_height, ptable_box);
+
+   return table.lut_buffer.data();
+}
diff --git a/src/mesa/main/texcompress_astc_luts_wrap.h b/src/mesa/main/texcompress_astc_luts_wrap.h
new file mode 100644
index 00000000000..553cd90016a
--- /dev/null
+++ b/src/mesa/main/texcompress_astc_luts_wrap.h
@@ -0,0 +1,62 @@
+/*
+ * Copyright © 2022 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included
+ * in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef __TEXCOMPRESS_ASTC_LUTS_WRAP_H__
+#define __TEXCOMPRESS_ASTC_LUTS_WRAP_H__
+
+#include <stdint.h>
+#include "pipe/p_state.h"
+
+/* C wrapper for Granite::ASTCLutHolder. */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+struct pipe_box;
+
+typedef struct
+{
+   void *data;
+   size_t size_B;
+   enum pipe_format format;
+} astc_decoder_lut;
+
+typedef struct
+{
+   astc_decoder_lut color_endpoint;
+   astc_decoder_lut color_endpoint_unquant;
+   astc_decoder_lut weights;
+   astc_decoder_lut weights_unquant;
+   astc_decoder_lut trits_quints;
+} astc_decoder_lut_holder;
+
+void _mesa_init_astc_decoder_luts(astc_decoder_lut_holder *holder);
+void *_mesa_get_astc_decoder_partition_table(uint32_t block_width,
+                                             uint32_t block_height,
+                                             struct pipe_box *ptable_box);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/src/mesa/meson.build b/src/mesa/meson.build
index 86f30ab44f6..4b0222acedc 100644
--- a/src/mesa/meson.build
+++ b/src/mesa/meson.build
@@ -205,6 +205,10 @@ files_libmesa = files(
   'main/texcompress.h',
   'main/texcompress_astc.cpp',
   'main/texcompress_astc.h',
+  'main/texcompress_astc_luts.cpp',
+  'main/texcompress_astc_luts.h',
+  'main/texcompress_astc_luts_wrap.cpp',
+  'main/texcompress_astc_luts_wrap.h',
   'main/texcompress_bptc.c',
   'main/texcompress_bptc.h',
   'main/texcompress_cpal.c',
@@ -305,6 +309,7 @@ files_libmesa = files(
   'state_tracker/st_atom_tess.c',
   'state_tracker/st_atom_texture.c',
   'state_tracker/st_atom_viewport.c',
+  'state_tracker/st_bc1_tables.h',
   'state_tracker/st_cb_bitmap.c',
   'state_tracker/st_cb_bitmap.h',
   'state_tracker/st_cb_clear.c',
@@ -365,6 +370,8 @@ files_libmesa = files(
   'state_tracker/st_scissor.h',
   'state_tracker/st_shader_cache.c',
   'state_tracker/st_shader_cache.h',
+  'state_tracker/st_texcompress_compute.c',
+  'state_tracker/st_texcompress_compute.h',
   'state_tracker/st_texture.c',
   'state_tracker/st_texture.h',
   'state_tracker/st_util.h',
diff --git a/src/mesa/state_tracker/st_bc1_tables.h b/src/mesa/state_tracker/st_bc1_tables.h
new file mode 100644
index 00000000000..654ccdadb78
--- /dev/null
+++ b/src/mesa/state_tracker/st_bc1_tables.h
@@ -0,0 +1,124 @@
+/*
+ * Copyright 2020-2022 Matias N. Goldberg
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+/* These tables have been generated with:
+
+		#define STB_DXT_IMPLEMENTATION
+		#include "stb_dxt.h"
+		#include <stdio.h>
+
+		int main()
+		{
+			stb__InitDXT();
+
+			printf( "static unsigned char stb__OMatch5[256][2] = {\n" );
+			for( size_t i = 0u; i < 256u; ++i )
+			{
+				printf( "{ %i, %i }", stb__OMatch5[i][0], stb__OMatch5[i][1] );
+				if( i != 255u )
+					printf( ",\n" );
+			}
+			printf( "\n};\n" );
+
+			printf( "static unsigned char stb__OMatch6[256][2] = {\n" );
+			for( size_t i = 0u; i < 256u; ++i )
+			{
+				printf( "{ %i, %i }", stb__OMatch6[i][0], stb__OMatch6[i][1] );
+				if( i != 255u )
+					printf( ",\n" );
+			}
+			printf( "\n};\n" );
+
+			return 0;
+		}
+
+	Note that stb__OMatch5[i][0] = max and stb__OMatch5[i][1] = min
+*/
+static unsigned char stb__OMatch5[256][2] = {
+	{ 0, 0 },   { 0, 0 },   { 0, 1 },   { 0, 1 },   { 1, 0 },   { 1, 0 },   { 1, 0 },   { 1, 1 },
+	{ 1, 1 },   { 2, 0 },   { 2, 0 },   { 0, 4 },   { 2, 1 },   { 2, 1 },   { 2, 1 },   { 3, 0 },
+	{ 3, 0 },   { 3, 0 },   { 3, 1 },   { 1, 5 },   { 3, 2 },   { 3, 2 },   { 4, 0 },   { 4, 0 },
+	{ 4, 1 },   { 4, 1 },   { 4, 2 },   { 4, 2 },   { 4, 2 },   { 3, 5 },   { 5, 1 },   { 5, 1 },
+	{ 5, 2 },   { 4, 4 },   { 5, 3 },   { 5, 3 },   { 5, 3 },   { 6, 2 },   { 6, 2 },   { 6, 2 },
+	{ 6, 3 },   { 5, 5 },   { 6, 4 },   { 6, 4 },   { 4, 8 },   { 7, 3 },   { 7, 3 },   { 7, 3 },
+	{ 7, 4 },   { 7, 4 },   { 7, 4 },   { 7, 5 },   { 5, 9 },   { 7, 6 },   { 7, 6 },   { 8, 4 },
+	{ 8, 4 },   { 8, 5 },   { 8, 5 },   { 8, 6 },   { 8, 6 },   { 8, 6 },   { 7, 9 },   { 9, 5 },
+	{ 9, 5 },   { 9, 6 },   { 8, 8 },   { 9, 7 },   { 9, 7 },   { 9, 7 },   { 10, 6 },  { 10, 6 },
+	{ 10, 6 },  { 10, 7 },  { 9, 9 },   { 10, 8 },  { 10, 8 },  { 8, 12 },  { 11, 7 },  { 11, 7 },
+	{ 11, 7 },  { 11, 8 },  { 11, 8 },  { 11, 8 },  { 11, 9 },  { 9, 13 },  { 11, 10 }, { 11, 10 },
+	{ 12, 8 },  { 12, 8 },  { 12, 9 },  { 12, 9 },  { 12, 10 }, { 12, 10 }, { 12, 10 }, { 11, 13 },
+	{ 13, 9 },  { 13, 9 },  { 13, 10 }, { 12, 12 }, { 13, 11 }, { 13, 11 }, { 13, 11 }, { 14, 10 },
+	{ 14, 10 }, { 14, 10 }, { 14, 11 }, { 13, 13 }, { 14, 12 }, { 14, 12 }, { 12, 16 }, { 15, 11 },
+	{ 15, 11 }, { 15, 11 }, { 15, 12 }, { 15, 12 }, { 15, 12 }, { 15, 13 }, { 13, 17 }, { 15, 14 },
+	{ 15, 14 }, { 16, 12 }, { 16, 12 }, { 16, 13 }, { 16, 13 }, { 16, 14 }, { 16, 14 }, { 16, 14 },
+	{ 15, 17 }, { 17, 13 }, { 17, 13 }, { 17, 14 }, { 16, 16 }, { 17, 15 }, { 17, 15 }, { 17, 15 },
+	{ 18, 14 }, { 18, 14 }, { 18, 14 }, { 18, 15 }, { 17, 17 }, { 18, 16 }, { 18, 16 }, { 16, 20 },
+	{ 19, 15 }, { 19, 15 }, { 19, 15 }, { 19, 16 }, { 19, 16 }, { 19, 16 }, { 19, 17 }, { 17, 21 },
+	{ 19, 18 }, { 19, 18 }, { 20, 16 }, { 20, 16 }, { 20, 17 }, { 20, 17 }, { 20, 18 }, { 20, 18 },
+	{ 20, 18 }, { 19, 21 }, { 21, 17 }, { 21, 17 }, { 21, 18 }, { 20, 20 }, { 21, 19 }, { 21, 19 },
+	{ 21, 19 }, { 22, 18 }, { 22, 18 }, { 22, 18 }, { 22, 19 }, { 21, 21 }, { 22, 20 }, { 22, 20 },
+	{ 20, 24 }, { 23, 19 }, { 23, 19 }, { 23, 19 }, { 23, 20 }, { 23, 20 }, { 23, 20 }, { 23, 21 },
+	{ 21, 25 }, { 23, 22 }, { 23, 22 }, { 24, 20 }, { 24, 20 }, { 24, 21 }, { 24, 21 }, { 24, 22 },
+	{ 24, 22 }, { 24, 22 }, { 23, 25 }, { 25, 21 }, { 25, 21 }, { 25, 22 }, { 24, 24 }, { 25, 23 },
+	{ 25, 23 }, { 25, 23 }, { 26, 22 }, { 26, 22 }, { 26, 22 }, { 26, 23 }, { 25, 25 }, { 26, 24 },
+	{ 26, 24 }, { 24, 28 }, { 27, 23 }, { 27, 23 }, { 27, 23 }, { 27, 24 }, { 27, 24 }, { 27, 24 },
+	{ 27, 25 }, { 25, 29 }, { 27, 26 }, { 27, 26 }, { 28, 24 }, { 28, 24 }, { 28, 25 }, { 28, 25 },
+	{ 28, 26 }, { 28, 26 }, { 28, 26 }, { 27, 29 }, { 29, 25 }, { 29, 25 }, { 29, 26 }, { 28, 28 },
+	{ 29, 27 }, { 29, 27 }, { 29, 27 }, { 30, 26 }, { 30, 26 }, { 30, 26 }, { 30, 27 }, { 29, 29 },
+	{ 30, 28 }, { 30, 28 }, { 30, 28 }, { 31, 27 }, { 31, 27 }, { 31, 27 }, { 31, 28 }, { 31, 28 },
+	{ 31, 28 }, { 31, 29 }, { 31, 29 }, { 31, 30 }, { 31, 30 }, { 31, 30 }, { 31, 31 }, { 31, 31 }
+};
+
+static unsigned char stb__OMatch6[256][2] = {
+	{ 0, 0 },   { 0, 1 },   { 1, 0 },   { 1, 0 },   { 1, 1 },   { 2, 0 },   { 2, 1 },   { 3, 0 },
+	{ 3, 0 },   { 3, 1 },   { 4, 0 },   { 4, 0 },   { 4, 1 },   { 5, 0 },   { 5, 1 },   { 6, 0 },
+	{ 6, 0 },   { 6, 1 },   { 7, 0 },   { 7, 0 },   { 7, 1 },   { 8, 0 },   { 8, 1 },   { 8, 1 },
+	{ 8, 2 },   { 9, 1 },   { 9, 2 },   { 9, 2 },   { 9, 3 },   { 10, 2 },  { 10, 3 },  { 10, 3 },
+	{ 10, 4 },  { 11, 3 },  { 11, 4 },  { 11, 4 },  { 11, 5 },  { 12, 4 },  { 12, 5 },  { 12, 5 },
+	{ 12, 6 },  { 13, 5 },  { 13, 6 },  { 8, 16 },  { 13, 7 },  { 14, 6 },  { 14, 7 },  { 9, 17 },
+	{ 14, 8 },  { 15, 7 },  { 15, 8 },  { 11, 16 }, { 15, 9 },  { 15, 10 }, { 16, 8 },  { 16, 9 },
+	{ 16, 10 }, { 15, 13 }, { 17, 9 },  { 17, 10 }, { 17, 11 }, { 15, 16 }, { 18, 10 }, { 18, 11 },
+	{ 18, 12 }, { 16, 16 }, { 19, 11 }, { 19, 12 }, { 19, 13 }, { 17, 17 }, { 20, 12 }, { 20, 13 },
+	{ 20, 14 }, { 19, 16 }, { 21, 13 }, { 21, 14 }, { 21, 15 }, { 20, 17 }, { 22, 14 }, { 22, 15 },
+	{ 25, 10 }, { 22, 16 }, { 23, 15 }, { 23, 16 }, { 26, 11 }, { 23, 17 }, { 24, 16 }, { 24, 17 },
+	{ 27, 12 }, { 24, 18 }, { 25, 17 }, { 25, 18 }, { 28, 13 }, { 25, 19 }, { 26, 18 }, { 26, 19 },
+	{ 29, 14 }, { 26, 20 }, { 27, 19 }, { 27, 20 }, { 30, 15 }, { 27, 21 }, { 28, 20 }, { 28, 21 },
+	{ 28, 21 }, { 28, 22 }, { 29, 21 }, { 29, 22 }, { 24, 32 }, { 29, 23 }, { 30, 22 }, { 30, 23 },
+	{ 25, 33 }, { 30, 24 }, { 31, 23 }, { 31, 24 }, { 27, 32 }, { 31, 25 }, { 31, 26 }, { 32, 24 },
+	{ 32, 25 }, { 32, 26 }, { 31, 29 }, { 33, 25 }, { 33, 26 }, { 33, 27 }, { 31, 32 }, { 34, 26 },
+	{ 34, 27 }, { 34, 28 }, { 32, 32 }, { 35, 27 }, { 35, 28 }, { 35, 29 }, { 33, 33 }, { 36, 28 },
+	{ 36, 29 }, { 36, 30 }, { 35, 32 }, { 37, 29 }, { 37, 30 }, { 37, 31 }, { 36, 33 }, { 38, 30 },
+	{ 38, 31 }, { 41, 26 }, { 38, 32 }, { 39, 31 }, { 39, 32 }, { 42, 27 }, { 39, 33 }, { 40, 32 },
+	{ 40, 33 }, { 43, 28 }, { 40, 34 }, { 41, 33 }, { 41, 34 }, { 44, 29 }, { 41, 35 }, { 42, 34 },
+	{ 42, 35 }, { 45, 30 }, { 42, 36 }, { 43, 35 }, { 43, 36 }, { 46, 31 }, { 43, 37 }, { 44, 36 },
+	{ 44, 37 }, { 44, 37 }, { 44, 38 }, { 45, 37 }, { 45, 38 }, { 40, 48 }, { 45, 39 }, { 46, 38 },
+	{ 46, 39 }, { 41, 49 }, { 46, 40 }, { 47, 39 }, { 47, 40 }, { 43, 48 }, { 47, 41 }, { 47, 42 },
+	{ 48, 40 }, { 48, 41 }, { 48, 42 }, { 47, 45 }, { 49, 41 }, { 49, 42 }, { 49, 43 }, { 47, 48 },
+	{ 50, 42 }, { 50, 43 }, { 50, 44 }, { 48, 48 }, { 51, 43 }, { 51, 44 }, { 51, 45 }, { 49, 49 },
+	{ 52, 44 }, { 52, 45 }, { 52, 46 }, { 51, 48 }, { 53, 45 }, { 53, 46 }, { 53, 47 }, { 52, 49 },
+	{ 54, 46 }, { 54, 47 }, { 57, 42 }, { 54, 48 }, { 55, 47 }, { 55, 48 }, { 58, 43 }, { 55, 49 },
+	{ 56, 48 }, { 56, 49 }, { 59, 44 }, { 56, 50 }, { 57, 49 }, { 57, 50 }, { 60, 45 }, { 57, 51 },
+	{ 58, 50 }, { 58, 51 }, { 61, 46 }, { 58, 52 }, { 59, 51 }, { 59, 52 }, { 62, 47 }, { 59, 53 },
+	{ 60, 52 }, { 60, 53 }, { 60, 53 }, { 60, 54 }, { 61, 53 }, { 61, 54 }, { 61, 54 }, { 61, 55 },
+	{ 62, 54 }, { 62, 55 }, { 62, 55 }, { 62, 56 }, { 63, 55 }, { 63, 56 }, { 63, 56 }, { 63, 57 },
+	{ 63, 58 }, { 63, 59 }, { 63, 59 }, { 63, 60 }, { 63, 61 }, { 63, 62 }, { 63, 62 }, { 63, 63 }
+};
diff --git a/src/mesa/state_tracker/st_cb_texture.c b/src/mesa/state_tracker/st_cb_texture.c
index 48af25a1df6..9d4f61b978e 100644
--- a/src/mesa/state_tracker/st_cb_texture.c
+++ b/src/mesa/state_tracker/st_cb_texture.c
@@ -27,6 +27,7 @@
 
 #include <stdio.h>
 #include "main/bufferobj.h"
+#include "main/context.h"
 #include "main/enums.h"
 #include "main/errors.h"
 #include "main/fbobject.h"
@@ -65,10 +66,12 @@
 #include "state_tracker/st_gen_mipmap.h"
 #include "state_tracker/st_atom.h"
 #include "state_tracker/st_sampler_view.h"
+#include "state_tracker/st_texcompress_compute.h"
 #include "state_tracker/st_util.h"
 
 #include "pipe/p_context.h"
 #include "pipe/p_defines.h"
+#include "util/log.h"
 #include "util/u_inlines.h"
 #include "util/u_upload_mgr.h"
 #include "pipe/p_shader_tokens.h"
@@ -540,6 +543,18 @@ st_MapTextureImage(struct gl_context *ctx,
    }
 }
 
+static void
+log_unmap_time_delta(const struct pipe_box *box,
+                     const struct gl_texture_image *texImage,
+                     const char *pathname, int64_t start_us)
+{
+   assert(start_us >= 0);
+   mesa_logi("unmap %dx%d pixels of %s data for %s tex, %s path: "
+             "%"PRIi64" us\n", box->width, box->height,
+             util_format_short_name(texImage->TexFormat),
+             util_format_short_name(texImage->pt->format),
+             pathname, os_time_get() - start_us);
+}
 
 void
 st_UnmapTextureImage(struct gl_context *ctx,
@@ -557,6 +572,44 @@ st_UnmapTextureImage(struct gl_context *ctx,
       if (itransfer->box.depth != 0) {
          assert(itransfer->box.depth == 1);
 
+         /* Toggle logging for the different unmap paths. */
+         const bool log_unmap_time = false;
+         const int64_t unmap_start_us = log_unmap_time ? os_time_get() : 0;
+
+         if (_mesa_is_format_astc_2d(texImage->TexFormat) &&
+             util_format_is_compressed(texImage->pt->format)) {
+
+            /* DXT5 is the only supported transcode target from ASTC. */
+            assert(texImage->pt->format == PIPE_FORMAT_DXT5_RGBA ||
+                   texImage->pt->format == PIPE_FORMAT_DXT5_SRGBA);
+
+            /* Try a compute-based transcode. */
+            if (itransfer->box.x == 0 &&
+                itransfer->box.y == 0 &&
+                itransfer->box.width == texImage->Width &&
+                itransfer->box.height == texImage->Height &&
+                _mesa_has_compute_shaders(ctx) &&
+                st_compute_transcode_astc_to_dxt5(st,
+                   itransfer->temp_data,
+                   itransfer->temp_stride,
+                   texImage->TexFormat,
+                   texImage->pt,
+                   st_texture_image_resource_level(texImage),
+                   itransfer->box.z)) {
+
+               if (log_unmap_time) {
+                  log_unmap_time_delta(&itransfer->box, texImage, "GPU",
+                                       unmap_start_us);
+               }
+
+               /* Mark the unmap as complete. */
+               assert(itransfer->transfer == NULL);
+               memset(itransfer, 0, sizeof(struct st_texture_image_transfer));
+
+               return;
+            }
+         }
+
          struct pipe_transfer *transfer;
          GLubyte *map = st_texture_image_map(st, texImage,
                                              PIPE_MAP_WRITE |
@@ -668,6 +721,12 @@ st_UnmapTextureImage(struct gl_context *ctx,
          }
 
          st_texture_image_unmap(st, texImage, slice);
+
+         if (log_unmap_time) {
+            log_unmap_time_delta(&itransfer->box, texImage, "CPU",
+                                 unmap_start_us);
+         }
+
          memset(&itransfer->box, 0, sizeof(struct pipe_box));
       }
 
diff --git a/src/mesa/state_tracker/st_context.c b/src/mesa/state_tracker/st_context.c
index 71fffcc4bff..fd4d0be449c 100644
--- a/src/mesa/state_tracker/st_context.c
+++ b/src/mesa/state_tracker/st_context.c
@@ -56,6 +56,7 @@
 #include "st_program.h"
 #include "st_sampler_view.h"
 #include "st_shader_cache.h"
+#include "st_texcompress_compute.h"
 #include "st_texture.h"
 #include "st_util.h"
 #include "pipe/p_context.h"
@@ -378,6 +379,10 @@ st_destroy_context_priv(struct st_context *st, bool destroy_pipe)
    st_destroy_drawpix(st);
    st_destroy_drawtex(st);
    st_destroy_pbo_helpers(st);
+
+   if (st->transcode_astc)
+      st_destroy_texcompress_compute(st);
+
    st_destroy_bound_texture_handles(st);
    st_destroy_bound_image_handles(st);
 
@@ -782,6 +787,17 @@ st_create_context_priv(struct gl_context *ctx, struct pipe_context *pipe,
       return NULL;
    }
 
+   if (_mesa_has_compute_shaders(ctx) &&
+       st->transcode_astc && !st_init_texcompress_compute(st)) {
+      /* Transcoding ASTC to DXT5 using compute shaders can provide a
+       * significant performance benefit over the CPU path. It isn't strictly
+       * necessary to fail if we can't use the compute shader path, but it's
+       * very convenient to do so. This should be rare.
+       */
+      st_destroy_context_priv(st, false);
+      return NULL;
+   }
+
    /* This must be done after extensions are initialized to enable persistent
     * mappings immediately.
     */
diff --git a/src/mesa/state_tracker/st_context.h b/src/mesa/state_tracker/st_context.h
index 7ff3baa0e6d..4d7a0ff3f6d 100644
--- a/src/mesa/state_tracker/st_context.h
+++ b/src/mesa/state_tracker/st_context.h
@@ -343,6 +343,13 @@ struct st_context
       bool use_gs;
    } pbo;
 
+   struct {
+      struct gl_program **progs;
+      struct pipe_resource *bc1_endpoint_buf;
+      struct pipe_sampler_view *astc_luts[5];
+      struct hash_table *astc_partition_tables;
+   } texcompress_compute;
+
    /** for drawing with st_util_vertex */
    struct cso_velems_state util_velems;
 
diff --git a/src/mesa/state_tracker/st_texcompress_compute.c b/src/mesa/state_tracker/st_texcompress_compute.c
new file mode 100644
index 00000000000..a2f68d91960
--- /dev/null
+++ b/src/mesa/state_tracker/st_texcompress_compute.c
@@ -0,0 +1,842 @@
+/**************************************************************************
+ *
+ * Copyright © 2022 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ **************************************************************************/
+
+#include "compiler/glsl/astc_glsl.h"
+#include "compiler/glsl/bc1_glsl.h"
+#include "compiler/glsl/bc4_glsl.h"
+#include "compiler/glsl/cross_platform_settings_piece_all.h"
+#include "compiler/glsl/etc2_rgba_stitch_glsl.h"
+
+#include "main/context.h"
+#include "main/shaderapi.h"
+#include "main/shaderobj.h"
+#include "main/texcompress_astc.h"
+#include "main/texcompress_astc_luts_wrap.h"
+#include "main/uniforms.h"
+
+#include "state_tracker/st_atom_constbuf.h"
+#include "state_tracker/st_bc1_tables.h"
+#include "state_tracker/st_context.h"
+#include "state_tracker/st_program.h"
+#include "state_tracker/st_texcompress_compute.h"
+#include "state_tracker/st_texture.h"
+
+#include "util/u_hash_table.h"
+#include "util/u_string.h"
+
+enum compute_program_id {
+   COMPUTE_PROGRAM_BC1,
+   COMPUTE_PROGRAM_BC4,
+   COMPUTE_PROGRAM_STITCH,
+   COMPUTE_PROGRAM_ASTC_4x4,
+   COMPUTE_PROGRAM_ASTC_5x4,
+   COMPUTE_PROGRAM_ASTC_5x5,
+   COMPUTE_PROGRAM_ASTC_6x5,
+   COMPUTE_PROGRAM_ASTC_6x6,
+   COMPUTE_PROGRAM_ASTC_8x5,
+   COMPUTE_PROGRAM_ASTC_8x6,
+   COMPUTE_PROGRAM_ASTC_8x8,
+   COMPUTE_PROGRAM_ASTC_10x5,
+   COMPUTE_PROGRAM_ASTC_10x6,
+   COMPUTE_PROGRAM_ASTC_10x8,
+   COMPUTE_PROGRAM_ASTC_10x10,
+   COMPUTE_PROGRAM_ASTC_12x10,
+   COMPUTE_PROGRAM_ASTC_12x12,
+   COMPUTE_PROGRAM_COUNT
+};
+
+static struct gl_program * PRINTFLIKE(3, 4)
+get_compute_program(struct st_context *st,
+                    enum compute_program_id prog_id,
+                    const char *source_fmt, ...)
+{
+   /* Try to get the program from the cache. */
+   assert(prog_id < COMPUTE_PROGRAM_COUNT);
+   if (st->texcompress_compute.progs[prog_id])
+      return st->texcompress_compute.progs[prog_id];
+
+   /* Cache miss. Create the final source string. */
+   char *source_str;
+   va_list ap;
+   va_start(ap, source_fmt);
+   int num_printed_bytes = vasprintf(&source_str, source_fmt, ap);
+   va_end(ap);
+   if (num_printed_bytes == -1)
+      return NULL;
+
+   /* Compile and link the shader. Then, destroy the shader string. */
+   const char *strings[] = { source_str };
+   GLuint program =
+      _mesa_CreateShaderProgramv_impl(st->ctx, GL_COMPUTE_SHADER, 1, strings);
+   free(source_str);
+
+   struct gl_shader_program *shProg =
+      _mesa_lookup_shader_program(st->ctx, program);
+   if (!shProg)
+      return NULL;
+
+   if (shProg->data->LinkStatus == LINKING_FAILURE) {
+      fprintf(stderr, "Linking failed:\n%s\n", shProg->data->InfoLog);
+      _mesa_reference_shader_program(st->ctx, &shProg, NULL);
+      return NULL;
+   }
+
+   /* Cache the program and return it. */
+   return st->texcompress_compute.progs[prog_id] =
+          shProg->_LinkedShaders[MESA_SHADER_COMPUTE]->Program;
+}
+
+static struct pipe_resource *
+create_bc1_endpoint_ssbo(struct pipe_context *pipe)
+{
+   struct pipe_resource *buffer =
+      pipe_buffer_create(pipe->screen, PIPE_BIND_SHADER_BUFFER,
+                         PIPE_USAGE_IMMUTABLE, sizeof(float) *
+                         (sizeof(stb__OMatch5) + sizeof(stb__OMatch6)));
+
+   if (!buffer)
+      return NULL;
+
+   struct pipe_transfer *transfer;
+   float (*buffer_map)[2] = pipe_buffer_map(pipe, buffer,
+                                            PIPE_MAP_WRITE |
+                                            PIPE_MAP_DISCARD_WHOLE_RESOURCE,
+                                            &transfer);
+   if (!buffer_map) {
+      pipe_resource_reference(&buffer, NULL);
+      return NULL;
+   }
+
+   for (int i = 0; i < 256; i++) {
+      for (int j = 0; j < 2; j++) {
+         buffer_map[i][j] = (float) stb__OMatch5[i][j];
+         buffer_map[i + 256][j] = (float) stb__OMatch6[i][j];
+      }
+   }
+
+   pipe_buffer_unmap(pipe, transfer);
+
+   return buffer;
+}
+
+static void
+bind_compute_state(struct st_context *st,
+                   struct gl_program *prog,
+                   struct pipe_sampler_view **sampler_views,
+                   const struct pipe_shader_buffer *shader_buffers,
+                   const struct pipe_image_view *image_views,
+                   bool cs_handle_from_prog,
+                   bool constbuf0_from_prog)
+{
+   assert(prog->info.stage == PIPE_SHADER_COMPUTE);
+
+   /* Set compute states in the same order as defined in st_atom_list.h */
+
+   assert(prog->affected_states & ST_NEW_CS_STATE);
+   assert(st->shader_has_one_variant[PIPE_SHADER_COMPUTE]);
+   cso_set_compute_shader_handle(st->cso_context,
+                                 cs_handle_from_prog ?
+                                 prog->variants->driver_shader : NULL);
+
+   if (prog->affected_states & ST_NEW_CS_SAMPLER_VIEWS) {
+      st->pipe->set_sampler_views(st->pipe, prog->info.stage, 0,
+                                  prog->info.num_textures, 0, false,
+                                  sampler_views);
+   }
+
+   if (prog->affected_states & ST_NEW_CS_SAMPLERS) {
+      /* Programs seem to set this bit more often than needed. For example, if
+       * a program only uses texelFetch, this shouldn't be needed. Section
+       * "11.1.3.2 Texel Fetches", of the GL 4.6 spec says:
+       *
+       *    Texel fetch proceeds similarly to the steps described for texture
+       *    access in section 11.1.3.5, with the exception that none of the
+       *    operations controlled by sampler object state are performed,
+       *
+       * We assume that the program is using texelFetch or doesn't care about
+       * this state for a similar reason.
+       *
+       * See https://gitlab.freedesktop.org/mesa/mesa/-/issues/8014.
+       */
+   }
+
+   if (prog->affected_states & ST_NEW_CS_CONSTANTS) {
+      st_upload_constants(st, constbuf0_from_prog ? prog : NULL,
+                          prog->info.stage);
+   }
+
+   if (prog->affected_states & ST_NEW_CS_UBOS) {
+      unreachable("Uniform buffer objects not handled");
+   }
+
+   if (prog->affected_states & ST_NEW_CS_ATOMICS) {
+      unreachable("Atomic buffer objects not handled");
+   }
+
+   if (prog->affected_states & ST_NEW_CS_SSBOS) {
+      st->pipe->set_shader_buffers(st->pipe, prog->info.stage, 0,
+                                   prog->info.num_ssbos, shader_buffers,
+                                   prog->sh.ShaderStorageBlocksWriteAccess);
+   }
+
+   if (prog->affected_states & ST_NEW_CS_IMAGES) {
+      st->pipe->set_shader_images(st->pipe, prog->info.stage, 0,
+                                  prog->info.num_images, 0, image_views);
+   }
+}
+
+static void
+dispatch_compute_state(struct st_context *st,
+                       struct gl_program *prog,
+                       struct pipe_sampler_view **sampler_views,
+                       const struct pipe_shader_buffer *shader_buffers,
+                       const struct pipe_image_view *image_views,
+                       unsigned num_workgroups_x,
+                       unsigned num_workgroups_y,
+                       unsigned num_workgroups_z)
+{
+   assert(prog->info.stage == PIPE_SHADER_COMPUTE);
+
+   /* Bind the state */
+   bind_compute_state(st, prog, sampler_views, shader_buffers, image_views,
+                      true, true);
+
+   /* Launch the grid */
+   const struct pipe_grid_info info = {
+      .block[0] = prog->info.workgroup_size[0],
+      .block[1] = prog->info.workgroup_size[1],
+      .block[2] = prog->info.workgroup_size[2],
+      .grid[0] = num_workgroups_x,
+      .grid[1] = num_workgroups_y,
+      .grid[2] = num_workgroups_z,
+   };
+
+   st->pipe->launch_grid(st->pipe, &info);
+
+   /* Unbind the state */
+   bind_compute_state(st, prog, NULL, NULL, NULL, false, false);
+
+   /* If the previously used compute program was relying on any state that was
+    * trampled on by these state changes, dirty the relevant flags.
+    */
+   if (st->cp) {
+      st->ctx->NewDriverState |=
+         st->cp->affected_states & prog->affected_states;
+   }
+}
+
+static struct pipe_resource *
+cs_encode_bc1(struct st_context *st,
+              struct pipe_resource *rgba8_tex)
+{
+   /* Create the required compute state */
+   struct gl_program *prog =
+      get_compute_program(st, COMPUTE_PROGRAM_BC1, bc1_source,
+                          cross_platform_settings_piece_all_header);
+   if (!prog)
+      return NULL;
+
+   /* ... complete the program setup by defining the number of refinements to
+    * do on the created blocks. The program will attempt to create a more
+    * accurate encoding on each iteration. Doing at least one refinement
+    * provides a significant improvement in quality and is needed to give a
+    * result comparable to the CPU encoder (according to piglit tests).
+    * Additional refinements don't help as much.
+    */
+   const unsigned num_refinements = 1;
+   _mesa_uniform(0, 1, &num_refinements, st->ctx, prog->shader_program,
+                 GLSL_TYPE_UINT, 1);
+
+   const struct pipe_sampler_view templ = {
+      .target = PIPE_TEXTURE_2D,
+      .format = PIPE_FORMAT_R8G8B8A8_UNORM,
+      .swizzle_r = PIPE_SWIZZLE_X,
+      .swizzle_g = PIPE_SWIZZLE_Y,
+      .swizzle_b = PIPE_SWIZZLE_Z,
+      .swizzle_a = PIPE_SWIZZLE_W,
+   };
+   struct pipe_sampler_view *rgba8_view =
+      st->pipe->create_sampler_view(st->pipe, rgba8_tex, &templ);
+   if (!rgba8_view)
+      return NULL;
+
+   const struct pipe_shader_buffer ssbo = {
+      .buffer = st->texcompress_compute.bc1_endpoint_buf,
+      .buffer_size = st->texcompress_compute.bc1_endpoint_buf->width0,
+   };
+
+   struct pipe_resource *bc1_tex =
+      st_texture_create(st, PIPE_TEXTURE_2D, PIPE_FORMAT_R32G32_UINT, 0,
+                        DIV_ROUND_UP(rgba8_tex->width0, 4),
+                        DIV_ROUND_UP(rgba8_tex->height0, 4), 1, 1, 0,
+                        PIPE_BIND_SHADER_IMAGE |
+                        PIPE_BIND_SAMPLER_VIEW, false);
+   if (!bc1_tex)
+      goto release_sampler_views;
+
+   const struct pipe_image_view image = {
+      .resource = bc1_tex,
+      .format = PIPE_FORMAT_R16G16B16A16_UINT,
+      .access = PIPE_IMAGE_ACCESS_WRITE,
+      .shader_access = PIPE_IMAGE_ACCESS_WRITE,
+   };
+
+   /* Dispatch the compute state */
+   dispatch_compute_state(st, prog, &rgba8_view, &ssbo, &image,
+                          DIV_ROUND_UP(rgba8_tex->width0, 32),
+                          DIV_ROUND_UP(rgba8_tex->height0, 32), 1);
+
+release_sampler_views:
+   pipe_sampler_view_reference(&rgba8_view, NULL);
+
+   return bc1_tex;
+}
+
+static struct pipe_resource *
+cs_encode_bc4(struct st_context *st,
+              struct pipe_resource *rgba8_tex,
+              enum pipe_swizzle component, bool use_snorm)
+{
+   /* Create the required compute state */
+   struct gl_program *prog =
+      get_compute_program(st, COMPUTE_PROGRAM_BC4, bc4_source,
+                          cross_platform_settings_piece_all_header);
+   if (!prog)
+      return NULL;
+
+   /* ... complete the program setup by picking the channel to encode and
+    * whether to encode it as snorm. The shader doesn't actually support
+    * channel index 2. So, pick index 0 and rely on swizzling instead.
+    */
+   const unsigned params[] = { 0, use_snorm };
+   _mesa_uniform(0, 1, params, st->ctx, prog->shader_program,
+                 GLSL_TYPE_UINT, 2);
+
+   const struct pipe_sampler_view templ = {
+      .target = PIPE_TEXTURE_2D,
+      .format = PIPE_FORMAT_R8G8B8A8_UNORM,
+      .swizzle_r = component,
+      .swizzle_g = PIPE_SWIZZLE_0,
+      .swizzle_b = PIPE_SWIZZLE_0,
+      .swizzle_a = PIPE_SWIZZLE_1,
+   };
+   struct pipe_sampler_view *rgba8_view =
+      st->pipe->create_sampler_view(st->pipe, rgba8_tex, &templ);
+   if (!rgba8_view)
+      return NULL;
+
+   struct pipe_resource *bc4_tex =
+      st_texture_create(st, PIPE_TEXTURE_2D, PIPE_FORMAT_R32G32_UINT, 0,
+                        DIV_ROUND_UP(rgba8_tex->width0, 4),
+                        DIV_ROUND_UP(rgba8_tex->height0, 4), 1, 1, 0,
+                        PIPE_BIND_SHADER_IMAGE |
+                        PIPE_BIND_SAMPLER_VIEW, false);
+   if (!bc4_tex)
+      goto release_sampler_views;
+
+   const struct pipe_image_view image = {
+      .resource = bc4_tex,
+      .format = PIPE_FORMAT_R16G16B16A16_UINT,
+      .access = PIPE_IMAGE_ACCESS_WRITE,
+      .shader_access = PIPE_IMAGE_ACCESS_WRITE,
+   };
+
+   /* Dispatch the compute state */
+   dispatch_compute_state(st, prog, &rgba8_view, NULL, &image, 1,
+                          DIV_ROUND_UP(rgba8_tex->width0, 16),
+                          DIV_ROUND_UP(rgba8_tex->height0, 16));
+
+release_sampler_views:
+   pipe_sampler_view_reference(&rgba8_view, NULL);
+
+   return bc4_tex;
+}
+
+static struct pipe_resource *
+cs_stitch_64bpb_textures(struct st_context *st,
+                         struct pipe_resource *tex_hi,
+                         struct pipe_resource *tex_lo)
+{
+   assert(util_format_get_blocksizebits(tex_hi->format) == 64);
+   assert(util_format_get_blocksizebits(tex_lo->format) == 64);
+   assert(tex_hi->width0 == tex_lo->width0);
+   assert(tex_hi->height0 == tex_lo->height0);
+
+   struct pipe_resource *stitched_tex = NULL;
+
+   /* Create the required compute state */
+   struct gl_program *prog =
+      get_compute_program(st, COMPUTE_PROGRAM_STITCH, etc2_rgba_stitch_source,
+                          cross_platform_settings_piece_all_header);
+   if (!prog)
+      return NULL;
+
+   const struct pipe_sampler_view templ = {
+      .target = PIPE_TEXTURE_2D,
+      .format = PIPE_FORMAT_R32G32_UINT,
+      .swizzle_r = PIPE_SWIZZLE_X,
+      .swizzle_g = PIPE_SWIZZLE_Y,
+      .swizzle_b = PIPE_SWIZZLE_0,
+      .swizzle_a = PIPE_SWIZZLE_1,
+   };
+   struct pipe_sampler_view *rg32_views[2] = {
+      [0] = st->pipe->create_sampler_view(st->pipe, tex_hi, &templ),
+      [1] = st->pipe->create_sampler_view(st->pipe, tex_lo, &templ),
+   };
+   if (!rg32_views[0] || !rg32_views[1])
+      goto release_sampler_views;
+
+   stitched_tex =
+      st_texture_create(st, PIPE_TEXTURE_2D, PIPE_FORMAT_R32G32B32A32_UINT, 0,
+                        tex_hi->width0,
+                        tex_hi->height0, 1, 1, 0,
+                        PIPE_BIND_SHADER_IMAGE |
+                        PIPE_BIND_SAMPLER_VIEW, false);
+   if (!stitched_tex)
+      goto release_sampler_views;
+
+   const struct pipe_image_view image = {
+      .resource = stitched_tex,
+      .format = PIPE_FORMAT_R32G32B32A32_UINT,
+      .access = PIPE_IMAGE_ACCESS_WRITE,
+      .shader_access = PIPE_IMAGE_ACCESS_WRITE,
+   };
+
+   /* Dispatch the compute state */
+   dispatch_compute_state(st, prog, rg32_views, NULL, &image,
+                          DIV_ROUND_UP(tex_hi->width0, 8),
+                          DIV_ROUND_UP(tex_hi->height0, 8), 1);
+
+release_sampler_views:
+   pipe_sampler_view_reference(&rg32_views[0], NULL);
+   pipe_sampler_view_reference(&rg32_views[1], NULL);
+
+   return stitched_tex;
+}
+
+static struct pipe_resource *
+cs_encode_bc3(struct st_context *st,
+              struct pipe_resource *rgba8_tex)
+{
+   struct pipe_resource *bc3_tex = NULL;
+
+   /* Encode RGB channels as BC1. */
+   struct pipe_resource *bc1_tex = cs_encode_bc1(st, rgba8_tex);
+   if (!bc1_tex)
+      return NULL;
+
+   /* Encode alpha channels as BC4. */
+   struct pipe_resource *bc4_tex =
+      cs_encode_bc4(st, rgba8_tex, PIPE_SWIZZLE_W, false);
+   if (!bc4_tex)
+      goto release_textures;
+
+   st->pipe->memory_barrier(st->pipe, PIPE_BARRIER_TEXTURE);
+
+   /* Combine BC1 and BC4 to create BC3. */
+   bc3_tex = cs_stitch_64bpb_textures(st, bc1_tex, bc4_tex);
+   if (!bc3_tex)
+      goto release_textures;
+
+release_textures:
+   pipe_resource_reference(&bc1_tex, NULL);
+   pipe_resource_reference(&bc4_tex, NULL);
+
+   return bc3_tex;
+}
+
+static struct pipe_resource *
+sw_decode_astc(struct st_context *st,
+               uint8_t *astc_data,
+               unsigned astc_stride,
+               mesa_format astc_format,
+               unsigned width_px, unsigned height_px)
+{
+   /* Create the destination */
+   struct pipe_resource *rgba8_tex =
+      st_texture_create(st, PIPE_TEXTURE_2D, PIPE_FORMAT_R8G8B8A8_UNORM, 0,
+                        width_px, height_px, 1, 1, 0,
+                        PIPE_BIND_SAMPLER_VIEW, false);
+   if (!rgba8_tex)
+      return NULL;
+
+   /* Temporarily map the destination and decode into the returned pointer */
+   struct pipe_transfer *rgba8_xfer;
+   void *rgba8_map = pipe_texture_map(st->pipe, rgba8_tex, 0, 0,
+                                      PIPE_MAP_WRITE, 0, 0,
+                                      width_px, height_px, &rgba8_xfer);
+   if (!rgba8_map) {
+      pipe_resource_reference(&rgba8_tex, NULL);
+      return NULL;
+   }
+
+   _mesa_unpack_astc_2d_ldr(rgba8_map, rgba8_xfer->stride,
+                            astc_data, astc_stride,
+                            width_px, height_px, astc_format);
+
+   pipe_texture_unmap(st->pipe, rgba8_xfer);
+
+   return rgba8_tex;
+}
+
+static struct pipe_sampler_view *
+create_astc_cs_payload_view(struct st_context *st,
+                            uint8_t *data, unsigned stride,
+                            uint32_t width_el, uint32_t height_el)
+{
+   const struct pipe_resource src_templ = {
+      .target = PIPE_TEXTURE_2D,
+      .format = PIPE_FORMAT_R32G32B32A32_UINT,
+      .bind = PIPE_BIND_SAMPLER_VIEW,
+      .usage = PIPE_USAGE_STAGING,
+      .width0 = width_el,
+      .height0 = height_el,
+      .depth0 = 1,
+      .array_size = 1,
+   };
+
+   struct pipe_resource *payload_res =
+      st->screen->resource_create(st->screen, &src_templ);
+
+   if (!payload_res)
+      return NULL;
+
+   struct pipe_box box;
+   u_box_origin_2d(width_el, height_el, &box);
+
+   st->pipe->texture_subdata(st->pipe, payload_res, 0,
+                             PIPE_MAP_DISCARD_WHOLE_RESOURCE,
+                             &box,
+                             data,
+                             stride,
+                             0 /* unused */);
+
+   const struct pipe_sampler_view view_templ = {
+      .target = PIPE_TEXTURE_2D,
+      .format = payload_res->format,
+      .swizzle_r = PIPE_SWIZZLE_X,
+      .swizzle_g = PIPE_SWIZZLE_Y,
+      .swizzle_b = PIPE_SWIZZLE_Z,
+      .swizzle_a = PIPE_SWIZZLE_W,
+   };
+
+   struct pipe_sampler_view *view =
+      st->pipe->create_sampler_view(st->pipe, payload_res, &view_templ);
+
+   pipe_resource_reference(&payload_res, NULL);
+
+   return view;
+}
+
+static struct pipe_sampler_view *
+get_astc_partition_table_view(struct st_context *st,
+                              unsigned block_w,
+                              unsigned block_h)
+{
+   struct pipe_box ptable_box;
+   void *ptable_data =
+      _mesa_get_astc_decoder_partition_table(block_w, block_h, &ptable_box);
+
+   struct pipe_sampler_view *view =
+      util_hash_table_get(st->texcompress_compute.astc_partition_tables,
+                          ptable_data);
+
+   if (view)
+      return view;
+
+   struct pipe_resource *res =
+      st_texture_create(st, PIPE_TEXTURE_2D, PIPE_FORMAT_R8_UINT, 0,
+                        ptable_box.width, ptable_box.height,
+                        1, 1, 0,
+                        PIPE_BIND_SAMPLER_VIEW, false);
+   if (!res)
+      return NULL;
+
+   st->pipe->texture_subdata(st->pipe, res, 0,
+                             PIPE_MAP_DISCARD_WHOLE_RESOURCE,
+                             &ptable_box,
+                             ptable_data,
+                             ptable_box.width,
+                             0 /* unused */);
+
+   const struct pipe_sampler_view templ = {
+      .target = PIPE_TEXTURE_2D,
+      .format = res->format,
+      .swizzle_r = PIPE_SWIZZLE_X,
+      .swizzle_g = PIPE_SWIZZLE_Y,
+      .swizzle_b = PIPE_SWIZZLE_Z,
+      .swizzle_a = PIPE_SWIZZLE_W,
+   };
+
+   view = st->pipe->create_sampler_view(st->pipe, res, &templ);
+
+   pipe_resource_reference(&res, NULL);
+
+   if (view) {
+      _mesa_hash_table_insert(st->texcompress_compute.astc_partition_tables,
+                              ptable_data, view);
+      ASSERTED const unsigned max_entries =
+         COMPUTE_PROGRAM_ASTC_12x12 - COMPUTE_PROGRAM_ASTC_4x4 + 1;
+      assert(_mesa_hash_table_num_entries(
+         st->texcompress_compute.astc_partition_tables) < max_entries);
+   }
+
+   return view;
+}
+
+static struct pipe_resource *
+cs_decode_astc(struct st_context *st,
+               uint8_t *astc_data,
+               unsigned astc_stride,
+               mesa_format astc_format,
+               unsigned width_px, unsigned height_px)
+{
+   const enum compute_program_id astc_id = COMPUTE_PROGRAM_ASTC_4x4 +
+      util_format_linear(astc_format) - PIPE_FORMAT_ASTC_4x4;
+
+   unsigned block_w, block_h;
+   _mesa_get_format_block_size(astc_format, &block_w, &block_h);
+
+   struct gl_program *prog =
+      get_compute_program(st, astc_id, astc_source, block_w, block_h);
+
+   if (!prog)
+      return NULL;
+
+   struct pipe_sampler_view *ptable_view =
+      get_astc_partition_table_view(st, block_w, block_h);
+
+   if (!ptable_view)
+      return NULL;
+
+   struct pipe_sampler_view *payload_view =
+      create_astc_cs_payload_view(st, astc_data, astc_stride,
+                                  DIV_ROUND_UP(width_px, block_w),
+                                  DIV_ROUND_UP(height_px, block_h));
+
+   if (!payload_view)
+      return NULL;
+
+   /* Create the destination */
+   struct pipe_resource *rgba8_tex =
+      st_texture_create(st, PIPE_TEXTURE_2D, PIPE_FORMAT_R8G8B8A8_UNORM, 0,
+                        width_px, height_px, 1, 1, 0,
+                        PIPE_BIND_SAMPLER_VIEW, false);
+
+   if (!rgba8_tex)
+      goto release_payload_view;
+
+   const struct pipe_image_view image = {
+      .resource = rgba8_tex,
+      .format = PIPE_FORMAT_R8G8B8A8_UINT,
+      .access = PIPE_IMAGE_ACCESS_WRITE,
+      .shader_access = PIPE_IMAGE_ACCESS_WRITE,
+   };
+
+   struct pipe_sampler_view *sampler_views[] = {
+      st->texcompress_compute.astc_luts[0],
+      st->texcompress_compute.astc_luts[1],
+      st->texcompress_compute.astc_luts[2],
+      st->texcompress_compute.astc_luts[3],
+      st->texcompress_compute.astc_luts[4],
+      ptable_view,
+      payload_view,
+   };
+
+   dispatch_compute_state(st, prog, sampler_views, NULL, &image,
+                          DIV_ROUND_UP(payload_view->texture->width0, 2),
+                          DIV_ROUND_UP(payload_view->texture->height0, 2),
+                          1);
+
+release_payload_view:
+   pipe_sampler_view_reference(&payload_view, NULL);
+
+   return rgba8_tex;
+}
+
+static struct pipe_sampler_view *
+get_sampler_view_for_lut(struct pipe_context *pipe,
+                         const astc_decoder_lut *lut)
+{
+   struct pipe_resource *res =
+      pipe_buffer_create_with_data(pipe,
+                                   PIPE_BIND_SAMPLER_VIEW,
+                                   PIPE_USAGE_DEFAULT,
+                                   lut->size_B,
+                                   lut->data);
+   if (!res)
+      return NULL;
+
+   const struct pipe_sampler_view templ = {
+      .format = lut->format,
+      .target = PIPE_BUFFER,
+      .swizzle_r = PIPE_SWIZZLE_X,
+      .swizzle_g = PIPE_SWIZZLE_Y,
+      .swizzle_b = PIPE_SWIZZLE_Z,
+      .swizzle_a = PIPE_SWIZZLE_W,
+      .u.buf.offset = 0,
+      .u.buf.size = lut->size_B,
+   };
+
+   struct pipe_sampler_view *view =
+      pipe->create_sampler_view(pipe, res, &templ);
+
+   pipe_resource_reference(&res, NULL);
+
+   return view;
+}
+
+/* Initializes required resources for Granite ASTC GPU decode.
+ *
+ * There are 5 texture buffer objects and one additional texture required.
+ * We initialize 5 tbo's here and a single texture later during runtime.
+ */
+static bool
+initialize_astc_decoder(struct st_context *st)
+{
+   astc_decoder_lut_holder astc_lut_holder;
+   _mesa_init_astc_decoder_luts(&astc_lut_holder);
+
+   const astc_decoder_lut *luts[] = {
+      &astc_lut_holder.color_endpoint,
+      &astc_lut_holder.color_endpoint_unquant,
+      &astc_lut_holder.weights,
+      &astc_lut_holder.weights_unquant,
+      &astc_lut_holder.trits_quints,
+   };
+
+   for (unsigned i = 0; i < ARRAY_SIZE(luts); i++) {
+      st->texcompress_compute.astc_luts[i] =
+         get_sampler_view_for_lut(st->pipe, luts[i]);
+      if (!st->texcompress_compute.astc_luts[i])
+         return false;
+   }
+
+   st->texcompress_compute.astc_partition_tables =
+      _mesa_pointer_hash_table_create(NULL);
+
+   if (!st->texcompress_compute.astc_partition_tables)
+      return false;
+
+   return true;
+}
+
+bool
+st_init_texcompress_compute(struct st_context *st)
+{
+   st->texcompress_compute.progs =
+      calloc(COMPUTE_PROGRAM_COUNT, sizeof(struct gl_program *));
+   if (!st->texcompress_compute.progs)
+      return false;
+
+   st->texcompress_compute.bc1_endpoint_buf =
+      create_bc1_endpoint_ssbo(st->pipe);
+   if (!st->texcompress_compute.bc1_endpoint_buf)
+      return false;
+
+   if (!initialize_astc_decoder(st))
+      return false;
+
+   return true;
+}
+
+static void
+destroy_astc_decoder(struct st_context *st)
+{
+   for (unsigned i = 0; i < ARRAY_SIZE(st->texcompress_compute.astc_luts); i++)
+      pipe_sampler_view_reference(&st->texcompress_compute.astc_luts[i], NULL);
+
+   hash_table_foreach(st->texcompress_compute.astc_partition_tables, entry) {
+      pipe_sampler_view_reference(
+         (struct pipe_sampler_view **)&entry->data, NULL);
+   }
+
+   _mesa_hash_table_destroy(st->texcompress_compute.astc_partition_tables,
+                            NULL);
+}
+
+void
+st_destroy_texcompress_compute(struct st_context *st)
+{
+   /* The programs in the array are part of the gl_context (in st->ctx).They
+    * are automatically destroyed when the context is destroyed (via
+    * _mesa_free_context_data -> ... -> free_shader_program_data_cb).
+    */
+   free(st->texcompress_compute.progs);
+
+   /* Destroy the SSBO used by the BC1 shader program. */
+   pipe_resource_reference(&st->texcompress_compute.bc1_endpoint_buf, NULL);
+
+   destroy_astc_decoder(st);
+}
+
+/* See st_texcompress_compute.h for more information. */
+bool
+st_compute_transcode_astc_to_dxt5(struct st_context *st,
+                                  uint8_t *astc_data,
+                                  unsigned astc_stride,
+                                  mesa_format astc_format,
+                                  struct pipe_resource *dxt5_tex,
+                                  unsigned dxt5_level,
+                                  unsigned dxt5_layer)
+{
+   assert(_mesa_has_compute_shaders(st->ctx));
+   assert(_mesa_is_format_astc_2d(astc_format));
+   assert(dxt5_tex->format == PIPE_FORMAT_DXT5_RGBA ||
+          dxt5_tex->format == PIPE_FORMAT_DXT5_SRGBA);
+   assert(dxt5_level <= dxt5_tex->last_level);
+   assert(dxt5_layer <= util_max_layer(dxt5_tex, dxt5_level));
+
+   bool success = false;
+
+   /* Decode ASTC to RGBA8. */
+   struct pipe_resource *rgba8_tex =
+      cs_decode_astc(st, astc_data, astc_stride, astc_format,
+                     u_minify(dxt5_tex->width0, dxt5_level),
+                     u_minify(dxt5_tex->height0, dxt5_level));
+   if (!rgba8_tex)
+      return false;
+
+   st->pipe->memory_barrier(st->pipe, PIPE_BARRIER_TEXTURE);
+
+   /* Encode RGBA8 to BC3. */
+   struct pipe_resource *bc3_tex = cs_encode_bc3(st, rgba8_tex);
+   if (!bc3_tex)
+      goto release_textures;
+
+   /* Upload the result. */
+   struct pipe_box src_box;
+   u_box_origin_2d(bc3_tex->width0, bc3_tex->height0, &src_box);
+   st->pipe->resource_copy_region(st->pipe, dxt5_tex, dxt5_level,
+                                  0, 0, dxt5_layer, bc3_tex, 0, &src_box);
+
+   success = true;
+
+release_textures:
+   pipe_resource_reference(&rgba8_tex, NULL);
+   pipe_resource_reference(&bc3_tex, NULL);
+
+   return success;
+}
diff --git a/src/mesa/state_tracker/st_texcompress_compute.h b/src/mesa/state_tracker/st_texcompress_compute.h
new file mode 100644
index 00000000000..fb2f08fdae7
--- /dev/null
+++ b/src/mesa/state_tracker/st_texcompress_compute.h
@@ -0,0 +1,51 @@
+/**************************************************************************
+ *
+ * Copyright © 2022 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ **************************************************************************/
+
+#ifndef ST_TEXCOMPRESS_COMPUTE_H
+#define ST_TEXCOMPRESS_COMPUTE_H
+
+bool
+st_init_texcompress_compute(struct st_context *st);
+
+void
+st_destroy_texcompress_compute(struct st_context *st);
+
+/**
+ * When this function returns true, the destination image will contain the
+ * contents of astc_data but transcoded to DXT5/BC3.
+ *
+ * Note that this function will internally create compute programs by using
+ * glCreateShaderProgramv with the application's GL context.
+ */
+bool
+st_compute_transcode_astc_to_dxt5(struct st_context *st,
+                                  uint8_t *astc_data,
+                                  unsigned astc_stride,
+                                  mesa_format astc_format,
+                                  struct pipe_resource *dxt5_tex,
+                                  unsigned dxt5_level,
+                                  unsigned dxt5_layer);
+
+#endif /* ST_TEXCOMPRESS_COMPUTE_H */
diff --git a/src/mesa/state_tracker/st_texture.c b/src/mesa/state_tracker/st_texture.c
index 65340b11e91..25601340a33 100644
--- a/src/mesa/state_tracker/st_texture.c
+++ b/src/mesa/state_tracker/st_texture.c
@@ -259,6 +259,21 @@ st_texture_image_insert_transfer(struct gl_texture_image *stImage,
    stImage->transfer[index].transfer = transfer;
 }
 
+/* See st_texture.h for more information. */
+GLuint
+st_texture_image_resource_level(struct gl_texture_image *stImage)
+{
+   /* An image for a non-finalized texture object only has a single level. */
+   if (stImage->pt != stImage->TexObject->pt)
+      return 0;
+
+   /* An immutable texture object may have views with an LOD offset. */
+   if (stImage->TexObject->Immutable)
+      return stImage->Level + stImage->TexObject->Attrib.MinLevel;
+
+   return stImage->Level;
+}
+
 /**
  * Map a texture image and return the address for a particular 2D face/slice/
  * layer.  The stImage indicates the cube face and mipmap level.  The slice
diff --git a/src/mesa/state_tracker/st_texture.h b/src/mesa/state_tracker/st_texture.h
index 064200d07da..1e5c7827851 100644
--- a/src/mesa/state_tracker/st_texture.h
+++ b/src/mesa/state_tracker/st_texture.h
@@ -186,6 +186,13 @@ st_texture_image_insert_transfer(struct gl_texture_image *stImage,
                                  unsigned index,
                                  struct pipe_transfer *transfer);
 
+/**
+ * Returns the level of the gl_texture_image with respect to the resource it
+ * is allocated within. Example: returns 0 for non-finalized texture.
+ */
+GLuint
+st_texture_image_resource_level(struct gl_texture_image *stImage);
+
 /* Return a pointer to an image within a texture.  Return image stride as
  * well.
  */
-- 
2.33.1

